{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import spacy\n",
    "\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/news-summary-kaggle/news_summary_more.csv',\n",
       " '../data/news-summary-kaggle/news-cleaned.csv',\n",
       " '../data/news-summary-kaggle/news_summary.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('../data/news-summary-kaggle/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/news-summary-kaggle/news_summary.csv', encoding='iso-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4514 entries, 0 to 4513\n",
      "Data columns (total 6 columns):\n",
      "author       4514 non-null object\n",
      "date         4514 non-null object\n",
      "headlines    4514 non-null object\n",
      "read_more    4514 non-null object\n",
      "text         4514 non-null object\n",
      "ctext        4396 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 211.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>headlines</th>\n",
       "      <th>read_more</th>\n",
       "      <th>text</th>\n",
       "      <th>ctext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chhavi Tyagi</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "      <td>http://www.hindustantimes.com/india-news/raksh...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "      <td>http://www.hindustantimes.com/bollywood/malaik...</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>From her special numbers to TV?appearances, Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arshiya Chopra</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "      <td>http://www.hindustantimes.com/patna/bihar-igim...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sumedha Sehra</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "      <td>http://indiatoday.intoday.in/story/abu-dujana-...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aarushi Maheshwari</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Hotel staff to get training to spot signs of s...</td>\n",
       "      <td>http://indiatoday.intoday.in/story/sex-traffic...</td>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "      <td>Hotels in Mumbai and other Indian cities are t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author                  date  \\\n",
       "0        Chhavi Tyagi  03 Aug 2017,Thursday   \n",
       "1         Daisy Mowke  03 Aug 2017,Thursday   \n",
       "2      Arshiya Chopra  03 Aug 2017,Thursday   \n",
       "3       Sumedha Sehra  03 Aug 2017,Thursday   \n",
       "4  Aarushi Maheshwari  03 Aug 2017,Thursday   \n",
       "\n",
       "                                           headlines  \\\n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in...   \n",
       "1  Malaika slams user who trolled her for 'divorc...   \n",
       "2  'Virgin' now corrected to 'Unmarried' in IGIMS...   \n",
       "3  Aaj aapne pakad liya: LeT man Dujana before be...   \n",
       "4  Hotel staff to get training to spot signs of s...   \n",
       "\n",
       "                                           read_more  \\\n",
       "0  http://www.hindustantimes.com/india-news/raksh...   \n",
       "1  http://www.hindustantimes.com/bollywood/malaik...   \n",
       "2  http://www.hindustantimes.com/patna/bihar-igim...   \n",
       "3  http://indiatoday.intoday.in/story/abu-dujana-...   \n",
       "4  http://indiatoday.intoday.in/story/sex-traffic...   \n",
       "\n",
       "                                                text  \\\n",
       "0  The Administration of Union Territory Daman an...   \n",
       "1  Malaika Arora slammed an Instagram user who tr...   \n",
       "2  The Indira Gandhi Institute of Medical Science...   \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
       "4  Hotels in Maharashtra will train their staff t...   \n",
       "\n",
       "                                               ctext  \n",
       "0  The Daman and Diu administration on Wednesday ...  \n",
       "1  From her special numbers to TV?appearances, Bo...  \n",
       "2  The Indira Gandhi Institute of Medical Science...  \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...  \n",
       "4  Hotels in Mumbai and other Indian cities are t...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_more = pd.read_csv('../data/news-summary-kaggle/news_summary_more.csv', encoding='iso-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 98401 entries, 0 to 98400\n",
      "Data columns (total 2 columns):\n",
      "headlines    98401 non-null object\n",
      "text         98401 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data_more.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.DataFrame({\n",
    "    'text': pd.concat([data.text, data_more.text], ignore_index=True),\n",
    "    'summary': pd.concat([data.headlines, data_more.headlines], ignore_index=True)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "      <td>Hotel staff to get training to spot signs of s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The Administration of Union Territory Daman an...   \n",
       "1  Malaika Arora slammed an Instagram user who tr...   \n",
       "2  The Indira Gandhi Institute of Medical Science...   \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
       "4  Hotels in Maharashtra will train their staff t...   \n",
       "\n",
       "                                             summary  \n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in...  \n",
       "1  Malaika slams user who trolled her for 'divorc...  \n",
       "2  'Virgin' now corrected to 'Unmarried' in IGIMS...  \n",
       "3  Aaj aapne pakad liya: LeT man Dujana before be...  \n",
       "4  Hotel staff to get training to spot signs of s...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data['text_len'] = raw_data.text.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['summary_len'] = raw_data.summary.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12fd52790>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.text_len.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x130c0f410>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data.summary_len.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'percentile 0': 'summary length 9.0',\n",
       " 'percentile 1': 'summary length 41.0',\n",
       " 'percentile 2': 'summary length 44.0',\n",
       " 'percentile 3': 'summary length 46.0',\n",
       " 'percentile 4': 'summary length 47.0',\n",
       " 'percentile 5': 'summary length 48.0',\n",
       " 'percentile 95': 'summary length 65.0',\n",
       " 'percentile 96': 'summary length 65.0',\n",
       " 'percentile 97': 'summary length 66.0',\n",
       " 'percentile 98': 'summary length 67.0',\n",
       " 'percentile 99': 'summary length 68.0',\n",
       " 'percentile 100': 'summary length 86.0'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    f'percentile {i}': f'summary length {np.percentile(raw_data.summary_len, i)}'\n",
    "    for i in list(range(0, 6, 1)) + list(range(95, 100 + 1, 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data[raw_data.summary_len > raw_data.summary_len.quantile(.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('pl_spacy_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_strip(row, is_summary=False):\n",
    "    row=re.sub(\"(\\\\t)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\\\r)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\\\n)\", ' ', str(row))\n",
    "\n",
    "    row=re.sub(\"(__+)\", ' ', str(row))\n",
    "    row=re.sub(\"(-+)\", ' ', str(row))\n",
    "    row=re.sub(\"(~~+)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\+\\++)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\.\\.+)\", ' ', str(row))\n",
    "\n",
    "    row=re.sub(\"(\\.\\s+)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\-\\s+)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\:\\s+)\", ' ', str(row))\n",
    "\n",
    "    row=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", '', str(row))\n",
    "\n",
    "    parsed = nlp(row)\n",
    "    lemmatized = ''\n",
    "    for sentence in parsed:\n",
    "        lemmatized += sentence.lemma_.strip() + ' '\n",
    "    lemmatized = lemmatized.lstrip().rstrip()\n",
    "    if is_summary:\n",
    "        return '<START> ' + lemmatized + ' <END>' \n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da6386424954d889d37c3ddf73be433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101873), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 2954/101873 [00:30<06:31, 252.38it/s]"
     ]
    }
   ],
   "source": [
    "raw_data['text_stripped'] = [\n",
    "    spacy_strip(row) for row in tqdm_notebook(raw_data.text)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1df3133b5d4fcf85b3163b36992c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data['text_cleaned'] = [\n",
    "    str(doc) for doc in tqdm_notebook(nlp.pipe(raw_data['text_stripped'], batch_size=5000, n_threads=-1))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a095ccee14f4307b937ae4be50a43e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101873), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data['summary_stripped'] = [\n",
    "    spacy_strip(row, True) for row in tqdm_notebook(raw_data.summary)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7750e6b6b82e42e39299297b4a1faf61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data['summary_cleaned'] = [\n",
    "    str(doc)\n",
    "    for doc in tqdm_notebook(nlp.pipe(raw_data['summary_stripped'], batch_size=5000, n_threads=-1))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load already filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data.to_csv('../data/news-summary-kaggle/news-cleaned.csv')\n",
    "raw_data = pd.read_csv('../data/news-summary-kaggle/news-cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change(row):\n",
    "    row = row.split(' ')\n",
    "    result = ''\n",
    "    for token in row:\n",
    "        if token == '_START_':\n",
    "            result += 'SOS_TOKEN' + ' '\n",
    "        elif token == '_END_':\n",
    "            result += 'EOS_TOKEN'\n",
    "        else:\n",
    "            result += token + ' '\n",
    "    result.lstrip().rstrip()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3714d8bc0544f39706f27dffeec48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101873), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data['summary_stripped'] = [change(row) for row in tqdm_notebook(raw_data.summary_stripped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869a06ee38214673bfa9440eca3c6bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101873), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data['summary_cleaned'] = [change(row) for row in tqdm_notebook(raw_data.summary_cleaned)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>text_len</th>\n",
       "      <th>summary_len</th>\n",
       "      <th>text_stripped</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>summary_stripped</th>\n",
       "      <th>summary_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "      <td>358</td>\n",
       "      <td>60</td>\n",
       "      <td>the Administration of Union Territory Daman an...</td>\n",
       "      <td>the Administration of Union Territory Daman an...</td>\n",
       "      <td>SOS_TOKEN Daman  Diu revoke mandatory Rakshaba...</td>\n",
       "      <td>SOS_TOKEN Daman  Diu revoke mandatory Rakshaba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "      <td>361</td>\n",
       "      <td>60</td>\n",
       "      <td>Malaika Arora slam an Instagram user who troll...</td>\n",
       "      <td>Malaika Arora slam an Instagram user who troll...</td>\n",
       "      <td>SOS_TOKEN Malaika slam user who troll -PRON- f...</td>\n",
       "      <td>SOS_TOKEN Malaika slam user who troll -PRON- f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "      <td>398</td>\n",
       "      <td>52</td>\n",
       "      <td>the Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>the Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>SOS_TOKEN Virgin now correct to Unmarried in I...</td>\n",
       "      <td>SOS_TOKEN Virgin now correct to Unmarried in I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "      <td>368</td>\n",
       "      <td>56</td>\n",
       "      <td>Lashkar e Taibas Kashmir commander Abu Dujana ...</td>\n",
       "      <td>Lashkar e Taibas Kashmir commander Abu Dujana ...</td>\n",
       "      <td>SOS_TOKEN Aaj aapne pakad liya LeT man Dujana ...</td>\n",
       "      <td>SOS_TOKEN Aaj aapne pakad liya LeT man Dujana ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "      <td>Hotel staff to get training to spot signs of s...</td>\n",
       "      <td>366</td>\n",
       "      <td>60</td>\n",
       "      <td>hotel in Maharashtra will train -PRON- staff t...</td>\n",
       "      <td>hotel in Maharashtra will train -PRON- staff t...</td>\n",
       "      <td>SOS_TOKEN hotel staff to get training to spot ...</td>\n",
       "      <td>SOS_TOKEN hotel staff to get training to spot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>A 32-year-old man on Wednesday was found hangi...</td>\n",
       "      <td>Man found dead at Delhi police station, kin al...</td>\n",
       "      <td>347</td>\n",
       "      <td>60</td>\n",
       "      <td>a 32 year old man on Wednesday be find hang in...</td>\n",
       "      <td>a 32 year old man on Wednesday be find hang in...</td>\n",
       "      <td>SOS_TOKEN man find dead at Delhi police statio...</td>\n",
       "      <td>SOS_TOKEN man find dead at Delhi police statio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>The Delhi High Court reduced the compensation ...</td>\n",
       "      <td>Delhi HC reduces aid for 'negligent' accident ...</td>\n",
       "      <td>361</td>\n",
       "      <td>59</td>\n",
       "      <td>the Delhi High Court reduce the compensation a...</td>\n",
       "      <td>the Delhi High Court reduce the compensation a...</td>\n",
       "      <td>SOS_TOKEN Delhi HC reduce aid for negligent ac...</td>\n",
       "      <td>SOS_TOKEN Delhi HC reduce aid for negligent ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>A 60-year old Dalit woman was allegedly lynche...</td>\n",
       "      <td>60-yr-old lynched over rumours she was cutting...</td>\n",
       "      <td>331</td>\n",
       "      <td>60</td>\n",
       "      <td>a 60 year old Dalit woman be allegedly lynch i...</td>\n",
       "      <td>a 60 year old Dalit woman be allegedly lynch i...</td>\n",
       "      <td>SOS_TOKEN 60 yr old lynch over rumour -PRON- b...</td>\n",
       "      <td>SOS_TOKEN 60 yr old lynch over rumour -PRON- b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>An inquiry by the Aircraft Accident Investigat...</td>\n",
       "      <td>Chopper flying critically low led to 2015 Bomb...</td>\n",
       "      <td>370</td>\n",
       "      <td>59</td>\n",
       "      <td>an inquiry by the Aircraft Accident Investigat...</td>\n",
       "      <td>an inquiry by the Aircraft Accident Investigat...</td>\n",
       "      <td>SOS_TOKEN chopper fly critically low lead to 2...</td>\n",
       "      <td>SOS_TOKEN chopper fly critically low lead to 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>The Congress party has opened a bank called 'S...</td>\n",
       "      <td>Congress opens 'State Bank of Tomato' in Lucknow</td>\n",
       "      <td>311</td>\n",
       "      <td>48</td>\n",
       "      <td>the Congress party have open a bank call State...</td>\n",
       "      <td>the Congress party have open a bank call State...</td>\n",
       "      <td>SOS_TOKEN Congress open State Bank of Tomato i...</td>\n",
       "      <td>SOS_TOKEN Congress open State Bank of Tomato i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>India's food regulator Food Safety and Standar...</td>\n",
       "      <td>Food regulator planning leftover banks to feed...</td>\n",
       "      <td>367</td>\n",
       "      <td>60</td>\n",
       "      <td>Indias food regulator Food Safety and Standard...</td>\n",
       "      <td>Indias food regulator Food Safety and Standard...</td>\n",
       "      <td>SOS_TOKEN food regulator planning leftover ban...</td>\n",
       "      <td>SOS_TOKEN food regulator planning leftover ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>The mother of Harshit Sharma, the class 12 Cha...</td>\n",
       "      <td>Call devastated his life: Mom of boy who got '...</td>\n",
       "      <td>336</td>\n",
       "      <td>59</td>\n",
       "      <td>the mother of Harshit Sharma the class 12 Chan...</td>\n",
       "      <td>the mother of Harshit Sharma the class 12 Chan...</td>\n",
       "      <td>SOS_TOKEN call devastate -PRON- life Mom of bo...</td>\n",
       "      <td>SOS_TOKEN call devastate -PRON- life Mom of bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Municipal Corporation of Gurugram on Wednesday...</td>\n",
       "      <td>19 Gurugram buildings to pay property tax over...</td>\n",
       "      <td>377</td>\n",
       "      <td>59</td>\n",
       "      <td>Municipal Corporation of Gurugram on Wednesday...</td>\n",
       "      <td>Municipal Corporation of Gurugram on Wednesday...</td>\n",
       "      <td>SOS_TOKEN 19 Gurugram building to pay property...</td>\n",
       "      <td>SOS_TOKEN 19 Gurugram building to pay property...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Scientists, for the first time, successfully f...</td>\n",
       "      <td>Human embryos edited to stop deadly disease fo...</td>\n",
       "      <td>365</td>\n",
       "      <td>60</td>\n",
       "      <td>scientist for the first time successfully free...</td>\n",
       "      <td>scientist for the first time successfully free...</td>\n",
       "      <td>SOS_TOKEN human embryo edit to stop deadly dis...</td>\n",
       "      <td>SOS_TOKEN human embryo edit to stop deadly dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>A Union Minister of State for Home Affairs inf...</td>\n",
       "      <td>Nearly 2,300 CPWD buildings in Delhi unsafe: U...</td>\n",
       "      <td>388</td>\n",
       "      <td>59</td>\n",
       "      <td>a Union Minister of State for Home Affairs inf...</td>\n",
       "      <td>a Union Minister of State for Home Affairs inf...</td>\n",
       "      <td>SOS_TOKEN nearly 2300 CPWD building in Delhi u...</td>\n",
       "      <td>SOS_TOKEN nearly 2300 CPWD building in Delhi u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>The Supreme Court today refused to stay the ex...</td>\n",
       "      <td>Gujarat Rajya Sabha polls to be held with NOTA...</td>\n",
       "      <td>302</td>\n",
       "      <td>57</td>\n",
       "      <td>the Supreme Court today refuse to stay the exe...</td>\n",
       "      <td>the Supreme Court today refuse to stay the exe...</td>\n",
       "      <td>SOS_TOKEN Gujarat Rajya Sabha poll to be hold ...</td>\n",
       "      <td>SOS_TOKEN Gujarat Rajya Sabha poll to be hold ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Tanveer Hussain, a 24-year-old Indian athlete ...</td>\n",
       "      <td>Indian athlete indicted on sex abuse charge in US</td>\n",
       "      <td>324</td>\n",
       "      <td>49</td>\n",
       "      <td>Tanveer Hussain a 24 year old indian athlete f...</td>\n",
       "      <td>Tanveer Hussain a 24 year old indian athlete f...</td>\n",
       "      <td>SOS_TOKEN indian athlete indict on sex abuse c...</td>\n",
       "      <td>SOS_TOKEN indian athlete indict on sex abuse c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Bomb squads and canine teams were rushed to ch...</td>\n",
       "      <td>Maruti spare parts trigger bomb scare at Delhi...</td>\n",
       "      <td>301</td>\n",
       "      <td>54</td>\n",
       "      <td>bomb squad and canine team be rush to check a ...</td>\n",
       "      <td>bomb squad and canine team be rush to check a ...</td>\n",
       "      <td>SOS_TOKEN Maruti spare part trigger bomb scare...</td>\n",
       "      <td>SOS_TOKEN Maruti spare part trigger bomb scare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Defending the IGIMS marital declaration form, ...</td>\n",
       "      <td>Virgin means unmarried, nothing offensive in i...</td>\n",
       "      <td>367</td>\n",
       "      <td>57</td>\n",
       "      <td>defend the IGIMS marital declaration form Biha...</td>\n",
       "      <td>defend the IGIMS marital declaration form Biha...</td>\n",
       "      <td>SOS_TOKEN Virgin mean unmarrie nothing offensi...</td>\n",
       "      <td>SOS_TOKEN Virgin mean unmarrie nothing offensi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>The members of a Norwegian anti-immigrant grou...</td>\n",
       "      <td>Bus seats mistaken for burqas by Norway anti-i...</td>\n",
       "      <td>359</td>\n",
       "      <td>60</td>\n",
       "      <td>the member of a norwegian anti immigrant group...</td>\n",
       "      <td>the member of a norwegian anti immigrant group...</td>\n",
       "      <td>SOS_TOKEN bus seat mistake for burqas by Norwa...</td>\n",
       "      <td>SOS_TOKEN bus seat mistake for burqas by Norwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>A newborn boy in Maharashtra's Thane was found...</td>\n",
       "      <td>Baby 'pregnant' with malformed twin born in Ma...</td>\n",
       "      <td>340</td>\n",
       "      <td>55</td>\n",
       "      <td>a newborn boy in Maharashtras Thane be find to...</td>\n",
       "      <td>a newborn boy in Maharashtras Thane be find to...</td>\n",
       "      <td>SOS_TOKEN baby pregnant with malformed twin be...</td>\n",
       "      <td>SOS_TOKEN baby pregnant with malformed twin be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>The North Delhi Municipal Corporation has said...</td>\n",
       "      <td>Delhi's AIIMS, Safdarjung to be declared no-ha...</td>\n",
       "      <td>366</td>\n",
       "      <td>55</td>\n",
       "      <td>the North Delhi Municipal Corporation have say...</td>\n",
       "      <td>the North Delhi Municipal Corporation have say...</td>\n",
       "      <td>SOS_TOKEN Delhis AIIMS Safdarjung to be declar...</td>\n",
       "      <td>SOS_TOKEN Delhis AIIMS Safdarjung to be declar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Over 400 farmers from Greater Noida and adjoin...</td>\n",
       "      <td>Noida farmers demand release of arrested count...</td>\n",
       "      <td>389</td>\n",
       "      <td>54</td>\n",
       "      <td>over 400 farmer from Greater Noida and adjoini...</td>\n",
       "      <td>over 400 farmer from Greater Noida and adjoini...</td>\n",
       "      <td>SOS_TOKEN Noida farmer demand release of arres...</td>\n",
       "      <td>SOS_TOKEN Noida farmer demand release of arres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Investigators have released pictures showing h...</td>\n",
       "      <td>Photo shows how close flight came to crashing ...</td>\n",
       "      <td>374</td>\n",
       "      <td>59</td>\n",
       "      <td>investigator have release picture show how clo...</td>\n",
       "      <td>investigator have release picture show how clo...</td>\n",
       "      <td>SOS_TOKEN photo show how close flight come to ...</td>\n",
       "      <td>SOS_TOKEN photo show how close flight come to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Two sunbathers, a 56-year-old man and an eight...</td>\n",
       "      <td>Sunbathers killed as plane hits them while lan...</td>\n",
       "      <td>342</td>\n",
       "      <td>59</td>\n",
       "      <td>two sunbather a 56 year old man and an eight y...</td>\n",
       "      <td>two sunbather a 56 year old man and an eight y...</td>\n",
       "      <td>SOS_TOKEN sunbather kill as plane hit -PRON- w...</td>\n",
       "      <td>SOS_TOKEN sunbather kill as plane hit -PRON- w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>The Saudi-led coalition in Yemen is blocking d...</td>\n",
       "      <td>Saudi-led coalition blocks fuel for UN aid pla...</td>\n",
       "      <td>384</td>\n",
       "      <td>58</td>\n",
       "      <td>the Saudi lead coalition in Yemen be block del...</td>\n",
       "      <td>the Saudi lead coalition in Yemen be block del...</td>\n",
       "      <td>SOS_TOKEN Saudi lead coalition block fuel for ...</td>\n",
       "      <td>SOS_TOKEN Saudi lead coalition block fuel for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>The US Air Force on Wednesday successfully lau...</td>\n",
       "      <td>US tests unarmed intercontinental ballistic mi...</td>\n",
       "      <td>393</td>\n",
       "      <td>51</td>\n",
       "      <td>the US Air Force on Wednesday successfully lau...</td>\n",
       "      <td>the US Air Force on Wednesday successfully lau...</td>\n",
       "      <td>SOS_TOKEN US test unarmed intercontinental bal...</td>\n",
       "      <td>SOS_TOKEN US test unarmed intercontinental bal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>The remains of a German hiker, who disappeared...</td>\n",
       "      <td>German hiker found in Swiss Alps 30 yrs after ...</td>\n",
       "      <td>347</td>\n",
       "      <td>59</td>\n",
       "      <td>the remain of a german hiker who disappear whi...</td>\n",
       "      <td>the remain of a german hiker who disappear whi...</td>\n",
       "      <td>SOS_TOKEN german hiker find in Swiss Alps 30 y...</td>\n",
       "      <td>SOS_TOKEN german hiker find in Swiss Alps 30 y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Veteran actor Dilip Kumar has been admitted to...</td>\n",
       "      <td>Veteran actor Dilip Kumar hospitalised in Mumbai</td>\n",
       "      <td>373</td>\n",
       "      <td>48</td>\n",
       "      <td>veteran actor Dilip Kumar have be admit to Lil...</td>\n",
       "      <td>veteran actor Dilip Kumar have be admit to Lil...</td>\n",
       "      <td>SOS_TOKEN veteran actor Dilip Kumar hospitalis...</td>\n",
       "      <td>SOS_TOKEN veteran actor Dilip Kumar hospitalis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>The Mangrove Society of India has listed Mumba...</td>\n",
       "      <td>Mumbai has 2 out of 12 unique mangrove forests...</td>\n",
       "      <td>383</td>\n",
       "      <td>56</td>\n",
       "      <td>the Mangrove Society of India have list Mumbai...</td>\n",
       "      <td>the Mangrove Society of India have list Mumbai...</td>\n",
       "      <td>SOS_TOKEN Mumbai have 2 out of 12 unique mangr...</td>\n",
       "      <td>SOS_TOKEN Mumbai have 2 out of 12 unique mangr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101843</th>\n",
       "      <td>102885</td>\n",
       "      <td>Bharatiya Janata Party on Wednesday dismissed ...</td>\n",
       "      <td>There are defects in you, not in EVMs: BJP to ...</td>\n",
       "      <td>381</td>\n",
       "      <td>54</td>\n",
       "      <td>Bharatiya Janata Party on Wednesday dismiss BS...</td>\n",
       "      <td>Bharatiya Janata Party on Wednesday dismiss BS...</td>\n",
       "      <td>SOS_TOKEN there be defect in -PRON- not in evm...</td>\n",
       "      <td>SOS_TOKEN there be defect in -PRON- not in evm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101844</th>\n",
       "      <td>102886</td>\n",
       "      <td>An armed fan, with his face covered by a black...</td>\n",
       "      <td>Video: Armed fan invades pitch to attack footb...</td>\n",
       "      <td>296</td>\n",
       "      <td>57</td>\n",
       "      <td>an armed fan with -PRON- face cover by a black...</td>\n",
       "      <td>an armed fan with -PRON- face cover by a black...</td>\n",
       "      <td>SOS_TOKEN Video Armed fan invades pitch to att...</td>\n",
       "      <td>SOS_TOKEN Video Armed fan invades pitch to att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101845</th>\n",
       "      <td>102887</td>\n",
       "      <td>Two leopards escaped from Gopalpur Zoo in Hima...</td>\n",
       "      <td>Two leopards escape from a zoo in Himachal Pra...</td>\n",
       "      <td>382</td>\n",
       "      <td>50</td>\n",
       "      <td>two leopard escape from Gopalpur Zoo in Himach...</td>\n",
       "      <td>two leopard escape from Gopalpur Zoo in Himach...</td>\n",
       "      <td>SOS_TOKEN two leopard escape from a zoo in Him...</td>\n",
       "      <td>SOS_TOKEN two leopard escape from a zoo in Him...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101846</th>\n",
       "      <td>102888</td>\n",
       "      <td>The Karnataka government has capped the price ...</td>\n",
       "      <td>Karnataka caps movie ticket prices at Ă˘ÂÂš20...</td>\n",
       "      <td>376</td>\n",
       "      <td>63</td>\n",
       "      <td>the Karnataka government have cap the price of...</td>\n",
       "      <td>the Karnataka government have cap the price of...</td>\n",
       "      <td>SOS_TOKEN Karnataka cap movie ticket price at ...</td>\n",
       "      <td>SOS_TOKEN Karnataka cap movie ticket price at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101847</th>\n",
       "      <td>102889</td>\n",
       "      <td>BJP's Biren Singh, who was sworn in as Manipur...</td>\n",
       "      <td>Biren Singh country's first CM to have been a ...</td>\n",
       "      <td>374</td>\n",
       "      <td>59</td>\n",
       "      <td>BJPs Biren Singh who be swear in as Manipurs C...</td>\n",
       "      <td>BJPs Biren Singh who be swear in as Manipurs C...</td>\n",
       "      <td>SOS_TOKEN Biren Singh country first CM to have...</td>\n",
       "      <td>SOS_TOKEN Biren Singh country first CM to have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101848</th>\n",
       "      <td>102890</td>\n",
       "      <td>The Union Cabinet on Wednesday approved a 2% h...</td>\n",
       "      <td>Cabinet approves 2% Dearness Allowance hike fo...</td>\n",
       "      <td>382</td>\n",
       "      <td>58</td>\n",
       "      <td>the Union Cabinet on Wednesday approve a 2 % h...</td>\n",
       "      <td>the Union Cabinet on Wednesday approve a 2 % h...</td>\n",
       "      <td>SOS_TOKEN Cabinet approve 2 % Dearness Allowan...</td>\n",
       "      <td>SOS_TOKEN Cabinet approve 2 % Dearness Allowan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101849</th>\n",
       "      <td>102891</td>\n",
       "      <td>A Facebook post by Stayzilla client Jig Saw's ...</td>\n",
       "      <td>Stayzilla client enquired about Voodoo dolls o...</td>\n",
       "      <td>359</td>\n",
       "      <td>56</td>\n",
       "      <td>a facebook post by Stayzilla client Jig saw ow...</td>\n",
       "      <td>a facebook post by Stayzilla client Jig saw ow...</td>\n",
       "      <td>SOS_TOKEN stayzilla client enquire about voodo...</td>\n",
       "      <td>SOS_TOKEN stayzilla client enquire about voodo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101850</th>\n",
       "      <td>102892</td>\n",
       "      <td>Actor Akshay Kumar is set to star as Gulshan K...</td>\n",
       "      <td>Akshay to star as T-Series founder Gulshan Kum...</td>\n",
       "      <td>336</td>\n",
       "      <td>59</td>\n",
       "      <td>Actor Akshay Kumar be set to star as Gulshan K...</td>\n",
       "      <td>Actor Akshay Kumar be set to star as Gulshan K...</td>\n",
       "      <td>SOS_TOKEN akshay to star as T Series founder G...</td>\n",
       "      <td>SOS_TOKEN akshay to star as T Series founder G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101851</th>\n",
       "      <td>102893</td>\n",
       "      <td>Researchers have uncovered a Gmail phishing sc...</td>\n",
       "      <td>Fake Gmail attachment scam fools users into te...</td>\n",
       "      <td>350</td>\n",
       "      <td>60</td>\n",
       "      <td>researcher have uncover a Gmail phishe scam wh...</td>\n",
       "      <td>researcher have uncover a Gmail phishe scam wh...</td>\n",
       "      <td>SOS_TOKEN fake Gmail attachment scam fool user...</td>\n",
       "      <td>SOS_TOKEN fake Gmail attachment scam fool user...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101852</th>\n",
       "      <td>102894</td>\n",
       "      <td>Patesh Talukdar from India holds the Guinness ...</td>\n",
       "      <td>Indian holds world record for eating a drinkin...</td>\n",
       "      <td>311</td>\n",
       "      <td>54</td>\n",
       "      <td>Patesh Talukdar from India hold the Guinness W...</td>\n",
       "      <td>Patesh Talukdar from India hold the Guinness W...</td>\n",
       "      <td>SOS_TOKEN Indian hold world record for eat a d...</td>\n",
       "      <td>SOS_TOKEN Indian hold world record for eat a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101853</th>\n",
       "      <td>102895</td>\n",
       "      <td>New satellite images reportedly show that Chin...</td>\n",
       "      <td>New Chinese construction work spotted in South...</td>\n",
       "      <td>382</td>\n",
       "      <td>57</td>\n",
       "      <td>new satellite image reportedly show that China...</td>\n",
       "      <td>new satellite image reportedly show that China...</td>\n",
       "      <td>SOS_TOKEN new chinese construction work spot i...</td>\n",
       "      <td>SOS_TOKEN new chinese construction work spot i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101854</th>\n",
       "      <td>102896</td>\n",
       "      <td>Censor Board chief Pahlaj Nihalani has confirm...</td>\n",
       "      <td>Censor Board to go digital, confirms chief Pah...</td>\n",
       "      <td>356</td>\n",
       "      <td>58</td>\n",
       "      <td>Censor Board chief Pahlaj Nihalani have confir...</td>\n",
       "      <td>Censor Board chief Pahlaj Nihalani have confir...</td>\n",
       "      <td>SOS_TOKEN Censor Board to go digital confirm c...</td>\n",
       "      <td>SOS_TOKEN Censor Board to go digital confirm c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101855</th>\n",
       "      <td>102897</td>\n",
       "      <td>Check Point Security has revealed a WhatsApp v...</td>\n",
       "      <td>WhatsApp flaw to hijack accounts through image...</td>\n",
       "      <td>374</td>\n",
       "      <td>56</td>\n",
       "      <td>check Point Security have reveal a WhatsApp vu...</td>\n",
       "      <td>check Point Security have reveal a WhatsApp vu...</td>\n",
       "      <td>SOS_TOKEN WhatsApp flaw to hijack account thro...</td>\n",
       "      <td>SOS_TOKEN WhatsApp flaw to hijack account thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101856</th>\n",
       "      <td>102898</td>\n",
       "      <td>A Czech zoo has said it will remove the horns ...</td>\n",
       "      <td>Czech zoo to remove horns of 18 white rhinos a...</td>\n",
       "      <td>322</td>\n",
       "      <td>57</td>\n",
       "      <td>a Czech zoo have say -PRON- will remove the ho...</td>\n",
       "      <td>a Czech zoo have say -PRON- will remove the ho...</td>\n",
       "      <td>SOS_TOKEN czech zoo to remove horn of 18 white...</td>\n",
       "      <td>SOS_TOKEN czech zoo to remove horn of 18 white...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101857</th>\n",
       "      <td>102899</td>\n",
       "      <td>Ride-hailing startup Uber's main rival in Sout...</td>\n",
       "      <td>Uber rival Grab to open research centre in Ben...</td>\n",
       "      <td>379</td>\n",
       "      <td>52</td>\n",
       "      <td>ride hailing startup Ubers main rival in South...</td>\n",
       "      <td>ride hailing startup Ubers main rival in South...</td>\n",
       "      <td>SOS_TOKEN Uber rival Grab to open research cen...</td>\n",
       "      <td>SOS_TOKEN Uber rival Grab to open research cen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101858</th>\n",
       "      <td>102900</td>\n",
       "      <td>BSP supremo Mayawati has said that her party w...</td>\n",
       "      <td>BSP to observe black day each month over EVM t...</td>\n",
       "      <td>356</td>\n",
       "      <td>60</td>\n",
       "      <td>bsp supremo Mayawati have say that -PRON- part...</td>\n",
       "      <td>bsp supremo Mayawati have say that -PRON- part...</td>\n",
       "      <td>SOS_TOKEN bsp to observe black day each month ...</td>\n",
       "      <td>SOS_TOKEN bsp to observe black day each month ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101859</th>\n",
       "      <td>102901</td>\n",
       "      <td>A 19th-century book at a library in Harvard Un...</td>\n",
       "      <td>A book at Harvard University is bound in human...</td>\n",
       "      <td>331</td>\n",
       "      <td>51</td>\n",
       "      <td>a 19th century book at a library in Harvard Un...</td>\n",
       "      <td>a 19th century book at a library in Harvard Un...</td>\n",
       "      <td>SOS_TOKEN a book at Harvard University be bind...</td>\n",
       "      <td>SOS_TOKEN a book at Harvard University be bind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101860</th>\n",
       "      <td>102902</td>\n",
       "      <td>Amid reports claiming that BJP may appoint Hom...</td>\n",
       "      <td>Rajnath Singh dismisses reports that he will b...</td>\n",
       "      <td>341</td>\n",
       "      <td>58</td>\n",
       "      <td>amid report claim that BJP may appoint Home Mi...</td>\n",
       "      <td>amid report claim that BJP may appoint Home Mi...</td>\n",
       "      <td>SOS_TOKEN Rajnath Singh dismiss report that -P...</td>\n",
       "      <td>SOS_TOKEN Rajnath Singh dismiss report that -P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101861</th>\n",
       "      <td>102903</td>\n",
       "      <td>Scott Marsden, a 14-year-old kickboxer from En...</td>\n",
       "      <td>14-year-old kickboxer dies after unsanctioned ...</td>\n",
       "      <td>372</td>\n",
       "      <td>56</td>\n",
       "      <td>Scott Marsden a 14 year old kickboxer from Eng...</td>\n",
       "      <td>Scott Marsden a 14 year old kickboxer from Eng...</td>\n",
       "      <td>SOS_TOKEN 14 year old kickboxer die after unsa...</td>\n",
       "      <td>SOS_TOKEN 14 year old kickboxer die after unsa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101862</th>\n",
       "      <td>102904</td>\n",
       "      <td>One person was arrested in connection with the...</td>\n",
       "      <td>Irish woman found dead in Goa, one arrested</td>\n",
       "      <td>302</td>\n",
       "      <td>43</td>\n",
       "      <td>one person be arrest in connection with the mu...</td>\n",
       "      <td>one person be arrest in connection with the mu...</td>\n",
       "      <td>SOS_TOKEN irish woman find dead in Goa one arr...</td>\n",
       "      <td>SOS_TOKEN irish woman find dead in Goa one arr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101863</th>\n",
       "      <td>102905</td>\n",
       "      <td>Retired US Navy Admiral Bruce Loveless and eig...</td>\n",
       "      <td>Retired US Navy Admiral arrested in sex for se...</td>\n",
       "      <td>382</td>\n",
       "      <td>59</td>\n",
       "      <td>retire US Navy Admiral Bruce Loveless and eigh...</td>\n",
       "      <td>retire US Navy Admiral Bruce Loveless and eigh...</td>\n",
       "      <td>SOS_TOKEN retire US Navy Admiral arrest in sex...</td>\n",
       "      <td>SOS_TOKEN retire US Navy Admiral arrest in sex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101864</th>\n",
       "      <td>102906</td>\n",
       "      <td>Dinesh Shivnath Upadhyaya from Mumbai is recog...</td>\n",
       "      <td>Indian has world record for most lit candles i...</td>\n",
       "      <td>318</td>\n",
       "      <td>53</td>\n",
       "      <td>Dinesh Shivnath Upadhyaya from Mumbai be recog...</td>\n",
       "      <td>Dinesh Shivnath Upadhyaya from Mumbai be recog...</td>\n",
       "      <td>SOS_TOKEN Indian have world record for most li...</td>\n",
       "      <td>SOS_TOKEN Indian have world record for most li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101865</th>\n",
       "      <td>102907</td>\n",
       "      <td>A Los Angeles-based startup has developed 'Paq...</td>\n",
       "      <td>Startup makes Ă˘ÂÂš23,000 smart bag to freshe...</td>\n",
       "      <td>339</td>\n",
       "      <td>64</td>\n",
       "      <td>a Los Angeles base startup have develop paqsul...</td>\n",
       "      <td>a Los Angeles base startup have develop paqsul...</td>\n",
       "      <td>SOS_TOKEN startup make Ă˘ÂÂš23000 smart bag t...</td>\n",
       "      <td>SOS_TOKEN startup make Ă˘ÂÂš23000 smart bag t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101866</th>\n",
       "      <td>102908</td>\n",
       "      <td>The Enforcement Directorate has summoned Jammu...</td>\n",
       "      <td>Kashmiri separatist leaders summoned over mone...</td>\n",
       "      <td>376</td>\n",
       "      <td>58</td>\n",
       "      <td>the Enforcement Directorate have summon Jammu ...</td>\n",
       "      <td>the Enforcement Directorate have summon Jammu ...</td>\n",
       "      <td>SOS_TOKEN Kashmiri separatist leader summon ov...</td>\n",
       "      <td>SOS_TOKEN Kashmiri separatist leader summon ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101867</th>\n",
       "      <td>102909</td>\n",
       "      <td>Pakistan has started building a nearly 2,400-k...</td>\n",
       "      <td>Pakistan starts building fence along Afghanist...</td>\n",
       "      <td>400</td>\n",
       "      <td>55</td>\n",
       "      <td>Pakistan have start build a nearly 2400 kilome...</td>\n",
       "      <td>Pakistan have start build a nearly 2400 kilome...</td>\n",
       "      <td>SOS_TOKEN Pakistan start building fence along ...</td>\n",
       "      <td>SOS_TOKEN Pakistan start building fence along ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101868</th>\n",
       "      <td>102910</td>\n",
       "      <td>A CRPF jawan was on Tuesday axed to death with...</td>\n",
       "      <td>CRPF jawan axed to death by Maoists in Chhatti...</td>\n",
       "      <td>360</td>\n",
       "      <td>51</td>\n",
       "      <td>a CRPF jawan be on Tuesday axe to death with s...</td>\n",
       "      <td>a CRPF jawan be on Tuesday axe to death with s...</td>\n",
       "      <td>SOS_TOKEN CRPF jawan axe to death by Maoists i...</td>\n",
       "      <td>SOS_TOKEN CRPF jawan axe to death by Maoists i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101869</th>\n",
       "      <td>102911</td>\n",
       "      <td>'Uff Yeh', the first song from the Sonakshi Si...</td>\n",
       "      <td>First song from Sonakshi Sinha's 'Noor' titled...</td>\n",
       "      <td>353</td>\n",
       "      <td>60</td>\n",
       "      <td>Uff Yeh the first song from the Sonakshi Sinha...</td>\n",
       "      <td>Uff Yeh the first song from the Sonakshi Sinha...</td>\n",
       "      <td>SOS_TOKEN first song from Sonakshi Sinhas Noor...</td>\n",
       "      <td>SOS_TOKEN first song from Sonakshi Sinhas Noor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101870</th>\n",
       "      <td>102912</td>\n",
       "      <td>According to reports, a new version of the 199...</td>\n",
       "      <td>'The Matrix' film to get a reboot: Reports</td>\n",
       "      <td>332</td>\n",
       "      <td>42</td>\n",
       "      <td>accord to report a new version of the 1999 sci...</td>\n",
       "      <td>accord to report a new version of the 1999 sci...</td>\n",
       "      <td>SOS_TOKEN the Matrix film to get a reboot repo...</td>\n",
       "      <td>SOS_TOKEN the Matrix film to get a reboot repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101871</th>\n",
       "      <td>102913</td>\n",
       "      <td>A new music video shows rapper Snoop Dogg aimi...</td>\n",
       "      <td>Snoop Dogg aims gun at clown dressed as Trump ...</td>\n",
       "      <td>321</td>\n",
       "      <td>59</td>\n",
       "      <td>a new music video show rapper Snoop Dogg aim a...</td>\n",
       "      <td>a new music video show rapper Snoop Dogg aim a...</td>\n",
       "      <td>SOS_TOKEN Snoop Dogg aim gun at clown dress as...</td>\n",
       "      <td>SOS_TOKEN Snoop Dogg aim gun at clown dress as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101872</th>\n",
       "      <td>102914</td>\n",
       "      <td>Madhesi Morcha, an alliance of seven political...</td>\n",
       "      <td>Madhesi Morcha withdraws support to Nepalese g...</td>\n",
       "      <td>390</td>\n",
       "      <td>55</td>\n",
       "      <td>Madhesi Morcha an alliance of seven political ...</td>\n",
       "      <td>Madhesi Morcha an alliance of seven political ...</td>\n",
       "      <td>SOS_TOKEN Madhesi Morcha withdraw support to n...</td>\n",
       "      <td>SOS_TOKEN Madhesi Morcha withdraw support to n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101873 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  \\\n",
       "0                0  The Administration of Union Territory Daman an...   \n",
       "1                1  Malaika Arora slammed an Instagram user who tr...   \n",
       "2                2  The Indira Gandhi Institute of Medical Science...   \n",
       "3                3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
       "4                4  Hotels in Maharashtra will train their staff t...   \n",
       "5                5  A 32-year-old man on Wednesday was found hangi...   \n",
       "6                6  The Delhi High Court reduced the compensation ...   \n",
       "7                7  A 60-year old Dalit woman was allegedly lynche...   \n",
       "8                8  An inquiry by the Aircraft Accident Investigat...   \n",
       "9                9  The Congress party has opened a bank called 'S...   \n",
       "10              10  India's food regulator Food Safety and Standar...   \n",
       "11              11  The mother of Harshit Sharma, the class 12 Cha...   \n",
       "12              12  Municipal Corporation of Gurugram on Wednesday...   \n",
       "13              13  Scientists, for the first time, successfully f...   \n",
       "14              14  A Union Minister of State for Home Affairs inf...   \n",
       "15              15  The Supreme Court today refused to stay the ex...   \n",
       "16              16  Tanveer Hussain, a 24-year-old Indian athlete ...   \n",
       "17              17  Bomb squads and canine teams were rushed to ch...   \n",
       "18              18  Defending the IGIMS marital declaration form, ...   \n",
       "19              19  The members of a Norwegian anti-immigrant grou...   \n",
       "20              20  A newborn boy in Maharashtra's Thane was found...   \n",
       "21              21  The North Delhi Municipal Corporation has said...   \n",
       "22              22  Over 400 farmers from Greater Noida and adjoin...   \n",
       "23              23  Investigators have released pictures showing h...   \n",
       "24              24  Two sunbathers, a 56-year-old man and an eight...   \n",
       "25              25  The Saudi-led coalition in Yemen is blocking d...   \n",
       "26              26  The US Air Force on Wednesday successfully lau...   \n",
       "27              27  The remains of a German hiker, who disappeared...   \n",
       "28              28  Veteran actor Dilip Kumar has been admitted to...   \n",
       "29              29  The Mangrove Society of India has listed Mumba...   \n",
       "...            ...                                                ...   \n",
       "101843      102885  Bharatiya Janata Party on Wednesday dismissed ...   \n",
       "101844      102886  An armed fan, with his face covered by a black...   \n",
       "101845      102887  Two leopards escaped from Gopalpur Zoo in Hima...   \n",
       "101846      102888  The Karnataka government has capped the price ...   \n",
       "101847      102889  BJP's Biren Singh, who was sworn in as Manipur...   \n",
       "101848      102890  The Union Cabinet on Wednesday approved a 2% h...   \n",
       "101849      102891  A Facebook post by Stayzilla client Jig Saw's ...   \n",
       "101850      102892  Actor Akshay Kumar is set to star as Gulshan K...   \n",
       "101851      102893  Researchers have uncovered a Gmail phishing sc...   \n",
       "101852      102894  Patesh Talukdar from India holds the Guinness ...   \n",
       "101853      102895  New satellite images reportedly show that Chin...   \n",
       "101854      102896  Censor Board chief Pahlaj Nihalani has confirm...   \n",
       "101855      102897  Check Point Security has revealed a WhatsApp v...   \n",
       "101856      102898  A Czech zoo has said it will remove the horns ...   \n",
       "101857      102899  Ride-hailing startup Uber's main rival in Sout...   \n",
       "101858      102900  BSP supremo Mayawati has said that her party w...   \n",
       "101859      102901  A 19th-century book at a library in Harvard Un...   \n",
       "101860      102902  Amid reports claiming that BJP may appoint Hom...   \n",
       "101861      102903  Scott Marsden, a 14-year-old kickboxer from En...   \n",
       "101862      102904  One person was arrested in connection with the...   \n",
       "101863      102905  Retired US Navy Admiral Bruce Loveless and eig...   \n",
       "101864      102906  Dinesh Shivnath Upadhyaya from Mumbai is recog...   \n",
       "101865      102907  A Los Angeles-based startup has developed 'Paq...   \n",
       "101866      102908  The Enforcement Directorate has summoned Jammu...   \n",
       "101867      102909  Pakistan has started building a nearly 2,400-k...   \n",
       "101868      102910  A CRPF jawan was on Tuesday axed to death with...   \n",
       "101869      102911  'Uff Yeh', the first song from the Sonakshi Si...   \n",
       "101870      102912  According to reports, a new version of the 199...   \n",
       "101871      102913  A new music video shows rapper Snoop Dogg aimi...   \n",
       "101872      102914  Madhesi Morcha, an alliance of seven political...   \n",
       "\n",
       "                                                  summary  text_len  \\\n",
       "0       Daman & Diu revokes mandatory Rakshabandhan in...       358   \n",
       "1       Malaika slams user who trolled her for 'divorc...       361   \n",
       "2       'Virgin' now corrected to 'Unmarried' in IGIMS...       398   \n",
       "3       Aaj aapne pakad liya: LeT man Dujana before be...       368   \n",
       "4       Hotel staff to get training to spot signs of s...       366   \n",
       "5       Man found dead at Delhi police station, kin al...       347   \n",
       "6       Delhi HC reduces aid for 'negligent' accident ...       361   \n",
       "7       60-yr-old lynched over rumours she was cutting...       331   \n",
       "8       Chopper flying critically low led to 2015 Bomb...       370   \n",
       "9        Congress opens 'State Bank of Tomato' in Lucknow       311   \n",
       "10      Food regulator planning leftover banks to feed...       367   \n",
       "11      Call devastated his life: Mom of boy who got '...       336   \n",
       "12      19 Gurugram buildings to pay property tax over...       377   \n",
       "13      Human embryos edited to stop deadly disease fo...       365   \n",
       "14      Nearly 2,300 CPWD buildings in Delhi unsafe: U...       388   \n",
       "15      Gujarat Rajya Sabha polls to be held with NOTA...       302   \n",
       "16      Indian athlete indicted on sex abuse charge in US       324   \n",
       "17      Maruti spare parts trigger bomb scare at Delhi...       301   \n",
       "18      Virgin means unmarried, nothing offensive in i...       367   \n",
       "19      Bus seats mistaken for burqas by Norway anti-i...       359   \n",
       "20      Baby 'pregnant' with malformed twin born in Ma...       340   \n",
       "21      Delhi's AIIMS, Safdarjung to be declared no-ha...       366   \n",
       "22      Noida farmers demand release of arrested count...       389   \n",
       "23      Photo shows how close flight came to crashing ...       374   \n",
       "24      Sunbathers killed as plane hits them while lan...       342   \n",
       "25      Saudi-led coalition blocks fuel for UN aid pla...       384   \n",
       "26      US tests unarmed intercontinental ballistic mi...       393   \n",
       "27      German hiker found in Swiss Alps 30 yrs after ...       347   \n",
       "28       Veteran actor Dilip Kumar hospitalised in Mumbai       373   \n",
       "29      Mumbai has 2 out of 12 unique mangrove forests...       383   \n",
       "...                                                   ...       ...   \n",
       "101843  There are defects in you, not in EVMs: BJP to ...       381   \n",
       "101844  Video: Armed fan invades pitch to attack footb...       296   \n",
       "101845  Two leopards escape from a zoo in Himachal Pra...       382   \n",
       "101846  Karnataka caps movie ticket prices at Ă˘ÂÂš20...       376   \n",
       "101847  Biren Singh country's first CM to have been a ...       374   \n",
       "101848  Cabinet approves 2% Dearness Allowance hike fo...       382   \n",
       "101849  Stayzilla client enquired about Voodoo dolls o...       359   \n",
       "101850  Akshay to star as T-Series founder Gulshan Kum...       336   \n",
       "101851  Fake Gmail attachment scam fools users into te...       350   \n",
       "101852  Indian holds world record for eating a drinkin...       311   \n",
       "101853  New Chinese construction work spotted in South...       382   \n",
       "101854  Censor Board to go digital, confirms chief Pah...       356   \n",
       "101855  WhatsApp flaw to hijack accounts through image...       374   \n",
       "101856  Czech zoo to remove horns of 18 white rhinos a...       322   \n",
       "101857  Uber rival Grab to open research centre in Ben...       379   \n",
       "101858  BSP to observe black day each month over EVM t...       356   \n",
       "101859  A book at Harvard University is bound in human...       331   \n",
       "101860  Rajnath Singh dismisses reports that he will b...       341   \n",
       "101861  14-year-old kickboxer dies after unsanctioned ...       372   \n",
       "101862        Irish woman found dead in Goa, one arrested       302   \n",
       "101863  Retired US Navy Admiral arrested in sex for se...       382   \n",
       "101864  Indian has world record for most lit candles i...       318   \n",
       "101865  Startup makes Ă˘ÂÂš23,000 smart bag to freshe...       339   \n",
       "101866  Kashmiri separatist leaders summoned over mone...       376   \n",
       "101867  Pakistan starts building fence along Afghanist...       400   \n",
       "101868  CRPF jawan axed to death by Maoists in Chhatti...       360   \n",
       "101869  First song from Sonakshi Sinha's 'Noor' titled...       353   \n",
       "101870         'The Matrix' film to get a reboot: Reports       332   \n",
       "101871  Snoop Dogg aims gun at clown dressed as Trump ...       321   \n",
       "101872  Madhesi Morcha withdraws support to Nepalese g...       390   \n",
       "\n",
       "        summary_len                                      text_stripped  \\\n",
       "0                60  the Administration of Union Territory Daman an...   \n",
       "1                60  Malaika Arora slam an Instagram user who troll...   \n",
       "2                52  the Indira Gandhi Institute of Medical Science...   \n",
       "3                56  Lashkar e Taibas Kashmir commander Abu Dujana ...   \n",
       "4                60  hotel in Maharashtra will train -PRON- staff t...   \n",
       "5                60  a 32 year old man on Wednesday be find hang in...   \n",
       "6                59  the Delhi High Court reduce the compensation a...   \n",
       "7                60  a 60 year old Dalit woman be allegedly lynch i...   \n",
       "8                59  an inquiry by the Aircraft Accident Investigat...   \n",
       "9                48  the Congress party have open a bank call State...   \n",
       "10               60  Indias food regulator Food Safety and Standard...   \n",
       "11               59  the mother of Harshit Sharma the class 12 Chan...   \n",
       "12               59  Municipal Corporation of Gurugram on Wednesday...   \n",
       "13               60  scientist for the first time successfully free...   \n",
       "14               59  a Union Minister of State for Home Affairs inf...   \n",
       "15               57  the Supreme Court today refuse to stay the exe...   \n",
       "16               49  Tanveer Hussain a 24 year old indian athlete f...   \n",
       "17               54  bomb squad and canine team be rush to check a ...   \n",
       "18               57  defend the IGIMS marital declaration form Biha...   \n",
       "19               60  the member of a norwegian anti immigrant group...   \n",
       "20               55  a newborn boy in Maharashtras Thane be find to...   \n",
       "21               55  the North Delhi Municipal Corporation have say...   \n",
       "22               54  over 400 farmer from Greater Noida and adjoini...   \n",
       "23               59  investigator have release picture show how clo...   \n",
       "24               59  two sunbather a 56 year old man and an eight y...   \n",
       "25               58  the Saudi lead coalition in Yemen be block del...   \n",
       "26               51  the US Air Force on Wednesday successfully lau...   \n",
       "27               59  the remain of a german hiker who disappear whi...   \n",
       "28               48  veteran actor Dilip Kumar have be admit to Lil...   \n",
       "29               56  the Mangrove Society of India have list Mumbai...   \n",
       "...             ...                                                ...   \n",
       "101843           54  Bharatiya Janata Party on Wednesday dismiss BS...   \n",
       "101844           57  an armed fan with -PRON- face cover by a black...   \n",
       "101845           50  two leopard escape from Gopalpur Zoo in Himach...   \n",
       "101846           63  the Karnataka government have cap the price of...   \n",
       "101847           59  BJPs Biren Singh who be swear in as Manipurs C...   \n",
       "101848           58  the Union Cabinet on Wednesday approve a 2 % h...   \n",
       "101849           56  a facebook post by Stayzilla client Jig saw ow...   \n",
       "101850           59  Actor Akshay Kumar be set to star as Gulshan K...   \n",
       "101851           60  researcher have uncover a Gmail phishe scam wh...   \n",
       "101852           54  Patesh Talukdar from India hold the Guinness W...   \n",
       "101853           57  new satellite image reportedly show that China...   \n",
       "101854           58  Censor Board chief Pahlaj Nihalani have confir...   \n",
       "101855           56  check Point Security have reveal a WhatsApp vu...   \n",
       "101856           57  a Czech zoo have say -PRON- will remove the ho...   \n",
       "101857           52  ride hailing startup Ubers main rival in South...   \n",
       "101858           60  bsp supremo Mayawati have say that -PRON- part...   \n",
       "101859           51  a 19th century book at a library in Harvard Un...   \n",
       "101860           58  amid report claim that BJP may appoint Home Mi...   \n",
       "101861           56  Scott Marsden a 14 year old kickboxer from Eng...   \n",
       "101862           43  one person be arrest in connection with the mu...   \n",
       "101863           59  retire US Navy Admiral Bruce Loveless and eigh...   \n",
       "101864           53  Dinesh Shivnath Upadhyaya from Mumbai be recog...   \n",
       "101865           64  a Los Angeles base startup have develop paqsul...   \n",
       "101866           58  the Enforcement Directorate have summon Jammu ...   \n",
       "101867           55  Pakistan have start build a nearly 2400 kilome...   \n",
       "101868           51  a CRPF jawan be on Tuesday axe to death with s...   \n",
       "101869           60  Uff Yeh the first song from the Sonakshi Sinha...   \n",
       "101870           42  accord to report a new version of the 1999 sci...   \n",
       "101871           59  a new music video show rapper Snoop Dogg aim a...   \n",
       "101872           55  Madhesi Morcha an alliance of seven political ...   \n",
       "\n",
       "                                             text_cleaned  \\\n",
       "0       the Administration of Union Territory Daman an...   \n",
       "1       Malaika Arora slam an Instagram user who troll...   \n",
       "2       the Indira Gandhi Institute of Medical Science...   \n",
       "3       Lashkar e Taibas Kashmir commander Abu Dujana ...   \n",
       "4       hotel in Maharashtra will train -PRON- staff t...   \n",
       "5       a 32 year old man on Wednesday be find hang in...   \n",
       "6       the Delhi High Court reduce the compensation a...   \n",
       "7       a 60 year old Dalit woman be allegedly lynch i...   \n",
       "8       an inquiry by the Aircraft Accident Investigat...   \n",
       "9       the Congress party have open a bank call State...   \n",
       "10      Indias food regulator Food Safety and Standard...   \n",
       "11      the mother of Harshit Sharma the class 12 Chan...   \n",
       "12      Municipal Corporation of Gurugram on Wednesday...   \n",
       "13      scientist for the first time successfully free...   \n",
       "14      a Union Minister of State for Home Affairs inf...   \n",
       "15      the Supreme Court today refuse to stay the exe...   \n",
       "16      Tanveer Hussain a 24 year old indian athlete f...   \n",
       "17      bomb squad and canine team be rush to check a ...   \n",
       "18      defend the IGIMS marital declaration form Biha...   \n",
       "19      the member of a norwegian anti immigrant group...   \n",
       "20      a newborn boy in Maharashtras Thane be find to...   \n",
       "21      the North Delhi Municipal Corporation have say...   \n",
       "22      over 400 farmer from Greater Noida and adjoini...   \n",
       "23      investigator have release picture show how clo...   \n",
       "24      two sunbather a 56 year old man and an eight y...   \n",
       "25      the Saudi lead coalition in Yemen be block del...   \n",
       "26      the US Air Force on Wednesday successfully lau...   \n",
       "27      the remain of a german hiker who disappear whi...   \n",
       "28      veteran actor Dilip Kumar have be admit to Lil...   \n",
       "29      the Mangrove Society of India have list Mumbai...   \n",
       "...                                                   ...   \n",
       "101843  Bharatiya Janata Party on Wednesday dismiss BS...   \n",
       "101844  an armed fan with -PRON- face cover by a black...   \n",
       "101845  two leopard escape from Gopalpur Zoo in Himach...   \n",
       "101846  the Karnataka government have cap the price of...   \n",
       "101847  BJPs Biren Singh who be swear in as Manipurs C...   \n",
       "101848  the Union Cabinet on Wednesday approve a 2 % h...   \n",
       "101849  a facebook post by Stayzilla client Jig saw ow...   \n",
       "101850  Actor Akshay Kumar be set to star as Gulshan K...   \n",
       "101851  researcher have uncover a Gmail phishe scam wh...   \n",
       "101852  Patesh Talukdar from India hold the Guinness W...   \n",
       "101853  new satellite image reportedly show that China...   \n",
       "101854  Censor Board chief Pahlaj Nihalani have confir...   \n",
       "101855  check Point Security have reveal a WhatsApp vu...   \n",
       "101856  a Czech zoo have say -PRON- will remove the ho...   \n",
       "101857  ride hailing startup Ubers main rival in South...   \n",
       "101858  bsp supremo Mayawati have say that -PRON- part...   \n",
       "101859  a 19th century book at a library in Harvard Un...   \n",
       "101860  amid report claim that BJP may appoint Home Mi...   \n",
       "101861  Scott Marsden a 14 year old kickboxer from Eng...   \n",
       "101862  one person be arrest in connection with the mu...   \n",
       "101863  retire US Navy Admiral Bruce Loveless and eigh...   \n",
       "101864  Dinesh Shivnath Upadhyaya from Mumbai be recog...   \n",
       "101865  a Los Angeles base startup have develop paqsul...   \n",
       "101866  the Enforcement Directorate have summon Jammu ...   \n",
       "101867  Pakistan have start build a nearly 2400 kilome...   \n",
       "101868  a CRPF jawan be on Tuesday axe to death with s...   \n",
       "101869  Uff Yeh the first song from the Sonakshi Sinha...   \n",
       "101870  accord to report a new version of the 1999 sci...   \n",
       "101871  a new music video show rapper Snoop Dogg aim a...   \n",
       "101872  Madhesi Morcha an alliance of seven political ...   \n",
       "\n",
       "                                         summary_stripped  \\\n",
       "0       SOS_TOKEN Daman  Diu revoke mandatory Rakshaba...   \n",
       "1       SOS_TOKEN Malaika slam user who troll -PRON- f...   \n",
       "2       SOS_TOKEN Virgin now correct to Unmarried in I...   \n",
       "3       SOS_TOKEN Aaj aapne pakad liya LeT man Dujana ...   \n",
       "4       SOS_TOKEN hotel staff to get training to spot ...   \n",
       "5       SOS_TOKEN man find dead at Delhi police statio...   \n",
       "6       SOS_TOKEN Delhi HC reduce aid for negligent ac...   \n",
       "7       SOS_TOKEN 60 yr old lynch over rumour -PRON- b...   \n",
       "8       SOS_TOKEN chopper fly critically low lead to 2...   \n",
       "9       SOS_TOKEN Congress open State Bank of Tomato i...   \n",
       "10      SOS_TOKEN food regulator planning leftover ban...   \n",
       "11      SOS_TOKEN call devastate -PRON- life Mom of bo...   \n",
       "12      SOS_TOKEN 19 Gurugram building to pay property...   \n",
       "13      SOS_TOKEN human embryo edit to stop deadly dis...   \n",
       "14      SOS_TOKEN nearly 2300 CPWD building in Delhi u...   \n",
       "15      SOS_TOKEN Gujarat Rajya Sabha poll to be hold ...   \n",
       "16      SOS_TOKEN indian athlete indict on sex abuse c...   \n",
       "17      SOS_TOKEN Maruti spare part trigger bomb scare...   \n",
       "18      SOS_TOKEN Virgin mean unmarrie nothing offensi...   \n",
       "19      SOS_TOKEN bus seat mistake for burqas by Norwa...   \n",
       "20      SOS_TOKEN baby pregnant with malformed twin be...   \n",
       "21      SOS_TOKEN Delhis AIIMS Safdarjung to be declar...   \n",
       "22      SOS_TOKEN Noida farmer demand release of arres...   \n",
       "23      SOS_TOKEN photo show how close flight come to ...   \n",
       "24      SOS_TOKEN sunbather kill as plane hit -PRON- w...   \n",
       "25      SOS_TOKEN Saudi lead coalition block fuel for ...   \n",
       "26      SOS_TOKEN US test unarmed intercontinental bal...   \n",
       "27      SOS_TOKEN german hiker find in Swiss Alps 30 y...   \n",
       "28      SOS_TOKEN veteran actor Dilip Kumar hospitalis...   \n",
       "29      SOS_TOKEN Mumbai have 2 out of 12 unique mangr...   \n",
       "...                                                   ...   \n",
       "101843  SOS_TOKEN there be defect in -PRON- not in evm...   \n",
       "101844  SOS_TOKEN Video Armed fan invades pitch to att...   \n",
       "101845  SOS_TOKEN two leopard escape from a zoo in Him...   \n",
       "101846  SOS_TOKEN Karnataka cap movie ticket price at ...   \n",
       "101847  SOS_TOKEN Biren Singh country first CM to have...   \n",
       "101848  SOS_TOKEN Cabinet approve 2 % Dearness Allowan...   \n",
       "101849  SOS_TOKEN stayzilla client enquire about voodo...   \n",
       "101850  SOS_TOKEN akshay to star as T Series founder G...   \n",
       "101851  SOS_TOKEN fake Gmail attachment scam fool user...   \n",
       "101852  SOS_TOKEN Indian hold world record for eat a d...   \n",
       "101853  SOS_TOKEN new chinese construction work spot i...   \n",
       "101854  SOS_TOKEN Censor Board to go digital confirm c...   \n",
       "101855  SOS_TOKEN WhatsApp flaw to hijack account thro...   \n",
       "101856  SOS_TOKEN czech zoo to remove horn of 18 white...   \n",
       "101857  SOS_TOKEN Uber rival Grab to open research cen...   \n",
       "101858  SOS_TOKEN bsp to observe black day each month ...   \n",
       "101859  SOS_TOKEN a book at Harvard University be bind...   \n",
       "101860  SOS_TOKEN Rajnath Singh dismiss report that -P...   \n",
       "101861  SOS_TOKEN 14 year old kickboxer die after unsa...   \n",
       "101862  SOS_TOKEN irish woman find dead in Goa one arr...   \n",
       "101863  SOS_TOKEN retire US Navy Admiral arrest in sex...   \n",
       "101864  SOS_TOKEN Indian have world record for most li...   \n",
       "101865  SOS_TOKEN startup make Ă˘ÂÂš23000 smart bag t...   \n",
       "101866  SOS_TOKEN Kashmiri separatist leader summon ov...   \n",
       "101867  SOS_TOKEN Pakistan start building fence along ...   \n",
       "101868  SOS_TOKEN CRPF jawan axe to death by Maoists i...   \n",
       "101869  SOS_TOKEN first song from Sonakshi Sinhas Noor...   \n",
       "101870  SOS_TOKEN the Matrix film to get a reboot repo...   \n",
       "101871  SOS_TOKEN Snoop Dogg aim gun at clown dress as...   \n",
       "101872  SOS_TOKEN Madhesi Morcha withdraw support to n...   \n",
       "\n",
       "                                          summary_cleaned  \n",
       "0       SOS_TOKEN Daman  Diu revoke mandatory Rakshaba...  \n",
       "1       SOS_TOKEN Malaika slam user who troll -PRON- f...  \n",
       "2       SOS_TOKEN Virgin now correct to Unmarried in I...  \n",
       "3       SOS_TOKEN Aaj aapne pakad liya LeT man Dujana ...  \n",
       "4       SOS_TOKEN hotel staff to get training to spot ...  \n",
       "5       SOS_TOKEN man find dead at Delhi police statio...  \n",
       "6       SOS_TOKEN Delhi HC reduce aid for negligent ac...  \n",
       "7       SOS_TOKEN 60 yr old lynch over rumour -PRON- b...  \n",
       "8       SOS_TOKEN chopper fly critically low lead to 2...  \n",
       "9       SOS_TOKEN Congress open State Bank of Tomato i...  \n",
       "10      SOS_TOKEN food regulator planning leftover ban...  \n",
       "11      SOS_TOKEN call devastate -PRON- life Mom of bo...  \n",
       "12      SOS_TOKEN 19 Gurugram building to pay property...  \n",
       "13      SOS_TOKEN human embryo edit to stop deadly dis...  \n",
       "14      SOS_TOKEN nearly 2300 CPWD building in Delhi u...  \n",
       "15      SOS_TOKEN Gujarat Rajya Sabha poll to be hold ...  \n",
       "16      SOS_TOKEN indian athlete indict on sex abuse c...  \n",
       "17      SOS_TOKEN Maruti spare part trigger bomb scare...  \n",
       "18      SOS_TOKEN Virgin mean unmarrie nothing offensi...  \n",
       "19      SOS_TOKEN bus seat mistake for burqas by Norwa...  \n",
       "20      SOS_TOKEN baby pregnant with malformed twin be...  \n",
       "21      SOS_TOKEN Delhis AIIMS Safdarjung to be declar...  \n",
       "22      SOS_TOKEN Noida farmer demand release of arres...  \n",
       "23      SOS_TOKEN photo show how close flight come to ...  \n",
       "24      SOS_TOKEN sunbather kill as plane hit -PRON- w...  \n",
       "25      SOS_TOKEN Saudi lead coalition block fuel for ...  \n",
       "26      SOS_TOKEN US test unarmed intercontinental bal...  \n",
       "27      SOS_TOKEN german hiker find in Swiss Alps 30 y...  \n",
       "28      SOS_TOKEN veteran actor Dilip Kumar hospitalis...  \n",
       "29      SOS_TOKEN Mumbai have 2 out of 12 unique mangr...  \n",
       "...                                                   ...  \n",
       "101843  SOS_TOKEN there be defect in -PRON- not in evm...  \n",
       "101844  SOS_TOKEN Video Armed fan invades pitch to att...  \n",
       "101845  SOS_TOKEN two leopard escape from a zoo in Him...  \n",
       "101846  SOS_TOKEN Karnataka cap movie ticket price at ...  \n",
       "101847  SOS_TOKEN Biren Singh country first CM to have...  \n",
       "101848  SOS_TOKEN Cabinet approve 2 % Dearness Allowan...  \n",
       "101849  SOS_TOKEN stayzilla client enquire about voodo...  \n",
       "101850  SOS_TOKEN akshay to star as T Series founder G...  \n",
       "101851  SOS_TOKEN fake Gmail attachment scam fool user...  \n",
       "101852  SOS_TOKEN Indian hold world record for eat a d...  \n",
       "101853  SOS_TOKEN new chinese construction work spot i...  \n",
       "101854  SOS_TOKEN Censor Board to go digital confirm c...  \n",
       "101855  SOS_TOKEN WhatsApp flaw to hijack account thro...  \n",
       "101856  SOS_TOKEN czech zoo to remove horn of 18 white...  \n",
       "101857  SOS_TOKEN Uber rival Grab to open research cen...  \n",
       "101858  SOS_TOKEN bsp to observe black day each month ...  \n",
       "101859  SOS_TOKEN a book at Harvard University be bind...  \n",
       "101860  SOS_TOKEN Rajnath Singh dismiss report that -P...  \n",
       "101861  SOS_TOKEN 14 year old kickboxer die after unsa...  \n",
       "101862  SOS_TOKEN irish woman find dead in Goa one arr...  \n",
       "101863  SOS_TOKEN retire US Navy Admiral arrest in sex...  \n",
       "101864  SOS_TOKEN Indian have world record for most li...  \n",
       "101865  SOS_TOKEN startup make Ă˘ÂÂš23000 smart bag t...  \n",
       "101866  SOS_TOKEN Kashmiri separatist leader summon ov...  \n",
       "101867  SOS_TOKEN Pakistan start building fence along ...  \n",
       "101868  SOS_TOKEN CRPF jawan axe to death by Maoists i...  \n",
       "101869  SOS_TOKEN first song from Sonakshi Sinhas Noor...  \n",
       "101870  SOS_TOKEN the Matrix film to get a reboot repo...  \n",
       "101871  SOS_TOKEN Snoop Dogg aim gun at clown dress as...  \n",
       "101872  SOS_TOKEN Madhesi Morcha withdraw support to n...  \n",
       "\n",
       "[101873 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23268eec3373425f8c9a6a80b63e4098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101873), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "most_common_words = Counter()\n",
    "for sent in tqdm_notebook(raw_data.text_cleaned):\n",
    "    most_common_words.update(sent.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101766, ['the', '-PRON-', 'be', 'to', 'a', 'in', 'of', 'and', 'have', '.'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_words = sorted(most_common_words, key=most_common_words.get, reverse=True)\n",
    "len(most_common_words), most_common_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((71311, 9), (30562, 9))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(raw_data, test_size=0.3, random_state=9)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "UNK_TOKEN = 1\n",
    "START_TOKEN = 2\n",
    "END_TOKEN = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, max_length=100, max_summary_length=25, word2idx=None, idx2word=None, max_vocab_size=50000):\n",
    "        self.data = data\n",
    "        self.max_length = max_length\n",
    "        self.max_summary_length = max_summary_length\n",
    "        if word2idx is None:\n",
    "            self.words_counter = self.make_words_counter()\n",
    "            self.word2idx, self.idx2word = self.make_vocab(self.words_counter, max_vocab_size)\n",
    "        else:\n",
    "            self.word2idx = word2idx\n",
    "            self.idx2word = idx2word\n",
    "        print('Dataset info:')\n",
    "        print(f'Number of Tweets: {self.data.shape[0]}')\n",
    "        print(f'Vocab Size: {len(self.word2idx)}')\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        text = self.data.text_stripped[index]\n",
    "        summary = self.data.summary_stripped[index]\n",
    "        x = self.get_vector(text)\n",
    "        padded_x, len_x = self.pad_data(x, self.max_length)\n",
    "        y = self.get_vector(summary)\n",
    "        padded_y, len_y = self.pad_data(y, self.max_summary_length)\n",
    "        return padded_x, padded_y, len_x, len_y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get_vector(self, text):\n",
    "#         if type(text) is str:\n",
    "        return [\n",
    "            self.word2idx.get(token, UNK_TOKEN) for token in spacy_strip(text).split(' ')\n",
    "        ]\n",
    "#         elif type(text) is pd.Series:\n",
    "#             for row in text\n",
    "            \n",
    "            \n",
    "    \n",
    "    def make_vocab(self, words_counter, max_vocab_size):\n",
    "        word2idx = {\n",
    "            '<PAD>': PAD_TOKEN,\n",
    "            '<UNK>': UNK_TOKEN,\n",
    "            'SOS_TOKEN': START_TOKEN,\n",
    "            'EOS_TOKEN': END_TOKEN,\n",
    "        }\n",
    "        word2idx.update({\n",
    "            word: i+4 for i, (word, count) in tqdm_notebook(\n",
    "                enumerate(words_counter.most_common(max_vocab_size))\n",
    "            )\n",
    "        })\n",
    "        idx2word = {\n",
    "            idx: word for word, idx in tqdm_notebook(word2idx.items())\n",
    "        }\n",
    "        return word2idx, idx2word\n",
    "    \n",
    "    def make_words_counter(self):\n",
    "        words_counter = Counter()\n",
    "        for sent in tqdm_notebook(self.data.text_cleaned):\n",
    "            words_counter.update(sent.split(' '))\n",
    "        return words_counter\n",
    "    \n",
    "    def pad_data(self, x, max_length):\n",
    "        padded_x = np.zeros((max_length,), dtype=np.int64)\n",
    "        if len(x) > max_length:\n",
    "            padded_x[:] = x[:max_length]\n",
    "        else:\n",
    "            padded_x[:len(x)] = x\n",
    "        return padded_x, len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_text_words = max(raw_data.text_stripped.apply(lambda x: len(x.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_summary_words = max(train_df.summary_stripped.apply(lambda x: len(x.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c147a2dc1724910b7aafc07868650df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=71311), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433db7f5ea78468990a34dae6aef93f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2037bef9725430aaa832b23c5e15911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=85411), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset info:\n",
      "Number of Tweets: 71311\n",
      "Vocab Size: 85411\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TextDataset(train_df, max_length=max_text_words, max_summary_length=max_summary_words, max_vocab_size=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69a0f171e624f819be8b085d68bc98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30562), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d20544d76042ad80e8c929a20cdd01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f59a63d4c2422d818ac9150841d235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50004), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset info:\n",
      "Number of Tweets: 30562\n",
      "Vocab Size: 50004\n"
     ]
    }
   ],
   "source": [
    "val_dataset = TextDataset(val_df, max_length=max_text_words, max_summary_length=max_summary_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85411"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size = len(train_dataset.idx2word)\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check single text + text_indices + summary + summary_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_text_from_sequence(sequence):\n",
    "    text = \"\"\n",
    "    for element in sequence:\n",
    "        if type(element) is torch.Tensor:\n",
    "            text += train_dataset.idx2word[element.item()] + ' '\n",
    "        else:\n",
    "            text += train_dataset.idx2word[element] + ' '\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_from_text(text, verbose=False):\n",
    "    indices = []\n",
    "    for word in spacy_strip(text).split(' '):\n",
    "        if word == 'SOS_TOKEN' or '<START>':\n",
    "            indices.append(START_TOKEN)\n",
    "        elif word == 'EOS_TOKEN' or '<END>':\n",
    "            indices.append(END_TOKEN)\n",
    "        elif word == '<PAD>':\n",
    "            indices.append(PAD_TOKEN)\n",
    "        elif word == '<UNK>':\n",
    "            indices.append(UNK_TOKEN)\n",
    "        elif verbose:\n",
    "            indices.append((train_dataset.word2idx[word], word))\n",
    "        else: \n",
    "            indices.append(train_dataset.word2idx[word])\n",
    "    return indices + [END_TOKEN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(dataset=val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 127])\n"
     ]
    }
   ],
   "source": [
    "for batch_id, (text, summary, text_length, summary_length) in enumerate(train_data_loader):\n",
    "    print(text.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_batch():\n",
    "    batch_data = next(iter(train_data_loader))\n",
    "    texts, summaries, text_length, summary_length = batch_data\n",
    "    return texts, summaries, text_length, summary_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1123,   641,   169,    14,  1182,   317,  2201,     9,   650,    20,\n",
       "              8,  2490,  2740,   596,   960,   218,    52,  1945,  1883,    14,\n",
       "            133,    15,   614,     6,     4,   100,    25,   603,     4,  1115,\n",
       "            100,   371,    50,     6,  2490,   121,     1,   121,    28,    10,\n",
       "           1663,   107,     6,  8071,   728,     4,   564,    69,     4,    47,\n",
       "              6,  3606,   121,     1,   121,     6,    34,  3606,    13,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [   36,   277,   842,  9061,  7981,    12,   143,  3089,    68,  2660,\n",
       "           2399,   246,   121,     1,   121,     1,   121,     6,  1993,    10,\n",
       "            121,     1,   121,    21,     4,   329,    30,  1065,     4,   857,\n",
       "             60,  1286,  1989,   842,    76,    82,  1662,  1291,  7981,    28,\n",
       "           2660,   246,   121,     1,   121,    17,     4,  1910,     6,    25,\n",
       "           9167,    23,   121,     1,   121,     1,   121,    35,   319,   121,\n",
       "              1,   121,     6,  9167,    23,   121,     1,   121,   289,   121,\n",
       "              1,   121,   160,    25,   246,   234,     6,    91,    14,   121,\n",
       "              1,   121,    28,    13,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [24549, 24406,  2707,  1594,  3954,  2305,    12,   143,   121,     1,\n",
       "            121,  1279,    22,  4264,  5420,  2193,     7,   170,    68,     8,\n",
       "            825,  3708,   423,  2305,     8,    77,   358,   833,   646,  9941,\n",
       "           9848,     9,  5493,  2155,    15,   121,     1,   121,     6,  7691,\n",
       "             10,    76,  3559,    11,  1615,   140,    14,     4,   872,    19,\n",
       "           1981,   121,     1,   121,    28,   121,     1,   121,     6,  1279,\n",
       "            183,   121,     1,   121,     6,    34,  3892,    44,   121,     1,\n",
       "            121,   875,    13,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [  103,    10,  2082, 24574,   247, 13238,    17,   223,     7,   276,\n",
       "            497,  2342,   628,    14,   132,  1219,    10,  3620,     9,   231,\n",
       "           2342,   628,     4,   103,    56,    17,    38, 19230,   160,     6,\n",
       "            276,    22,   121,     1,   121,   365,   121,     1,   121,   969,\n",
       "              6,    25,     6,   231,  2003,  2082,   811,  1444,    15,     4,\n",
       "            155,   152,   187,     6,  1938,    16,    69,   103,    47,     6,\n",
       "            666,    43,     4,   328,    13,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [   66,   813,   102,   956,    71,    10,  1446,   338,   675,    21,\n",
       "            258,  1036,   219,     7,  6542,     9,   121,     1,   121,    78,\n",
       "            800,  1299,   130,    14,   131, 26044,  5830,  2748,   250,     4,\n",
       "            119,   732,    18,  2036,     8,  1288,     9,     4, 20172,   414,\n",
       "             33,   122,   121,     1,   121,   799,  1446,   338,    12,   956,\n",
       "             71,     9,     4,    41,   464,     9,   121,     1,   121,    78,\n",
       "             46,  1221,  3333,    11,  1179,    20,   267,    13,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [    8,   620,   141,  4173,  4928,    12,     6,   129,    16,   116,\n",
       "            300,     8,    67,  2136,    16,     8,    27,     9, 53963,     4,\n",
       "            272,   176,    58,    15,   480,     4,    93,    12, 54365,     4,\n",
       "             67,    78,    27,    11,   209,     4,   564,   121,     1,   121,\n",
       "            116,    59,     4,   115,     7,  4745,     4,   400,    11,   647,\n",
       "              7,  2641,   121,     1,   121,    14,   296,   213,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0]]),\n",
       " tensor([[    2,   100,   371,    50,  2490,  1945,    21,   169,    14,  2201,\n",
       "              3,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    2,  2660,   246,   121,     1,   121,     1,   121,     6,  1993,\n",
       "             10,   121,     1,   121,  7981,    14,    36,   277,   988],\n",
       "         [    2, 81985,  1594,  1279,     7,    76,    94,  8287,   423,     3,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    1,   103,    10,   401, 13238,  1219,    10,  3620,     9,   231,\n",
       "           2342,     3,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [    2,    33,   956,    71,    10,  1446,   338,    21,  6542,   250,\n",
       "          20172, 18331,  1288,     3,     0,     0,     0,     0,     0],\n",
       "         [    2,  1624,   620,   300,    67,    16,    27,    59,   115,     7,\n",
       "           4745,   121,     1,   121,     3,     0,     0,     0,     0]]),\n",
       " tensor([59, 84, 73, 65, 68, 58]),\n",
       " tensor([11, 20, 10, 12, 14, 15]))"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_texts, batch_summaries, text_length, summary_length = get_random_batch()\n",
    "batch_texts, batch_summaries, text_length, summary_length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'describe recent attack on Hindi speak migrant in Gujarat as a dangerous trend West Bengal Chief Minister Mamata Banerjee on Tuesday say why be the BJP not control the situation BJP rule state be dangerous  <UNK>  add of course there be provocation behind the act all the people be scare  <UNK>  be also scare . <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> '"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_text_from_sequence(batch_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SOS_TOKEN BJP rule state dangerous Mamata after attack on migrant EOS_TOKEN <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> '"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_text_from_sequence(batch_summaries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, batch_size=128, n_layers=1, num_directions=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.num_directions = num_directions\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.rnn = nn.GRU(self.embedding_size, self.hidden_size, num_layers=n_layers, dropout=self.dropout, \n",
    "                          bidirectional=True if self.num_directions > 1 else False)\n",
    "        \n",
    "    def forward(self, sequence, sequence_lengths, hidden=None):\n",
    "        hidden = self.init_hidden()\n",
    "        embedding_output = self.embedding(sequence) # max_text_len x batch_size x embedding_size\n",
    "        embedding_output = nn.utils.rnn.pack_padded_sequence(embedding_output, sequence_lengths, enforce_sorted=False)\n",
    "        encoder_output, hidden = self.rnn(embedding_output, hidden)\n",
    "        encoder_output, output_lengths = nn.utils.rnn.pad_packed_sequence(encoder_output)\n",
    "        # hidden: bidirectional x batch_size x hidden_size\n",
    "        # output: max_text_len x batch_size x bidirectional * hidden_size\n",
    "\n",
    "        encoder_output = encoder_output[:, :, :self.hidden_size] + encoder_output[:, :, self.hidden_size:]\n",
    "        # output: max_text_len x batch_size x hidden_size\n",
    "        return encoder_output, hidden\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1 * self.num_directions, self.batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'concat':\n",
    "            self.attention = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(1, self.hidden_size))\n",
    "            \n",
    "    def forward(self, hidden, encoder_output):\n",
    "        length = encoder_output.size(0)\n",
    "        current_batch_size = encoder_output.size(1)\n",
    "        attention_energy = torch.zeros(current_batch_size, length) # batch_size x max_text_length\n",
    "        \n",
    "        for b in range(current_batch_size):\n",
    "            for i in range(length):\n",
    "                attention_energy[b, i] = self.score(hidden[:, b], encoder_output[i, b].unsqueeze(0))\n",
    "        \n",
    "        return F.softmax(attention_energy).unsqueeze(1)\n",
    "        \n",
    "    def score(self, hidden, encoder_output):\n",
    "        if self.method == 'concat':\n",
    "            energy = self.attention(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = self.v.dot(energy)\n",
    "            return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, embedding_size, hidden_size, batch_size=128, n_layers=1, num_directions=1, dropout=0.1):\n",
    "        super(AttentionDecoderRNN, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.num_directions = num_directions\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_size, self.embedding_size)\n",
    "        self.encoder_dropout = nn.Dropout(self.dropout)\n",
    "#         self.attention = Attention('concat', self.hidden_size)\n",
    "        self.rnn = nn.GRU(self.embedding_size, self.hidden_size, num_layers=self.n_layers, dropout=self.dropout)\n",
    "        self.output = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.encoder_output = nn.Linear(self.hidden_size * self.num_directions, self.embedding_size)\n",
    "        \n",
    "    def forward(self, sequence, hidden, encoder_output):\n",
    "        embedding_output = self.embedding(sequence).view(1, sequence.size(0), -1) \n",
    "        # n_layers x batch_size x embedding_size\n",
    "        dropout_output = self.encoder_dropout(embedding_output) # n_layers x batch_size x hidden_size\n",
    "        # hidden: 1 x batch_size x hidden_size\n",
    "        \n",
    "#         attention_weights = self.attention(hidden[-1], encoder_output)\n",
    "#         context = attention_weights.bmm(encoder_output.transpose(0, 1)) # batch_size x 1 x hidden_size\n",
    "#         context = context.transpose(0, 1) # 1 x batch_size x hidden_size\n",
    "        \n",
    "#         rnn_input = torch.cat((dropout_output, context), 2)\n",
    "        decoder_output, hidden = self.rnn(dropout_output, hidden) # n_layers x batch_size x hidden_size\n",
    "\n",
    "        decoder_output = decoder_output.squeeze(0) # output: batch_size x hidden_size\n",
    "#         decoder_output = F.log_softmax(self.output(torch.cat((decoder_output, context), 1)))\n",
    "        decoder_output = F.log_softmax(self.output(decoder_output))\n",
    "        return decoder_output, hidden #, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 5\n",
    "embedding_size = 4\n",
    "layers_number = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_test = EncoderRNN(vocabulary_size, embedding_size, hidden_size, batch_size=batch_size, num_directions=2, n_layers=layers_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_test = AttentionDecoderRNN(vocabulary_size, embedding_size, hidden_size, batch_size=batch_size, n_layers=layers_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(85411, 4)\n",
      "  (rnn): GRU(4, 5, dropout=0.1, bidirectional=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(encoder_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentionDecoderRNN(\n",
      "  (embedding): Embedding(85411, 4)\n",
      "  (encoder_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (rnn): GRU(4, 5, dropout=0.1)\n",
      "  (output): Linear(in_features=5, out_features=85411, bias=True)\n",
      "  (encoder_output): Linear(in_features=5, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(decoder_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch():\n",
    "    batch_data = next(iter(train_data_loader))\n",
    "    xs, ys, xs_length, ys_lengths = batch_data\n",
    "    xs = xs.transpose(0, 1)\n",
    "    ys = ys.transpose(0, 1)\n",
    "    return xs, ys, xs_length, ys_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xs, ys, xs_length, ys_lengths = random_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([127, 64])"
      ]
     },
     "execution_count": 1049,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape # max_text_len x batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 64])"
      ]
     },
     "execution_count": 1050,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.shape # max_summary_len x batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 5])"
      ]
     },
     "execution_count": 1051,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = encoder_test.init_hidden()\n",
    "hidden.shape # bidirectional x batch_size x hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_output, encoder_hidden = encoder_test(xs, xs_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENC outputs torch.Size([89, 64, 5])\n",
      "ENC hidden torch.Size([2, 64, 5])\n"
     ]
    }
   ],
   "source": [
    "print('ENC outputs', encoder_output.size()) # max_text_len x batch_size x hidden_size\n",
    "print('ENC hidden', encoder_hidden.size()) # n_layers(1) * bidirectional x batch_size x hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 1054,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input = Variable(torch.LongTensor([START_TOKEN] * batch_size)) # START_TOKEN x batch_size\n",
    "decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_hidden = encoder_hidden[:decoder_test.n_layers] # last forward hidden state from encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 64, 85411])"
      ]
     },
     "execution_count": 1056,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outputs = Variable(torch.zeros(max_summary_words, batch_size, decoder_test.output_size))\n",
    "all_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 1057,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((torch.zeros(64), torch.zeros(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "decoder_output, decoder_hidden = decoder_test(\n",
    "    decoder_input,\n",
    "    decoder_hidden,\n",
    "    encoder_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "for t in range(max_summary_words):\n",
    "    decoder_output, decoder_hidden = decoder_test(\n",
    "        decoder_input,\n",
    "        decoder_hidden,\n",
    "        encoder_output\n",
    "    )\n",
    "    all_outputs[t] = decoder_output\n",
    "    decoder_input = ys[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 64, 85411])"
      ]
     },
     "execution_count": 1060,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outputs.contiguous().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 64])"
      ]
     },
     "execution_count": 1061,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.contiguous().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss - 1st method\n",
    "* decoder_outputs: max_target_len x vocab_size x batch_size\n",
    "* targets: max_target_len x batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 85411, 64])"
      ]
     },
     "execution_count": 1062,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outputs.contiguous().view(-1, vocabulary_size, batch_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 64])"
      ]
     },
     "execution_count": 1063,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.contiguous().view(-1, batch_size).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss - 2nd method \n",
    "* decoder_outputs: max_target_len * batch_size x vocab_size\n",
    "* targets: max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1216, 85411])"
      ]
     },
     "execution_count": 1064,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outputs.contiguous().view(-1, vocabulary_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1216])"
      ]
     },
     "execution_count": 1065,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.contiguous().view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn(all_outputs.contiguous().view(-1, vocabulary_size), ys.contiguous().view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(all_outputs.contiguous().view(-1, vocabulary_size, batch_size), ys.contiguous().view(-1, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.4131)"
      ]
     },
     "execution_count": 1069,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOS_TOKEN pet dog fight off two leopard to save woman in Mumbai EOS_TOKEN <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "<UNK> PM Narendra Modi hollow man do nothing for nation Naidu EOS_TOKEN <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "SOS_TOKEN relieve to have quit international cricket AB de Villiers EOS_TOKEN <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "SOS_TOKEN Man enter Delhi airport use fake ticket to see family off EOS_TOKEN <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "SOS_TOKEN Obama surprise kid at childrens hospital dress as Santa Claus EOS_TOKEN <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "SOS_TOKEN Vidya Balan to portray Indira Gandhi in upcoming project EOS_TOKEN <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n"
     ]
    }
   ],
   "source": [
    "for target_summary in ys.transpose(0, 1):\n",
    "    print(decode_text_from_sequence(target_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_summary = all_outputs.transpose(0, 1).max(axis=2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trexo Trexo hose hose hose hose iMacs Omnipresent Omnipresent Omnipresent 287400 iMacs iMacs iMacs iMacs iMacs iMacs iMacs iMacs \n",
      "suspiciously suspiciously suspiciously hose hose hose hose radioheadi iMacs hose iMacs paw 287400 Taigan iMacs iMacs iMacs iMacs iMacs \n",
      "glossary hose hose hose hose iMacs iMacs iMacs iMacs iMacs paw 287400 iMacs iMacs iMacs hose iMacs iMacs iMacs \n",
      "Trexo Trexo Tuberculosis gstn iMacs iMacs iMacs iMacs iMacs iMacs iMacs hose hose hose hose iMacs hose iMacs iMacs \n",
      "Trexo Trexo hose hose iMacs iMacs iMacs iMacs 287400 iMacs 287400 287400 Sivakumar Taigan iMacs iMacs iMacs iMacs iMacs \n",
      "Trexo hose hose hose iMacs Eros Omnipresent Omnipresent Omnipresent Sivakumar Housing Tuberculosis Cowboys iMacs iMacs iMacs iMacs iMacs iMacs \n"
     ]
    }
   ],
   "source": [
    "for summ in output_summary:\n",
    "    print(decode_text_from_sequence(summ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    epoch,\n",
    "    train_data_loader, \n",
    "    encoder, decoder, \n",
    "    encoder_optimizer, decoder_optimizer, \n",
    "    criterion, \n",
    "    max_text_length, max_summary_length,\n",
    "    grad_clip=20.0,\n",
    "):\n",
    "    total_loss = 0\n",
    "    enc_a = 0\n",
    "    dec_a = 0\n",
    "    for batch_idx, (data, target, data_lengths, target_lengths) in tqdm_notebook(enumerate(train_data_loader), total=len(train_data_loader)):\n",
    "        encoder_hidden = encoder.init_hidden()\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        loss = 0\n",
    "        data = data.transpose(0, 1)\n",
    "        target = target.transpose(0, 1)\n",
    "\n",
    "        encoder_output, encoder_hidden = encoder(data, data_lengths)\n",
    "        decoder_input = Variable(torch.LongTensor([START_TOKEN] * encoder.batch_size))\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "        all_decoder_outputs = Variable(torch.zeros(max_summary_words, decoder.batch_size, decoder.output_size))\n",
    "\n",
    "        for t in range(max_summary_words):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input,\n",
    "                decoder_hidden,\n",
    "                encoder_output,\n",
    "            )\n",
    "            all_decoder_outputs[t] = decoder_output\n",
    "            decoder_input = target[t]\n",
    "\n",
    "        loss = criterion(\n",
    "            all_decoder_outputs.contiguous()[1:].view(-1, vocabulary_size), \n",
    "            target.contiguous()[1:].view(-1),\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        enc = nn.utils.clip_grad_norm_(encoder.parameters(), grad_clip)\n",
    "        dec = nn.utils.clip_grad_norm_(decoder.parameters(), grad_clip)\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss\n",
    "        enc_a += enc\n",
    "        dec_a += dec\n",
    "        if batch_id % 10 == 0:\n",
    "            print(f'Loss {loss}, Total loss / batches: {total_loss / (batch_idx + 1)}, Enc_a {enc_a}, Dec_a {dec_a}, Epoch {epoch}, Batch {batch_idx + 1}')\n",
    "    return total_loss.data, enc, dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inputs, max_text_length=127, max_summary_length=19):\n",
    "    if type(inputs) is torch.Tensor:\n",
    "        input_lengths = [len(inputs)]\n",
    "        inputs_seq = [inputs]\n",
    "        input_batch = inputs.unsqueeze(1)\n",
    "    else:\n",
    "        input_lengths = [len(inputs.split(' '))]\n",
    "        inputs_seq = [indices_from_text(inputs)]\n",
    "        input_batch = torch.LongTensor(inputs_seq).transpose(0, 1)\n",
    "    with torch.no_grad():\n",
    "        encoder_output, encoder_hidden = encoder(input_batch, input_lengths, None)\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([START_TOKEN]), volatile=True)\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "        decoded_words = ['SOS_TOKEN']\n",
    "    #     decoder_attentions = torch.zeros(max_summary_length + 1, max_text_length + 1)\n",
    "\n",
    "        for t in range(max_summary_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input,\n",
    "                decoder_hidden,\n",
    "                encoder_output,\n",
    "            )\n",
    "            top_value, top_index = decoder_output.data.topk(1)\n",
    "            token = top_index[0][0]\n",
    "            print(token)\n",
    "            if token == END_TOKEN:\n",
    "                decoded_words.append('EOS_TOKEN')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(decode_text_from_sequence([token]))\n",
    "            decoder_input = Variable(torch.LongTensor([token]))\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    return \" \".join(decoded_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init training & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 200\n",
    "embedding_size = 100\n",
    "batch_size = 64\n",
    "n_layers = 1\n",
    "num_directions = 2 # bidirectional encoder\n",
    "dropout = 0.1\n",
    "grad_clip = 20.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "learning_rate = 0.0001\n",
    "n_epochs = 1000\n",
    "decoder_learning_ratio = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(\n",
    "    input_size=vocabulary_size, \n",
    "    embedding_size=embedding_size, \n",
    "    hidden_size=hidden_size,\n",
    "    batch_size=batch_size,\n",
    "    n_layers=n_layers,\n",
    "    num_directions=num_directions,\n",
    "    dropout=dropout,\n",
    ")\n",
    "decoder = AttentionDecoderRNN(\n",
    "    output_size=vocabulary_size, \n",
    "    embedding_size=embedding_size, \n",
    "    hidden_size=hidden_size, \n",
    "    batch_size=batch_size, \n",
    "    n_layers=n_layers, \n",
    "    num_directions=num_directions, \n",
    "    dropout=dropout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(85411, 100)\n",
      "  (rnn): GRU(100, 200, dropout=0.1, bidirectional=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentionDecoderRNN(\n",
      "  (embedding): Embedding(85411, 100)\n",
      "  (encoder_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (rnn): GRU(100, 200, dropout=0.1)\n",
      "  (output): Linear(in_features=200, out_features=85411, bias=True)\n",
      "  (encoder_output): Linear(in_features=400, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(dataset=val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eea1ddd3f7044899a1a06ae85bc5dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c02168bcb44fdfa109e572f167048d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1115), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 11.36705493927002, Total loss / batches: 11.36705493927002, Enc_a 0.016440895448167635, Dec_a 0.2596549720747063, Epoch 0\n",
      "Loss 11.358495712280273, Total loss / batches: 11.362775802612305, Enc_a 0.03302695449871136, Dec_a 0.5167090989932837, Epoch 0\n",
      "Loss 11.352649688720703, Total loss / batches: 11.359400749206543, Enc_a 0.04933836047560722, Dec_a 0.7637970650147585, Epoch 0\n",
      "Loss 11.346272468566895, Total loss / batches: 11.356118202209473, Enc_a 0.06567892126098623, Dec_a 1.02149481613734, Epoch 0\n",
      "Loss 11.309538841247559, Total loss / batches: 11.346802711486816, Enc_a 0.08261240055093202, Dec_a 1.3215543279493134, Epoch 0\n",
      "Loss 11.324068069458008, Total loss / batches: 11.343013763427734, Enc_a 0.09989916386247466, Dec_a 1.5784073496037725, Epoch 0\n",
      "Loss 11.312949180603027, Total loss / batches: 11.338719367980957, Enc_a 0.11834202399593789, Dec_a 1.840972486629915, Epoch 0\n",
      "Loss 11.290619850158691, Total loss / batches: 11.332706451416016, Enc_a 0.13826375623997905, Dec_a 2.1166697616557983, Epoch 0\n",
      "Loss 11.26927661895752, Total loss / batches: 11.325658798217773, Enc_a 0.16036427170992062, Dec_a 2.4103049865576853, Epoch 0\n",
      "Loss 11.273859977722168, Total loss / batches: 11.320478439331055, Enc_a 0.18198197153984638, Dec_a 2.6900677648451277, Epoch 0\n",
      "Loss 11.209376335144043, Total loss / batches: 11.310378074645996, Enc_a 0.20383913690248257, Dec_a 3.0815670388021204, Epoch 0\n",
      "Loss 11.220505714416504, Total loss / batches: 11.302889823913574, Enc_a 0.22907972369126056, Dec_a 3.3935464017806254, Epoch 0\n",
      "Loss 11.214052200317383, Total loss / batches: 11.296055793762207, Enc_a 0.2576634272515717, Dec_a 3.715684437380207, Epoch 0\n",
      "Loss 11.174800872802734, Total loss / batches: 11.287394523620605, Enc_a 0.2866273083174105, Dec_a 4.071157621046701, Epoch 0\n",
      "Loss 11.176937103271484, Total loss / batches: 11.280031204223633, Enc_a 0.3156845201986582, Dec_a 4.422920358552548, Epoch 0\n",
      "Loss 11.137242317199707, Total loss / batches: 11.271106719970703, Enc_a 0.3557874538609028, Dec_a 4.803926706698371, Epoch 0\n",
      "Loss 11.099712371826172, Total loss / batches: 11.261024475097656, Enc_a 0.39759186184743256, Dec_a 5.206557750230636, Epoch 0\n",
      "Loss 11.079174995422363, Total loss / batches: 11.250922203063965, Enc_a 0.435546314318324, Dec_a 5.632301934797288, Epoch 0\n",
      "Loss 11.043290138244629, Total loss / batches: 11.239994049072266, Enc_a 0.48760029653017534, Dec_a 6.104154270585908, Epoch 0\n",
      "Loss 10.885749816894531, Total loss / batches: 11.222282409667969, Enc_a 0.5542287632729621, Dec_a 6.732078205400204, Epoch 0\n",
      "Loss 10.850202560424805, Total loss / batches: 11.204564094543457, Enc_a 0.6353602450750743, Dec_a 7.378256774815279, Epoch 0\n",
      "Loss 10.724560737609863, Total loss / batches: 11.182745933532715, Enc_a 0.7276363835578812, Dec_a 8.156420952592223, Epoch 0\n",
      "Loss 10.605484962463379, Total loss / batches: 11.157648086547852, Enc_a 0.8264667864105102, Dec_a 9.061911071633869, Epoch 0\n",
      "Loss 10.535400390625, Total loss / batches: 11.131721496582031, Enc_a 0.9342360890930196, Dec_a 10.020624410581247, Epoch 0\n",
      "Loss 10.339963912963867, Total loss / batches: 11.100050926208496, Enc_a 1.0637828791273403, Dec_a 11.157066367708552, Epoch 0\n",
      "Loss 10.218481063842773, Total loss / batches: 11.066144943237305, Enc_a 1.2111896147951073, Dec_a 12.360065602290407, Epoch 0\n",
      "Loss 9.971449851989746, Total loss / batches: 11.025599479675293, Enc_a 1.3488524064735081, Dec_a 13.685006444941767, Epoch 0\n",
      "Loss 9.744397163391113, Total loss / batches: 10.979842185974121, Enc_a 1.4852025261049298, Dec_a 15.05277652258413, Epoch 0\n",
      "Loss 9.348777770996094, Total loss / batches: 10.923598289489746, Enc_a 1.6331169913973962, Dec_a 16.494179818919047, Epoch 0\n",
      "Loss 9.378592491149902, Total loss / batches: 10.872098922729492, Enc_a 1.7458916373929747, Dec_a 17.812217247111064, Epoch 0\n",
      "Loss 9.119107246398926, Total loss / batches: 10.815550804138184, Enc_a 1.8394402595450112, Dec_a 19.143855748438867, Epoch 0\n",
      "Loss 8.8256254196167, Total loss / batches: 10.753365516662598, Enc_a 1.918963572951921, Dec_a 20.498709138574704, Epoch 0\n",
      "Loss 8.695905685424805, Total loss / batches: 10.691018104553223, Enc_a 1.9930258627321142, Dec_a 21.858821153556967, Epoch 0\n",
      "Loss 8.757942199707031, Total loss / batches: 10.634162902832031, Enc_a 2.0429077321372624, Dec_a 23.124889973152467, Epoch 0\n",
      "Loss 8.308171272277832, Total loss / batches: 10.567705154418945, Enc_a 2.0911611951947404, Dec_a 24.497594019158445, Epoch 0\n",
      "Loss 8.351451873779297, Total loss / batches: 10.506142616271973, Enc_a 2.1311396707974586, Dec_a 25.787153823659928, Epoch 0\n",
      "Loss 8.199031829833984, Total loss / batches: 10.443788528442383, Enc_a 2.1681193056105394, Dec_a 27.137361313145966, Epoch 0\n",
      "Loss 8.159638404846191, Total loss / batches: 10.383679389953613, Enc_a 2.1977168523895183, Dec_a 28.353451098303857, Epoch 0\n",
      "Loss 7.989394187927246, Total loss / batches: 10.322286605834961, Enc_a 2.2211370723329353, Dec_a 29.666241151375694, Epoch 0\n",
      "Loss 7.965072154998779, Total loss / batches: 10.26335620880127, Enc_a 2.241411351102524, Dec_a 30.905742575589915, Epoch 0\n",
      "Loss 8.024582862854004, Total loss / batches: 10.208751678466797, Enc_a 2.2568539755170933, Dec_a 32.04242015706351, Epoch 0\n",
      "Loss 7.71508264541626, Total loss / batches: 10.149378776550293, Enc_a 2.27218972046803, Dec_a 33.13083585391629, Epoch 0\n",
      "Loss 7.74757194519043, Total loss / batches: 10.093523025512695, Enc_a 2.28291810435676, Dec_a 34.1674198423123, Epoch 0\n",
      "Loss 7.841995716094971, Total loss / batches: 10.042351722717285, Enc_a 2.290667889191062, Dec_a 35.10253850901189, Epoch 0\n",
      "Loss 7.701174736022949, Total loss / batches: 9.990325927734375, Enc_a 2.298977985334627, Dec_a 35.97237175943429, Epoch 0\n",
      "Loss 7.69697380065918, Total loss / batches: 9.940469741821289, Enc_a 2.307084416717251, Dec_a 36.809937107152855, Epoch 0\n",
      "Loss 7.796146869659424, Total loss / batches: 9.894845962524414, Enc_a 2.316274993113493, Dec_a 37.56162333931099, Epoch 0\n",
      "Loss 7.579363822937012, Total loss / batches: 9.846607208251953, Enc_a 2.3242401485104174, Dec_a 38.227326239731276, Epoch 0\n",
      "Loss 7.426290035247803, Total loss / batches: 9.797213554382324, Enc_a 2.331711288272857, Dec_a 38.88193016066051, Epoch 0\n",
      "Loss 7.477688789367676, Total loss / batches: 9.750823020935059, Enc_a 2.341885604861268, Dec_a 39.41366418133634, Epoch 0\n",
      "Loss 7.6428422927856445, Total loss / batches: 9.709489822387695, Enc_a 2.352953773514864, Dec_a 39.9588541766392, Epoch 0\n",
      "Loss 7.53110408782959, Total loss / batches: 9.667597770690918, Enc_a 2.3622883778211836, Dec_a 40.52772570606934, Epoch 0\n",
      "Loss 7.596846580505371, Total loss / batches: 9.62852668762207, Enc_a 2.373873640198711, Dec_a 41.11284214678426, Epoch 0\n",
      "Loss 7.705118656158447, Total loss / batches: 9.592907905578613, Enc_a 2.387843622093645, Dec_a 41.70441049797224, Epoch 0\n",
      "Loss 7.5829925537109375, Total loss / batches: 9.556364059448242, Enc_a 2.4018061871729963, Dec_a 42.281792459925164, Epoch 0\n",
      "Loss 7.650222301483154, Total loss / batches: 9.52232551574707, Enc_a 2.4179806555169323, Dec_a 42.935788122705986, Epoch 0\n",
      "Loss 7.633198261260986, Total loss / batches: 9.489182472229004, Enc_a 2.434653723374402, Dec_a 43.61430571823167, Epoch 0\n",
      "Loss 7.454407215118408, Total loss / batches: 9.454100608825684, Enc_a 2.448837856383185, Dec_a 44.35756912701208, Epoch 0\n",
      "Loss 7.487929821014404, Total loss / batches: 9.420775413513184, Enc_a 2.4639332042809006, Dec_a 45.05091697538634, Epoch 0\n",
      "Loss 7.873773574829102, Total loss / batches: 9.394991874694824, Enc_a 2.482614903137254, Dec_a 45.86530922252011, Epoch 0\n",
      "Loss 7.492664337158203, Total loss / batches: 9.36380672454834, Enc_a 2.4993819038002036, Dec_a 46.63695697292301, Epoch 0\n",
      "Loss 7.7175164222717285, Total loss / batches: 9.33725357055664, Enc_a 2.5178107146823887, Dec_a 47.37711335313516, Epoch 0\n",
      "Loss 7.5746564865112305, Total loss / batches: 9.30927562713623, Enc_a 2.538018656978881, Dec_a 47.95976131033071, Epoch 0\n",
      "Loss 7.414831638336182, Total loss / batches: 9.279675483703613, Enc_a 2.55653631023368, Dec_a 48.570075424905276, Epoch 0\n",
      "Loss 7.642890930175781, Total loss / batches: 9.254493713378906, Enc_a 2.577335433874115, Dec_a 49.18707893091703, Epoch 0\n",
      "Loss 7.636413097381592, Total loss / batches: 9.22997760772705, Enc_a 2.596758510038475, Dec_a 49.87108457365092, Epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 7.563372611999512, Total loss / batches: 9.205102920532227, Enc_a 2.61513072013441, Dec_a 50.47981677126358, Epoch 0\n",
      "Loss 7.758218288421631, Total loss / batches: 9.183825492858887, Enc_a 2.639355095473463, Dec_a 51.10802001881754, Epoch 0\n",
      "Loss 7.510009288787842, Total loss / batches: 9.159566879272461, Enc_a 2.657598252711895, Dec_a 51.64561633429009, Epoch 0\n",
      "Loss 7.583366394042969, Total loss / batches: 9.137049674987793, Enc_a 2.677127360623234, Dec_a 52.16197286869712, Epoch 0\n",
      "Loss 7.352837085723877, Total loss / batches: 9.111920356750488, Enc_a 2.6947170108028033, Dec_a 52.77389740811277, Epoch 0\n",
      "Loss 7.456912994384766, Total loss / batches: 9.088933944702148, Enc_a 2.7135055670662043, Dec_a 53.29156001256684, Epoch 0\n",
      "Loss 7.602108001708984, Total loss / batches: 9.06856632232666, Enc_a 2.7357860360540536, Dec_a 53.751879404426035, Epoch 0\n",
      "Loss 7.661604404449463, Total loss / batches: 9.049553871154785, Enc_a 2.7586482764220865, Dec_a 54.31916590886026, Epoch 0\n",
      "Loss 7.676629543304443, Total loss / batches: 9.031248092651367, Enc_a 2.781082658645495, Dec_a 54.839864752971515, Epoch 0\n",
      "Loss 7.5405049324035645, Total loss / batches: 9.01163387298584, Enc_a 2.804335492173004, Dec_a 55.37578881466291, Epoch 0\n",
      "Loss 7.371423244476318, Total loss / batches: 8.990331649780273, Enc_a 2.8228677243381655, Dec_a 55.919360782179474, Epoch 0\n",
      "Loss 7.497634410858154, Total loss / batches: 8.97119426727295, Enc_a 2.846854540164872, Dec_a 56.39509202391885, Epoch 0\n",
      "Loss 7.685453414916992, Total loss / batches: 8.95491886138916, Enc_a 2.8698315201187734, Dec_a 56.948218666122926, Epoch 0\n",
      "Loss 7.343458652496338, Total loss / batches: 8.934775352478027, Enc_a 2.887977510068202, Dec_a 57.4519413589787, Epoch 0\n",
      "Loss 7.377326011657715, Total loss / batches: 8.915547370910645, Enc_a 2.914307415578113, Dec_a 58.02347738528944, Epoch 0\n",
      "Loss 7.335655689239502, Total loss / batches: 8.896280288696289, Enc_a 2.9365754556261003, Dec_a 58.55705880785267, Epoch 0\n",
      "Loss 7.4995808601379395, Total loss / batches: 8.8794527053833, Enc_a 2.9625171651849715, Dec_a 59.0230894978375, Epoch 0\n",
      "Loss 7.547442436218262, Total loss / batches: 8.863595008850098, Enc_a 2.9930414609463742, Dec_a 59.52452718100818, Epoch 0\n",
      "Loss 7.505418300628662, Total loss / batches: 8.847617149353027, Enc_a 3.0242167159051823, Dec_a 60.04190242757987, Epoch 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-815-89d68b190dbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mencoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_text_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_text_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_summary_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_summary_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     )\n\u001b[1;32m      8\u001b[0m     \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-794-449bcb96b244>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, train_data_loader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_text_length, max_summary_length, grad_clip)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         )\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm_notebook(range(n_epochs)):\n",
    "    loss, enc, dec = train(\n",
    "        epoch, train_data_loader=train_data_loader, \n",
    "        encoder=encoder, decoder=decoder, \n",
    "        encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "        criterion=criterion, max_text_length=max_text_words, max_summary_length=max_summary_words,\n",
    "    )\n",
    "    xs, ys, xs_lengths, ys_lengths = random_batch()\n",
    "    result = evaluate(xs[0], max_text_words, max_summary_words)\n",
    "    print(f'Evaluation after: {epoch} epochs.\\nInput: {xs}.\\nTarget: {ys}.\\nResult: {result}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n",
      "tensor(3)\n",
      "Evaluation after: 0 epochs.\n",
      "\n",
      "Input:       Pakistan Test captain Misbah ul Haq become the first batsman in the history of test cricket to register three score of 99 after get dismiss one run short of a century against the West Indies on Tuesday the 42 year old right handed batsman who be chase  <UNK>  11th test century also become the first player to score 99 in two consecutive test . <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> .\n",
      "\n",
      "Target:       SOS_TOKEN Misbah become 1st batsman with three score of 99 in test EOS_TOKEN <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> .\n",
      "\n",
      "Result:       SOS_TOKEN to  EOS_TOKEN.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "xs, ys, xs_length, ys_length = random_batch()\n",
    "idx = 43\n",
    "result = evaluate(xs[idx], max_text_words, max_summary_words)\n",
    "print(f'Evaluation after: {epoch} epochs.\\n\\nInput: \\\n",
    "      {decode_text_from_sequence(xs.transpose(0, 1)[idx])}.\\n\\nTarget: \\\n",
    "      {decode_text_from_sequence(ys.transpose(0, 1)[idx])}.\\n\\nResult: \\\n",
    "      {result}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
