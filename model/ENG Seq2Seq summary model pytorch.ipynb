{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/news-summary-kaggle/news_test.csv',\n",
       " '../data/news-summary-kaggle/news_train.csv',\n",
       " '../data/news-summary-kaggle/news_summary_more.csv',\n",
       " '../data/news-summary-kaggle/news-cleaned.csv',\n",
       " '../data/news-summary-kaggle/news-splitted.csv',\n",
       " '../data/news-summary-kaggle/news_summary.csv',\n",
       " '../data/news-summary-kaggle/news_val.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('../data/news-summary-kaggle/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/news-summary-kaggle/news_summary.csv', encoding='iso-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4514 entries, 0 to 4513\n",
      "Data columns (total 6 columns):\n",
      "author       4514 non-null object\n",
      "date         4514 non-null object\n",
      "headlines    4514 non-null object\n",
      "read_more    4514 non-null object\n",
      "text         4514 non-null object\n",
      "ctext        4396 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 211.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>headlines</th>\n",
       "      <th>read_more</th>\n",
       "      <th>text</th>\n",
       "      <th>ctext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chhavi Tyagi</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "      <td>http://www.hindustantimes.com/india-news/raksh...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "      <td>http://www.hindustantimes.com/bollywood/malaik...</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>From her special numbers to TV?appearances, Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arshiya Chopra</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "      <td>http://www.hindustantimes.com/patna/bihar-igim...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sumedha Sehra</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "      <td>http://indiatoday.intoday.in/story/abu-dujana-...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aarushi Maheshwari</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Hotel staff to get training to spot signs of s...</td>\n",
       "      <td>http://indiatoday.intoday.in/story/sex-traffic...</td>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "      <td>Hotels in Mumbai and other Indian cities are t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author                  date  \\\n",
       "0        Chhavi Tyagi  03 Aug 2017,Thursday   \n",
       "1         Daisy Mowke  03 Aug 2017,Thursday   \n",
       "2      Arshiya Chopra  03 Aug 2017,Thursday   \n",
       "3       Sumedha Sehra  03 Aug 2017,Thursday   \n",
       "4  Aarushi Maheshwari  03 Aug 2017,Thursday   \n",
       "\n",
       "                                           headlines  \\\n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in...   \n",
       "1  Malaika slams user who trolled her for 'divorc...   \n",
       "2  'Virgin' now corrected to 'Unmarried' in IGIMS...   \n",
       "3  Aaj aapne pakad liya: LeT man Dujana before be...   \n",
       "4  Hotel staff to get training to spot signs of s...   \n",
       "\n",
       "                                           read_more  \\\n",
       "0  http://www.hindustantimes.com/india-news/raksh...   \n",
       "1  http://www.hindustantimes.com/bollywood/malaik...   \n",
       "2  http://www.hindustantimes.com/patna/bihar-igim...   \n",
       "3  http://indiatoday.intoday.in/story/abu-dujana-...   \n",
       "4  http://indiatoday.intoday.in/story/sex-traffic...   \n",
       "\n",
       "                                                text  \\\n",
       "0  The Administration of Union Territory Daman an...   \n",
       "1  Malaika Arora slammed an Instagram user who tr...   \n",
       "2  The Indira Gandhi Institute of Medical Science...   \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
       "4  Hotels in Maharashtra will train their staff t...   \n",
       "\n",
       "                                               ctext  \n",
       "0  The Daman and Diu administration on Wednesday ...  \n",
       "1  From her special numbers to TV?appearances, Bo...  \n",
       "2  The Indira Gandhi Institute of Medical Science...  \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...  \n",
       "4  Hotels in Mumbai and other Indian cities are t...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_more = pd.read_csv('../data/news-summary-kaggle/news_summary_more.csv', encoding='iso-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_more.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.DataFrame({\n",
    "    'text': pd.concat([data.text, data_more.text], ignore_index=True),\n",
    "    'summary': pd.concat([data.headlines, data_more.headlines], ignore_index=True)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "      <td>Hotel staff to get training to spot signs of s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The Administration of Union Territory Daman an...   \n",
       "1  Malaika Arora slammed an Instagram user who tr...   \n",
       "2  The Indira Gandhi Institute of Medical Science...   \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
       "4  Hotels in Maharashtra will train their staff t...   \n",
       "\n",
       "                                             summary  \n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in...  \n",
       "1  Malaika slams user who trolled her for 'divorc...  \n",
       "2  'Virgin' now corrected to 'Unmarried' in IGIMS...  \n",
       "3  Aaj aapne pakad liya: LeT man Dujana before be...  \n",
       "4  Hotel staff to get training to spot signs of s...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['text_len'] = raw_data.text.apply(lambda x: len(x))\n",
    "raw_data['summary_len'] = raw_data.summary.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x132451210>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.text_len.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x132578710>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data.summary_len.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove shortest summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data[raw_data.summary_len > raw_data.summary_len.quantile(.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_strip(row):\n",
    "    row=re.sub(\"(\\\\t)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\\\r)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\\\n)\", ' ', str(row))\n",
    "\n",
    "    row=re.sub(\"(__+)\", ' ', str(row))\n",
    "    row=re.sub(\"(-+)\", ' ', str(row))\n",
    "    row=re.sub(\"(~~+)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\+\\++)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\.\\.+)\", ' ', str(row))\n",
    "\n",
    "    row=re.sub(\"(\\.\\s+)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\-\\s+)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\:\\s+)\", ' ', str(row))\n",
    "\n",
    "    row=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", '', str(row))\n",
    "\n",
    "    parsed = nlp(row)\n",
    "    lemmatized = ''\n",
    "    for sentence in parsed:\n",
    "        lemmatized += sentence.lemma_.strip() + ' '\n",
    "    return lemmatized.lstrip().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ed1e614d5e4a5e99dddb11dd15f0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101873), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data['text_stripped'] = [\n",
    "    spacy_strip(row) for row in tqdm_notebook(raw_data.text)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb52f3ffea84bec9d69153056cf43e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101873), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data['summary_stripped'] = [\n",
    "    spacy_strip(row) for row in tqdm_notebook(raw_data.summary)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data.to_csv('../data/news-summary-kaggle/news-cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate to train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../data/news-summary-kaggle/news-cleaned.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>text_len</th>\n",
       "      <th>summary_len</th>\n",
       "      <th>text_stripped</th>\n",
       "      <th>summary_stripped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "      <td>358</td>\n",
       "      <td>60</td>\n",
       "      <td>the Administration of Union Territory Daman an...</td>\n",
       "      <td>Daman  Diu revoke mandatory Rakshabandhan in o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "      <td>361</td>\n",
       "      <td>60</td>\n",
       "      <td>Malaika Arora slam an Instagram user who troll...</td>\n",
       "      <td>Malaika slam user who troll -PRON- for divorce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "      <td>398</td>\n",
       "      <td>52</td>\n",
       "      <td>the Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>Virgin now correct to Unmarried in IGIMS form</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "      <td>368</td>\n",
       "      <td>56</td>\n",
       "      <td>Lashkar e Taibas Kashmir commander Abu Dujana ...</td>\n",
       "      <td>Aaj aapne pakad liya LeT man Dujana before be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "      <td>Hotel staff to get training to spot signs of s...</td>\n",
       "      <td>366</td>\n",
       "      <td>60</td>\n",
       "      <td>hotel in Maharashtra will train -PRON- staff t...</td>\n",
       "      <td>hotel staff to get training to spot sign of se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The Administration of Union Territory Daman an...   \n",
       "1  Malaika Arora slammed an Instagram user who tr...   \n",
       "2  The Indira Gandhi Institute of Medical Science...   \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
       "4  Hotels in Maharashtra will train their staff t...   \n",
       "\n",
       "                                             summary  text_len  summary_len  \\\n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in...       358           60   \n",
       "1  Malaika slams user who trolled her for 'divorc...       361           60   \n",
       "2  'Virgin' now corrected to 'Unmarried' in IGIMS...       398           52   \n",
       "3  Aaj aapne pakad liya: LeT man Dujana before be...       368           56   \n",
       "4  Hotel staff to get training to spot signs of s...       366           60   \n",
       "\n",
       "                                       text_stripped  \\\n",
       "0  the Administration of Union Territory Daman an...   \n",
       "1  Malaika Arora slam an Instagram user who troll...   \n",
       "2  the Indira Gandhi Institute of Medical Science...   \n",
       "3  Lashkar e Taibas Kashmir commander Abu Dujana ...   \n",
       "4  hotel in Maharashtra will train -PRON- staff t...   \n",
       "\n",
       "                                    summary_stripped  \n",
       "0  Daman  Diu revoke mandatory Rakshabandhan in o...  \n",
       "1  Malaika slam user who troll -PRON- for divorce...  \n",
       "2      Virgin now correct to Unmarried in IGIMS form  \n",
       "3  Aaj aapne pakad liya LeT man Dujana before be ...  \n",
       "4  hotel staff to get training to spot sign of se...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df, train_percentage=0.8, val_percentage=0.1, seed=None, inplace=False):\n",
    "    np.random.seed(seed)\n",
    "    permutation = np.random.permutation(df.index)\n",
    "    length = len(df.index)\n",
    "    train_end = int(train_percentage * length)\n",
    "    val_end = int(val_percentage * length) + train_end\n",
    "    train_ids = permutation[:train_end]\n",
    "    val_ids = permutation[train_end:val_end]\n",
    "    test_ids = permutation[val_end:]\n",
    "    if inplace:\n",
    "        df.loc[df.index.isin(train_ids), 'dataset'] = ['train'] * len(train_ids)\n",
    "        df.loc[df.index.isin(val_ids), 'dataset'] = ['val'] * len(val_ids)\n",
    "        df.loc[df.index.isin(test_ids), 'dataset'] = ['test'] * len(test_ids)\n",
    "        return df\n",
    "    else:\n",
    "        train = df.iloc[train_ids]\n",
    "        val = df.iloc[val_ids]\n",
    "        test = df.iloc[test_ids]\n",
    "        return train.reset_index(drop=True), val.reset_index(drop=True), test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = train_val_test_split(data, seed=9, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data as separate datasets:\n",
    "* train\n",
    "* val\n",
    "* test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_data[['text_stripped', 'summary_stripped']].to_csv('../data/news-summary-kaggle/news_train.csv', index=False)\n",
    "# val_data[['text_stripped', 'summary_stripped']].to_csv('../data/news-summary-kaggle/news_val.csv', index=False)\n",
    "# test_data[['text_stripped', 'summary_stripped']].to_csv('../data/news-summary-kaggle/news_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_en(text):\n",
    "    text=re.sub(\"(\\\\t)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\\\r)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\\\n)\", ' ', str(text))\n",
    "\n",
    "    text=re.sub(\"(__+)\", ' ', str(text))\n",
    "    text=re.sub(\"(-+)\", ' ', str(text))\n",
    "    text=re.sub(\"(~~+)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\+\\++)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\.\\.+)\", ' ', str(text))\n",
    "\n",
    "    text=re.sub(\"(\\.\\s+)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\-\\s+)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\:\\s+)\", ' ', str(text))\n",
    "\n",
    "    text=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", '', str(text))\n",
    "    return [tok.text for tok in nlp.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(batch_size):\n",
    "    TEXT = Field(tokenize=tokenize_en, include_lengths=True,\n",
    "                 init_token='<sos>', eos_token='<eos>')\n",
    "    SUMMARY = Field(tokenize=tokenize_en, include_lengths=True,\n",
    "                    init_token='<sos>', eos_token='<eos>')\n",
    "    train, val, test = TabularDataset.splits(\n",
    "        skip_header=True, \n",
    "        path='../data/news-summary-kaggle/', format='csv', \n",
    "        fields=[('text', TEXT), ('summary', SUMMARY)],\n",
    "        train='news_train.csv', validation='news_val.csv', test='news_test.csv'\n",
    "    )\n",
    "    TEXT.build_vocab(train, min_freq=2)\n",
    "    SUMMARY.build_vocab(train, min_freq=2)\n",
    "    train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "        (train, val, test), batch_size=batch_size, repeat=False,\n",
    "    )\n",
    "    return train_iter, val_iter, test_iter, TEXT, SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter, TEXT, SUMMARY = load_dataset(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_from_text(text, lang=TEXT):\n",
    "    indices = []\n",
    "    for word in text.strip().split(' '):\n",
    "        indices.append(lang.vocab.stoi[word])\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_indices(indices, lang=TEXT):\n",
    "    text = \"\"\n",
    "    for element in indices:\n",
    "        if type(element) is torch.Tensor:\n",
    "            text += lang.vocab.itos[element.item()] + \" \"\n",
    "        else:\n",
    "            text += lang.vocab.itos[element] + \" \"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> Karnataka Chief Minister Siddaramaiah on Tuesday tweet that   PRON   be glad PM Narendra Modi be talk about corruption and that   PRON   now invite   PRON   to walk the Talk Siddaramaiah ask pm Modi to appoint Lok Pal investigate Justice <unk> death investigate the astronomical rise of Jay Shah and appoint an <unk> person as bjp CM candidate <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_from_indices(next(iter(train_iter)).text[0].transpose(0, 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> easy soul   be   taxiway comet court in until   be   of while <eos> '"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_from_indices(next(iter(train_iter)).summary[0].transpose(0, 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, n_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, n_layers,\n",
    "                          dropout=dropout, bidirectional=True)\n",
    "\n",
    "    def forward(self, sequence, hidden=None):\n",
    "        embedding_output = self.embedding(sequence) # max_text_len x batch_size x embedding_size\n",
    "        encoder_outputs, hidden = self.gru(embedding_output, hidden)\n",
    "        # hidden: bidirectional x batch_size x hidden_size\n",
    "        # output: max_text_len x batch_size x bidirectional * hidden_size\n",
    "        encoder_outputs = encoder_outputs[:, :, :self.hidden_size] + encoder_outputs[:, :, self.hidden_size:]\n",
    "        # output: max_text_len x batch_size x hidden_size\n",
    "        return encoder_outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "        stdv = 1. / math.sqrt(self.v.size(0))\n",
    "        self.v.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        timestep = encoder_outputs.size(0)\n",
    "        h = hidden.repeat(timestep, 1, 1).transpose(0, 1)\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1) \n",
    "        attn_energies = self.score(h, encoder_outputs) # batch_size x t x hidden\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1) # batch_size x t\n",
    "\n",
    "    def score(self, hidden, encoder_outputs):\n",
    "        # batch_size x t x 2*hidden -> batch_size x t x hidden\n",
    "        energy = F.tanh(self.attention(torch.cat([hidden, encoder_outputs], 2)))\n",
    "        energy = energy.transpose(1, 2) # batch_size x t x 2*hidden -> batch_size x t x hidden\n",
    "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1) # batch_size x 1 x hidden\n",
    "        energy = torch.bmm(v, energy) # batch_size x 1 x t\n",
    "        return energy.squeeze(1) # batch_size x t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout, inplace=True)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size + embedding_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.output = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, sequence, hidden, encoder_outputs):\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        embedding_output = self.embedding(sequence).unsqueeze(0)  # 1 x batch_size x n\n",
    "        embedding_output = self.dropout(embedding_output)\n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attention_weights = self.attention(hidden[-1], encoder_outputs)\n",
    "        context = attention_weights.bmm(encoder_outputs.transpose(0, 1)) # batch_size x 1 x n\n",
    "        context = context.transpose(0, 1)  # (1,B,N)\n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        decoder_input = torch.cat([embedding_output, context], 2)\n",
    "        decoder_output, hidden = self.gru(decoder_input, hidden)\n",
    "        decoder_output = decoder_output.squeeze(0)  # (1,B,N) -> (B,N)\n",
    "        context = context.squeeze(0)\n",
    "        decoder_output = self.output(torch.cat([decoder_output, context], 1))\n",
    "        decoder_output = F.log_softmax(decoder_output, dim=1)\n",
    "        return decoder_output, hidden, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, text, summary, teacher_forcing_ratio=0.5):\n",
    "        batch_size = text.size(1)\n",
    "        max_len = summary.size(0)\n",
    "        vocab_size = self.decoder.output_size\n",
    "\n",
    "        encoder_output, hidden = self.encoder(text)\n",
    "        hidden = hidden[:self.decoder.n_layers]\n",
    "        output = Variable(summary.data[0, :])  # sos\n",
    "        \n",
    "        outputs = Variable(torch.zeros(max_len, batch_size, vocab_size))\n",
    "        for t in range(1, max_len):\n",
    "            output, hidden, attention_weights = self.decoder(\n",
    "                    output, hidden, encoder_output)\n",
    "            outputs[t] = output\n",
    "            is_teacher = random.random() < teacher_forcing_ratio\n",
    "            top_first = output.data.max(1)[1]\n",
    "            output = Variable(summary.data[t] if is_teacher else top_first)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(e, model, optimizer, train_iter, vocab_size, grad_clip, lang=TEXT):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pad = lang.vocab.stoi['<pad>']\n",
    "    for b, batch in tqdm_notebook(enumerate(train_iter), total=len(train_iter)):\n",
    "        text, len_text = batch.text\n",
    "        summary, len_summary = batch.summary\n",
    "        optimizer.zero_grad()\n",
    "        output = model(text, summary)\n",
    "        loss = F.nll_loss(\n",
    "            output[1:].view(-1, vocab_size),\n",
    "            summary[1:].contiguous().view(-1),\n",
    "            ignore_index=pad,\n",
    "        )\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.data\n",
    "\n",
    "        if b % 1 == 0 and b != 0:\n",
    "            total_loss = total_loss / 100\n",
    "            print(f'[{b}] [loss: {total_loss}] [loss_exp: {math.exp(total_loss)}]')\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter, vocab_size, lang=TEXT):\n",
    "    model.eval()\n",
    "    pad = lang.vocab.stoi['<pad>']\n",
    "    total_loss = 0\n",
    "    for b, batch in enumerate(val_iter):\n",
    "        text, len_text = batch.text\n",
    "        summary, len_summary = batch.summary\n",
    "        text = Variable(text.data, volatile=True)\n",
    "        summary = Variable(summary.data, volatile=True)\n",
    "        output = model(text, summary, teacher_forcing_ratio=0.0)\n",
    "        loss = F.nll_loss(\n",
    "            output[1:].view(-1, vocab_size),\n",
    "            summary[1:].contiguous().view(-1),\n",
    "            ignore_index=pad,\n",
    "        )\n",
    "        total_loss += loss.data\n",
    "    return total_loss / len(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "lr = 0.0001\n",
    "grad_clip = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "embed_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] preparing dataset...\n",
      "[TRAIN]:1274 (dataset:81498)\t[TEST]:160 (dataset:10188)\n",
      "[TEXT_vocab]:50576 [SUMMARY_vocab]:20530\n"
     ]
    }
   ],
   "source": [
    "print(\"[!] preparing dataset...\")\n",
    "text_size, summary_size = len(TEXT.vocab), len(SUMMARY.vocab)\n",
    "print(\"[TRAIN]:%d (dataset:%d)\\t[TEST]:%d (dataset:%d)\"\n",
    "      % (len(train_iter), len(train_iter.dataset),\n",
    "         len(test_iter), len(test_iter.dataset)))\n",
    "print(\"[TEXT_vocab]:%d [SUMMARY_vocab]:%d\" % (text_size, summary_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Instantiating models...\n",
      "Seq2Seq(\n",
      "  (encoder): EncoderRNN(\n",
      "    (embedding): Embedding(50576, 128)\n",
      "    (gru): GRU(128, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
      "  )\n",
      "  (decoder): DecoderRNN(\n",
      "    (embedding): Embedding(50576, 128)\n",
      "    (dropout): Dropout(p=0.5, inplace=True)\n",
      "    (attention): BahdanauAttention(\n",
      "      (attention): Linear(in_features=512, out_features=256, bias=True)\n",
      "    )\n",
      "    (gru): GRU(384, 256, dropout=0.5)\n",
      "    (output): Linear(in_features=512, out_features=50576, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"[!] Instantiating models...\")\n",
    "encoder = EncoderRNN(text_size, embed_size, hidden_size,\n",
    "                  n_layers=2, dropout=0.5)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, text_size,\n",
    "                  n_layers=1, dropout=0.5)\n",
    "seq2seq = Seq2Seq(encoder, decoder)\n",
    "optimizer = optim.Adam(seq2seq.parameters(), lr=lr)\n",
    "print(seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21aa9f3978d64e808af951963f27f1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [loss: 0.21644702553749084] [loss_exp: 1.2416573074830861]\n",
      "[2] [loss: 0.10794827342033386] [loss_exp: 1.113990120997383]\n",
      "[3] [loss: 0.10785089433193207] [loss_exp: 1.11388164693655]\n",
      "[4] [loss: 0.10776355862617493] [loss_exp: 1.1137843695447416]\n",
      "[5] [loss: 0.10750753432512283] [loss_exp: 1.1134992501803065]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-b244b27c2e94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     train(e, seq2seq, optimizer, train_iter,\n\u001b[0;32m----> 4\u001b[0;31m           text_size, grad_clip, TEXT)\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     print(\"[Epoch:%d] val_loss:%5.3f | val_pp:%5.2fS\"\n",
      "\u001b[0;32m<ipython-input-49-bb0ca83ca05d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(e, model, optimizer, train_iter, vocab_size, grad_clip, lang)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         )\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "for e in range(1, epochs+1):\n",
    "    train(e, seq2seq, optimizer, train_iter,\n",
    "          text_size, grad_clip, TEXT)\n",
    "    val_loss = evaluate(seq2seq, val_iter, text_size, TEXT)\n",
    "    print(\"[Epoch:%d] val_loss:%5.3f | val_pp:%5.2fS\"\n",
    "          % (e, val_loss, math.exp(val_loss)))\n",
    "\n",
    "    # Save the model if the validation loss is the best we've seen so far.\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        print(\"[!] saving model...\")\n",
    "        if not os.path.isdir(\".save\"):\n",
    "            os.makedirs(\".save\")\n",
    "        torch.save(seq2seq.state_dict(), './.save/seq2seq_%d.pt' % (e))\n",
    "        best_val_loss = val_loss\n",
    "test_loss = evaluate(seq2seq, test_iter, text_size, TEXT)\n",
    "print(\"[TEST] loss:%5.2f\" % test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
