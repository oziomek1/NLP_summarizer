{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import notebook, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.autograd import Variable\n",
    "from torchtext.data import Field, BPTTIterator, BucketIterator, Iterator, TabularDataset, interleave_keys\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/news-summary-kaggle/news_test.csv',\n",
       " '../data/news-summary-kaggle/news_train.csv',\n",
       " '../data/news-summary-kaggle/news_summary_more.csv',\n",
       " '../data/news-summary-kaggle/news-cleaned.csv',\n",
       " '../data/news-summary-kaggle/news-splitted.csv',\n",
       " '../data/news-summary-kaggle/news_summary.csv',\n",
       " '../data/news-summary-kaggle/news_val.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('../data/news-summary-kaggle/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/news-summary-kaggle/news_summary.csv', encoding='iso-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4514 entries, 0 to 4513\n",
      "Data columns (total 6 columns):\n",
      "author       4514 non-null object\n",
      "date         4514 non-null object\n",
      "headlines    4514 non-null object\n",
      "read_more    4514 non-null object\n",
      "text         4514 non-null object\n",
      "ctext        4396 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 211.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>headlines</th>\n",
       "      <th>read_more</th>\n",
       "      <th>text</th>\n",
       "      <th>ctext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chhavi Tyagi</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "      <td>http://www.hindustantimes.com/india-news/raksh...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "      <td>http://www.hindustantimes.com/bollywood/malaik...</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>From her special numbers to TV?appearances, Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arshiya Chopra</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "      <td>http://www.hindustantimes.com/patna/bihar-igim...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sumedha Sehra</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "      <td>http://indiatoday.intoday.in/story/abu-dujana-...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aarushi Maheshwari</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Hotel staff to get training to spot signs of s...</td>\n",
       "      <td>http://indiatoday.intoday.in/story/sex-traffic...</td>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "      <td>Hotels in Mumbai and other Indian cities are t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author                  date  \\\n",
       "0        Chhavi Tyagi  03 Aug 2017,Thursday   \n",
       "1         Daisy Mowke  03 Aug 2017,Thursday   \n",
       "2      Arshiya Chopra  03 Aug 2017,Thursday   \n",
       "3       Sumedha Sehra  03 Aug 2017,Thursday   \n",
       "4  Aarushi Maheshwari  03 Aug 2017,Thursday   \n",
       "\n",
       "                                           headlines  \\\n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in...   \n",
       "1  Malaika slams user who trolled her for 'divorc...   \n",
       "2  'Virgin' now corrected to 'Unmarried' in IGIMS...   \n",
       "3  Aaj aapne pakad liya: LeT man Dujana before be...   \n",
       "4  Hotel staff to get training to spot signs of s...   \n",
       "\n",
       "                                           read_more  \\\n",
       "0  http://www.hindustantimes.com/india-news/raksh...   \n",
       "1  http://www.hindustantimes.com/bollywood/malaik...   \n",
       "2  http://www.hindustantimes.com/patna/bihar-igim...   \n",
       "3  http://indiatoday.intoday.in/story/abu-dujana-...   \n",
       "4  http://indiatoday.intoday.in/story/sex-traffic...   \n",
       "\n",
       "                                                text  \\\n",
       "0  The Administration of Union Territory Daman an...   \n",
       "1  Malaika Arora slammed an Instagram user who tr...   \n",
       "2  The Indira Gandhi Institute of Medical Science...   \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
       "4  Hotels in Maharashtra will train their staff t...   \n",
       "\n",
       "                                               ctext  \n",
       "0  The Daman and Diu administration on Wednesday ...  \n",
       "1  From her special numbers to TV?appearances, Bo...  \n",
       "2  The Indira Gandhi Institute of Medical Science...  \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...  \n",
       "4  Hotels in Mumbai and other Indian cities are t...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_more = pd.read_csv('../data/news-summary-kaggle/news_summary_more.csv', encoding='iso-8859-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_more.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.DataFrame({\n",
    "    'text': pd.concat([data.text, data_more.text], ignore_index=True),\n",
    "    'summary': pd.concat([data.headlines, data_more.headlines], ignore_index=True)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "      <td>Hotel staff to get training to spot signs of s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The Administration of Union Territory Daman an...   \n",
       "1  Malaika Arora slammed an Instagram user who tr...   \n",
       "2  The Indira Gandhi Institute of Medical Science...   \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
       "4  Hotels in Maharashtra will train their staff t...   \n",
       "\n",
       "                                             summary  \n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in...  \n",
       "1  Malaika slams user who trolled her for 'divorc...  \n",
       "2  'Virgin' now corrected to 'Unmarried' in IGIMS...  \n",
       "3  Aaj aapne pakad liya: LeT man Dujana before be...  \n",
       "4  Hotel staff to get training to spot signs of s...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['text_len'] = raw_data.text.apply(lambda x: len(x))\n",
    "raw_data['summary_len'] = raw_data.summary.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x132451210>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.text_len.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x132578710>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data.summary_len.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove shortest summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data[raw_data.summary_len > raw_data.summary_len.quantile(.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_strip(row):\n",
    "    row=re.sub(\"(\\\\t)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\\\r)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\\\n)\", ' ', str(row))\n",
    "\n",
    "    row=re.sub(\"(__+)\", ' ', str(row))\n",
    "    row=re.sub(\"(-+)\", ' ', str(row))\n",
    "    row=re.sub(\"(~~+)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\+\\++)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\.\\.+)\", ' ', str(row))\n",
    "\n",
    "    row=re.sub(\"(\\.\\s+)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\-\\s+)\", ' ', str(row))\n",
    "    row=re.sub(\"(\\:\\s+)\", ' ', str(row))\n",
    "\n",
    "    row=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", '', str(row))\n",
    "\n",
    "    parsed = nlp(row)\n",
    "    lemmatized = ''\n",
    "    for sentence in parsed:\n",
    "        lemmatized += sentence.lemma_.strip() + ' '\n",
    "    return lemmatized.lstrip().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ed1e614d5e4a5e99dddb11dd15f0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101873), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data['text_stripped'] = [\n",
    "    spacy_strip(row) for row in tqdm_notebook(raw_data.text)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb52f3ffea84bec9d69153056cf43e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=101873), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data['summary_stripped'] = [\n",
    "    spacy_strip(row) for row in tqdm_notebook(raw_data.summary)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data.to_csv('../data/news-summary-kaggle/news-cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate to train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/news-summary-kaggle/news-cleaned.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>text_len</th>\n",
       "      <th>summary_len</th>\n",
       "      <th>text_stripped</th>\n",
       "      <th>summary_stripped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "      <td>358</td>\n",
       "      <td>60</td>\n",
       "      <td>the Administration of Union Territory Daman an...</td>\n",
       "      <td>Daman  Diu revoke mandatory Rakshabandhan in o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "      <td>361</td>\n",
       "      <td>60</td>\n",
       "      <td>Malaika Arora slam an Instagram user who troll...</td>\n",
       "      <td>Malaika slam user who troll -PRON- for divorce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "      <td>398</td>\n",
       "      <td>52</td>\n",
       "      <td>the Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>Virgin now correct to Unmarried in IGIMS form</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "      <td>368</td>\n",
       "      <td>56</td>\n",
       "      <td>Lashkar e Taibas Kashmir commander Abu Dujana ...</td>\n",
       "      <td>Aaj aapne pakad liya LeT man Dujana before be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "      <td>Hotel staff to get training to spot signs of s...</td>\n",
       "      <td>366</td>\n",
       "      <td>60</td>\n",
       "      <td>hotel in Maharashtra will train -PRON- staff t...</td>\n",
       "      <td>hotel staff to get training to spot sign of se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The Administration of Union Territory Daman an...   \n",
       "1  Malaika Arora slammed an Instagram user who tr...   \n",
       "2  The Indira Gandhi Institute of Medical Science...   \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
       "4  Hotels in Maharashtra will train their staff t...   \n",
       "\n",
       "                                             summary  text_len  summary_len  \\\n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in...       358           60   \n",
       "1  Malaika slams user who trolled her for 'divorc...       361           60   \n",
       "2  'Virgin' now corrected to 'Unmarried' in IGIMS...       398           52   \n",
       "3  Aaj aapne pakad liya: LeT man Dujana before be...       368           56   \n",
       "4  Hotel staff to get training to spot signs of s...       366           60   \n",
       "\n",
       "                                       text_stripped  \\\n",
       "0  the Administration of Union Territory Daman an...   \n",
       "1  Malaika Arora slam an Instagram user who troll...   \n",
       "2  the Indira Gandhi Institute of Medical Science...   \n",
       "3  Lashkar e Taibas Kashmir commander Abu Dujana ...   \n",
       "4  hotel in Maharashtra will train -PRON- staff t...   \n",
       "\n",
       "                                    summary_stripped  \n",
       "0  Daman  Diu revoke mandatory Rakshabandhan in o...  \n",
       "1  Malaika slam user who troll -PRON- for divorce...  \n",
       "2      Virgin now correct to Unmarried in IGIMS form  \n",
       "3  Aaj aapne pakad liya LeT man Dujana before be ...  \n",
       "4  hotel staff to get training to spot sign of se...  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df, train_percentage=0.8, val_percentage=0.1, seed=None, inplace=False):\n",
    "    np.random.seed(seed)\n",
    "    permutation = np.random.permutation(df.index)\n",
    "    length = len(df.index)\n",
    "    train_end = int(train_percentage * length)\n",
    "    val_end = int(val_percentage * length) + train_end\n",
    "    train_ids = permutation[:train_end]\n",
    "    val_ids = permutation[train_end:val_end]\n",
    "    test_ids = permutation[val_end:]\n",
    "    if inplace:\n",
    "        df.loc[df.index.isin(train_ids), 'dataset'] = ['train'] * len(train_ids)\n",
    "        df.loc[df.index.isin(val_ids), 'dataset'] = ['val'] * len(val_ids)\n",
    "        df.loc[df.index.isin(test_ids), 'dataset'] = ['test'] * len(test_ids)\n",
    "        return df\n",
    "    else:\n",
    "        train = df.iloc[train_ids]\n",
    "        val = df.iloc[val_ids]\n",
    "        test = df.iloc[test_ids]\n",
    "        return train.reset_index(drop=True), val.reset_index(drop=True), test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = train_val_test_split(data, seed=9, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>text_len</th>\n",
       "      <th>summary_len</th>\n",
       "      <th>text_stripped</th>\n",
       "      <th>summary_stripped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The I-League organisers said on Monday that th...</td>\n",
       "      <td>No telecast of Real Kashmir vs Chennai City du...</td>\n",
       "      <td>327</td>\n",
       "      <td>55</td>\n",
       "      <td>the I League organiser say on Monday that the ...</td>\n",
       "      <td>no telecast of Real Kashmir vs Chennai City du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Poland-born scientist Marie Curie, known for h...</td>\n",
       "      <td>Marie Curie unknowingly died due to her own di...</td>\n",
       "      <td>350</td>\n",
       "      <td>53</td>\n",
       "      <td>Poland bear scientist Marie Curie know for -PR...</td>\n",
       "      <td>Marie Curie unknowingly die due to -PRON- own ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US State Secretary Mike Pompeo has announced t...</td>\n",
       "      <td>US to revoke visas of 21 Saudis involved in jo...</td>\n",
       "      <td>377</td>\n",
       "      <td>60</td>\n",
       "      <td>US State Secretary Mike Pompeo have announce t...</td>\n",
       "      <td>US to revoke visa of 21 Saudis involve in jour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>British DJ Paul Oakenfold on Tuesday performed...</td>\n",
       "      <td>British DJ Paul Oakenfold performs concert at ...</td>\n",
       "      <td>353</td>\n",
       "      <td>59</td>\n",
       "      <td>british DJ Paul Oakenfold on Tuesday perform a...</td>\n",
       "      <td>british DJ Paul Oakenfold perform concert at M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bihar's Somesh Choudhary, a ticket examiner in...</td>\n",
       "      <td>Indian Railways employee asked PNR full form o...</td>\n",
       "      <td>368</td>\n",
       "      <td>66</td>\n",
       "      <td>Bihars Somesh Choudhary a ticket examiner in I...</td>\n",
       "      <td>Indian Railways employee ask PNR full form on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The I-League organisers said on Monday that th...   \n",
       "1  Poland-born scientist Marie Curie, known for h...   \n",
       "2  US State Secretary Mike Pompeo has announced t...   \n",
       "3  British DJ Paul Oakenfold on Tuesday performed...   \n",
       "4  Bihar's Somesh Choudhary, a ticket examiner in...   \n",
       "\n",
       "                                             summary  text_len  summary_len  \\\n",
       "0  No telecast of Real Kashmir vs Chennai City du...       327           55   \n",
       "1  Marie Curie unknowingly died due to her own di...       350           53   \n",
       "2  US to revoke visas of 21 Saudis involved in jo...       377           60   \n",
       "3  British DJ Paul Oakenfold performs concert at ...       353           59   \n",
       "4  Indian Railways employee asked PNR full form o...       368           66   \n",
       "\n",
       "                                       text_stripped  \\\n",
       "0  the I League organiser say on Monday that the ...   \n",
       "1  Poland bear scientist Marie Curie know for -PR...   \n",
       "2  US State Secretary Mike Pompeo have announce t...   \n",
       "3  british DJ Paul Oakenfold on Tuesday perform a...   \n",
       "4  Bihars Somesh Choudhary a ticket examiner in I...   \n",
       "\n",
       "                                    summary_stripped  \n",
       "0  no telecast of Real Kashmir vs Chennai City du...  \n",
       "1  Marie Curie unknowingly die due to -PRON- own ...  \n",
       "2  US to revoke visa of 21 Saudis involve in jour...  \n",
       "3  british DJ Paul Oakenfold perform concert at M...  \n",
       "4  Indian Railways employee ask PNR full form on ...  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data as separate datasets:\n",
    "* train\n",
    "* val\n",
    "* test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data[['text_stripped', 'summary_stripped']].to_csv('../data/news-summary-kaggle/news_train.csv')\n",
    "val_data[['text_stripped', 'summary_stripped']].to_csv('../data/news-summary-kaggle/news_val.csv')\n",
    "test_data[['text_stripped', 'summary_stripped']].to_csv('../data/news-summary-kaggle/news_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_en(text):\n",
    "    text=re.sub(\"(\\\\t)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\\\r)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\\\n)\", ' ', str(text))\n",
    "\n",
    "    text=re.sub(\"(__+)\", ' ', str(text))\n",
    "    text=re.sub(\"(-+)\", ' ', str(text))\n",
    "    text=re.sub(\"(~~+)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\+\\++)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\.\\.+)\", ' ', str(text))\n",
    "\n",
    "    text=re.sub(\"(\\.\\s+)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\-\\s+)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\:\\s+)\", ' ', str(text))\n",
    "\n",
    "    text=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", '', str(text))\n",
    "    return [tok.text for tok in nlp.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(batch_size):\n",
    "    TEXT = Field(tokenize=tokenize_en, include_lengths=True,\n",
    "                 init_token='<sos>', eos_token='<eos>')\n",
    "    SUMMARY = Field(tokenize=tokenize_en, include_lengths=True,\n",
    "                    init_token='<sos>', eos_token='<eos>')\n",
    "    train, val, test = TabularDataset.splits(\n",
    "        skip_header=True, \n",
    "        path='../data/news-summary-kaggle/', format='csv', \n",
    "        fields=[('index', None), ('text', TEXT), ('summary', SUMMARY), ],\n",
    "        train='news_train.csv', validation='news_val.csv', test='news_test.csv'\n",
    "    )\n",
    "    TEXT.build_vocab(train, min_freq=2)\n",
    "    SUMMARY.vocab = TEXT.vocab\n",
    "    train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "        (train, val, test), \n",
    "        batch_size=batch_size, \n",
    "        sort_key=lambda x: interleave_keys(len(x.text), len(x.summary)), \n",
    "        sort=True, \n",
    "        repeat=False,\n",
    "    )\n",
    "    return train_iter, val_iter, test_iter, TEXT, SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter, TEXT, SUMMARY = load_dataset(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_from_text(text, lang=TEXT):\n",
    "    indices = []\n",
    "    for word in text.strip().split(' '):\n",
    "        indices.append(lang.vocab.stoi[word])\n",
    "    return torch.LongTensor(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_indices(indices, lang=TEXT):\n",
    "    text = \"\"\n",
    "    for element in indices:\n",
    "        if type(element) is torch.Tensor:\n",
    "            text += lang.vocab.itos[element.item()] + \" \"\n",
    "        else:\n",
    "            text += lang.vocab.itos[element] + \" \"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> Actor Diljit Dosanjhs look from the upcoming comedy film Arjun Patiala have be reveal Diljit can be see dress as a police officer in the first look direct by filmmaker Rohit Jugraj and also star actor Varun Sharma and Kriti Sanon Arjun Patiala be schedule to release on September 13 . <eos> '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_from_indices(batch.text[0][:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> Diljit Dosanjhs look from Arjun Patiala reveal <eos> <pad> <pad> <pad> <pad> <pad> <pad> '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_from_indices(batch.summary[0][:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, n_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, n_layers,\n",
    "                          dropout=dropout, bidirectional=True)\n",
    "\n",
    "    def forward(self, sequence, hidden=None):\n",
    "        embedding_output = self.embedding(sequence) # max_text_len x batch_size x embedding_size\n",
    "        encoder_outputs, hidden = self.gru(embedding_output, hidden)\n",
    "        # hidden: bidirectional x batch_size x hidden_size\n",
    "        # output: max_text_len x batch_size x bidirectional * hidden_size\n",
    "        encoder_outputs = encoder_outputs[:, :, :self.hidden_size] + encoder_outputs[:, :, self.hidden_size:]\n",
    "        # output: max_text_len x batch_size x hidden_size\n",
    "        return encoder_outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "        stdv = 1. / math.sqrt(self.v.size(0))\n",
    "        self.v.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        timestep = encoder_outputs.size(0)\n",
    "        h = hidden.repeat(timestep, 1, 1).transpose(0, 1)\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1) \n",
    "        attn_energies = self.score(h, encoder_outputs) # batch_size x t x hidden\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1) # batch_size x t\n",
    "\n",
    "    def score(self, hidden, encoder_outputs):\n",
    "        # batch_size x t x 2*hidden -> batch_size x t x hidden\n",
    "        energy = F.tanh(self.attention(torch.cat([hidden, encoder_outputs], 2)))\n",
    "        energy = energy.transpose(1, 2) # batch_size x t x 2*hidden -> batch_size x t x hidden\n",
    "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1) # batch_size x 1 x hidden\n",
    "        energy = torch.bmm(v, energy) # batch_size x 1 x t\n",
    "        return energy.squeeze(1) # batch_size x t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout, inplace=True)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size + embedding_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.output = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, sequence, hidden, encoder_outputs):\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        embedding_output = self.embedding(sequence).unsqueeze(0)  # 1 x batch_size x n\n",
    "        embedding_output = self.dropout(embedding_output)\n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attention_weights = self.attention(hidden[-1], encoder_outputs)\n",
    "        context = attention_weights.bmm(encoder_outputs.transpose(0, 1)) # batch_size x 1 x n\n",
    "        context = context.transpose(0, 1)  # (1,B,N)\n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        decoder_input = torch.cat([embedding_output, context], 2)\n",
    "        decoder_output, hidden = self.gru(decoder_input, hidden)\n",
    "        decoder_output = decoder_output.squeeze(0)  # (1,B,N) -> (B,N)\n",
    "        context = context.squeeze(0)\n",
    "        decoder_output = self.output(torch.cat([decoder_output, context], 1))\n",
    "        decoder_output = F.log_softmax(decoder_output, dim=1)\n",
    "        return decoder_output, hidden, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, text, summary, teacher_forcing_ratio=0.5):\n",
    "        batch_size = text.size(1)\n",
    "        max_len = summary.size(0)\n",
    "        vocab_size = self.decoder.output_size\n",
    "\n",
    "        encoder_output, hidden = self.encoder(text)\n",
    "        hidden = hidden[:self.decoder.n_layers]\n",
    "        output = Variable(summary.data[0, :])  # sos\n",
    "        \n",
    "        outputs = Variable(torch.zeros(max_len, batch_size, vocab_size))\n",
    "        for t in range(1, max_len):\n",
    "            output, hidden, attention_weights = self.decoder(\n",
    "                    output, hidden, encoder_output)\n",
    "            outputs[t] = output\n",
    "            is_teacher = random.random() < teacher_forcing_ratio\n",
    "            top_first = output.data.max(1)[1]\n",
    "            output = Variable(summary.data[t] if is_teacher else top_first)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(e, model, optimizer, scheduler, train_iter, vocab_size, grad_clip, lang=TEXT):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pad = lang.vocab.stoi['<pad>']\n",
    "    for b, batch in tqdm_notebook(enumerate(train_iter), total=len(train_iter)):\n",
    "        text, len_text = batch.text\n",
    "        summary, len_summary = batch.summary\n",
    "        optimizer.zero_grad()\n",
    "        output = model(text, summary)\n",
    "        loss = F.nll_loss(\n",
    "            output[1:].view(-1, vocab_size),\n",
    "            summary[1:].contiguous().view(-1),\n",
    "            ignore_index=pad,\n",
    "        )\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.data\n",
    "\n",
    "        if b % 10 == 0 and b != 0:\n",
    "            total_loss = total_loss / 100\n",
    "            print(f'[{b}] [loss: {total_loss}] [loss_exp: {math.exp(total_loss)}]')\n",
    "            total_loss = 0\n",
    "        if b % 10 == 0 and b != 0:\n",
    "            target_summary = text_from_indices(summary.transpose(0, 1)[0])\n",
    "            output_summary = summarize(text_from_indices(text.transpose(0, 1)[0]))[0]\n",
    "            print('Original :', text_from_indices(text.transpose(0, 1)[0]))\n",
    "            print(['-' * 80])\n",
    "            print('Target :', target_summary)\n",
    "            print(['-' * 80])\n",
    "            print('Summary :', output_summary)\n",
    "            print(['=' * 80])\n",
    "            scores = calculate_rouge(hypothesis=output_summary, reference=target_summary)\n",
    "            for key, value in scores[0].items():\n",
    "                print(f'{key.upper()} [precision] : {np.round(value[\"p\"] * 100, 2)}'\n",
    "                      '| [recall] : {np.round(value[\"r\"] * 100, 2)}'\n",
    "                      '| [f-score] : {np.round(value[\"f\"] * 100, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter, vocab_size, lang=TEXT):\n",
    "    model.eval()\n",
    "    pad = lang.vocab.stoi['<pad>']\n",
    "    total_loss = 0\n",
    "    for b, batch in enumerate(val_iter):\n",
    "        text, len_text = batch.text\n",
    "        summary, len_summary = batch.summary\n",
    "        text = Variable(text.data, volatile=True)\n",
    "        summary = Variable(summary.data, volatile=True)\n",
    "        output = model(text, summary, teacher_forcing_ratio=0.0)\n",
    "        loss = F.nll_loss(\n",
    "            output[1:].view(-1, vocab_size),\n",
    "            summary[1:].contiguous().view(-1),\n",
    "            ignore_index=pad,\n",
    "        )\n",
    "        total_loss += loss.data\n",
    "    return total_loss / len(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge(hypothesis, reference):\n",
    "    hypothesis = hypothesis.split('<sos>')[1].split('<eos>')[0].strip()\n",
    "    reference = reference.split('<sos>')[1].split('<eos>')[0].strip()\n",
    "    scores = rouge.get_scores(hypothesis, reference)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text):\n",
    "    with torch.no_grad():\n",
    "        sequence = indices_from_text(text).unsqueeze(0)\n",
    "        sequence_length = sequence.size(1)\n",
    "        encoder_output, encoder_hidden = encoder(sequence.transpose(0, 1))\n",
    "        \n",
    "        decoder_input = Variable(torch.LongTensor([indices_from_text(TEXT.init_token)]))\n",
    "        hidden = encoder_hidden[:decoder.n_layers]\n",
    "        summary_words = ['<sos>']\n",
    "        max_summary_length = int(sequence_length * 0.25)\n",
    "        decoder_attentions = torch.zeros(max_summary_length, sequence_length)\n",
    "        for idx in range(max_summary_length):\n",
    "            output, hidden, decoder_attention = decoder(\n",
    "                decoder_input, \n",
    "                hidden, \n",
    "                encoder_output,\n",
    "            )\n",
    "            decoder_attentions[idx, :decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).data\n",
    "            top_v, top_i = output.data.topk(1)\n",
    "            ni = top_i[0]\n",
    "            if ni == indices_from_text(TEXT.eos_token):\n",
    "                break\n",
    "            else:\n",
    "                summary_words.append(text_from_indices(ni))\n",
    "            \n",
    "            decoder_input = Variable(torch.LongTensor([ni]))\n",
    "        summary_words.append(TEXT.eos_token)\n",
    "        summary = \" \".join(summary_words).lstrip()\n",
    "        return summary, decoder_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr = 0.01\n",
    "grad_clip = 10.0\n",
    "scheduler_step_size = 50\n",
    "scheduler_gamma = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "embed_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] preparing dataset...\n",
      "[TRAIN]: 1274 | 81498\t [TEST]: 160 | 10188\n",
      "[TEXT_vocab] & [SUMMARY_vocab] (same) 50576\n"
     ]
    }
   ],
   "source": [
    "print(f'[!] preparing dataset...')\n",
    "text_size, summary_size = len(TEXT.vocab), len(SUMMARY.vocab)\n",
    "print(f'[TRAIN]: {len(train_iter)} | {len(train_iter.dataset)}\\t [TEST]: {len(test_iter)} | {len(test_iter.dataset)}')\n",
    "print(f'[TEXT_vocab] & [SUMMARY_vocab] (same) {text_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Instantiating models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): EncoderRNN(\n",
      "    (embedding): Embedding(50576, 128)\n",
      "    (gru): GRU(128, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
      "  )\n",
      "  (decoder): DecoderRNN(\n",
      "    (embedding): Embedding(50576, 128)\n",
      "    (dropout): Dropout(p=0.5, inplace=True)\n",
      "    (attention): BahdanauAttention(\n",
      "      (attention): Linear(in_features=512, out_features=256, bias=True)\n",
      "    )\n",
      "    (gru): GRU(384, 256, dropout=0.5)\n",
      "    (output): Linear(in_features=512, out_features=50576, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"[!] Instantiating models...\")\n",
    "encoder = EncoderRNN(text_size, embed_size, hidden_size,\n",
    "                  n_layers=2, dropout=0.5)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, text_size,\n",
    "                  n_layers=1, dropout=0.5)\n",
    "seq2seq = Seq2Seq(encoder, decoder)\n",
    "optimizer = optim.Adam(seq2seq.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step_size, gamma=scheduler_gamma)\n",
    "print(seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c362f563cb746d3a4cbccdb1f179024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41eba882cd74f58be090b817459b44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1274.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] [loss: 0.790608823299408] [loss_exp: 2.20473831378282]\n",
      "Original : <sos> researcher associate with CERN be work on a project to translate datum generate by the Large Hadron Collider world large particle accelerator into piano music researcher hope the <unk> process could reveal pattern and concept miss during traditional scientific analysis the musical note compose use simulation would be perform by professional pianist . <eos> \n",
      "['--------------------------------------------------------------------------------']\n",
      "Target : <sos> world large accelerator datum to be translate for piano <eos> \n",
      "['--------------------------------------------------------------------------------']\n",
      "Summary : <sos> <unk>  to  to  to  to  to  to  to  be  to  to  be  to  <eos>\n",
      "['================================================================================']\n",
      "ROUGE-1 [precision] : 15.38| [recall] : {np.round(value[\"r\"] * 100, 2)}| [f-score] : {np.round(value[\"f\"] * 100, 2)}\n",
      "ROUGE-2 [precision] : 8.33| [recall] : {np.round(value[\"r\"] * 100, 2)}| [f-score] : {np.round(value[\"f\"] * 100, 2)}\n",
      "ROUGE-L [precision] : 66.67| [recall] : {np.round(value[\"r\"] * 100, 2)}| [f-score] : {np.round(value[\"f\"] * 100, 2)}\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "for e in notebook.tqdm(range(1, epochs+1)):\n",
    "    train(e, seq2seq, optimizer, scheduler, train_iter, text_size, grad_clip, TEXT)\n",
    "    val_loss = evaluate(seq2seq, val_iter, text_size, TEXT)\n",
    "    print(f'[Epoch: {e}] val_loss: {val_loss} | val_pp: {math.exp(val_loss)}')\n",
    "\n",
    "    # Save the model if the validation loss is the best we've seen so far.\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        print(\"[!] saving model...\")\n",
    "        if not os.path.isdir(\".save\"):\n",
    "            os.makedirs(\".save\")\n",
    "        torch.save(seq2seq.state_dict(), './.save/seq2seq_%d.pt' % (e))\n",
    "        best_val_loss = val_loss\n",
    "test_loss = evaluate(seq2seq, test_iter, text_size, TEXT)\n",
    "print(f'[TEST] loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
