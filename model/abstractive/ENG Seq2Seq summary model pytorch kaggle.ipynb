{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import notebook, tqdm_notebook\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob('../input/summary-data-split/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_en(text):\n",
    "    text=re.sub(\"(\\\\t)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\\\r)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\\\n)\", ' ', str(text))\n",
    "\n",
    "    text=re.sub(\"(__+)\", ' ', str(text))\n",
    "    text=re.sub(\"(-+)\", ' ', str(text))\n",
    "    text=re.sub(\"(~~+)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\+\\++)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\.\\.+)\", ' ', str(text))\n",
    "\n",
    "    text=re.sub(\"(\\.\\s+)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\-\\s+)\", ' ', str(text))\n",
    "    text=re.sub(\"(\\:\\s+)\", ' ', str(text))\n",
    "\n",
    "    text=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", '', str(text))\n",
    "    return [tok.text for tok in nlp.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(batch_size):\n",
    "    TEXT = Field(tokenize=tokenize_en, include_lengths=True,\n",
    "                 init_token='<sos>', eos_token='<eos>')\n",
    "    SUMMARY = Field(tokenize=tokenize_en, include_lengths=True,\n",
    "                    init_token='<sos>', eos_token='<eos>')\n",
    "    train, val, test = TabularDataset.splits(\n",
    "        skip_header=True, \n",
    "        path='../input/summary-data-split/', format='csv', \n",
    "        fields=[('text', TEXT), ('summary', SUMMARY)],\n",
    "        train='news_train.csv', validation='news_val.csv', test='news_test.csv'\n",
    "    )\n",
    "    TEXT.build_vocab(train, min_freq=2)\n",
    "#     SUMMARY.build_vocab(train, min_freq=2)\n",
    "    SUMMARY.vocab = TEXT.vocab\n",
    "    train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "        (train, val, test), batch_size=batch_size, repeat=False, sort_key=lambda x: len(x.text), sort_within_batch=False\n",
    "    )\n",
    "    return train_iter, val_iter, test_iter, TEXT, SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter, TEXT, SUMMARY = load_dataset(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_from_text(text, lang=TEXT):\n",
    "    indices = []\n",
    "    for word in text.strip().split(' '):\n",
    "        indices.append(lang.vocab.stoi[word])\n",
    "    return Variable(torch.LongTensor(indices)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_indices(indices, lang=TEXT):\n",
    "    text = \"\"\n",
    "    for element in indices:\n",
    "        if type(element) is torch.Tensor:\n",
    "            text += lang.vocab.itos[element.item()] + \" \"\n",
    "        else:\n",
    "            text += lang.vocab.itos[element] + \" \"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_from_indices(next(iter(train_iter)).text[0].transpose(0, 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_from_indices(next(iter(train_iter)).summary[0].transpose(0, 1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, n_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, n_layers,\n",
    "                          dropout=dropout, bidirectional=True)\n",
    "\n",
    "    def forward(self, sequence, hidden=None):\n",
    "        embedding_output = self.embedding(sequence).cuda() # max_text_len x batch_size x embedding_size\n",
    "        encoder_outputs, hidden = self.gru(embedding_output, hidden)\n",
    "        # hidden: bidirectional x batch_size x hidden_size\n",
    "        # output: max_text_len x batch_size x bidirectional * hidden_size\n",
    "        encoder_outputs = encoder_outputs[:, :, :self.hidden_size] + encoder_outputs[:, :, self.hidden_size:]\n",
    "        # output: max_text_len x batch_size x hidden_size\n",
    "        encoder_outputs = encoder_outputs.cuda()\n",
    "        return encoder_outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "        stdv = 1. / math.sqrt(self.v.size(0))\n",
    "        self.v.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        timestep = encoder_outputs.size(0)\n",
    "        h = hidden.repeat(timestep, 1, 1).transpose(0, 1)\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1) \n",
    "        attn_energies = self.score(h, encoder_outputs) # batch_size x t x hidden\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1) # batch_size x t\n",
    "\n",
    "    def score(self, hidden, encoder_outputs):\n",
    "        # batch_size x t x 2*hidden -> batch_size x t x hidden\n",
    "        energy = torch.tanh(self.attention(torch.cat([hidden, encoder_outputs], 2)))\n",
    "        energy = energy.transpose(1, 2) # batch_size x t x 2*hidden -> batch_size x t x hidden\n",
    "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1) # batch_size x 1 x hidden\n",
    "        energy = torch.bmm(v, energy) # batch_size x 1 x t\n",
    "        return energy.squeeze(1) # batch_size x t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout, inplace=True)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size + embedding_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.output = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, sequence, hidden, encoder_outputs):\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        embedding_output = self.embedding(sequence).unsqueeze(0).cuda()  # 1 x batch_size x n\n",
    "        embedding_output = self.dropout(embedding_output)\n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attention_weights = self.attention(hidden[-1], encoder_outputs).cuda()\n",
    "        context = attention_weights.bmm(encoder_outputs.transpose(0, 1)) # batch_size x 1 x n\n",
    "        context = context.transpose(0, 1)  # (1,B,N)\n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        decoder_input = torch.cat([embedding_output, context], 2)\n",
    "        decoder_output, hidden = self.gru(decoder_input, hidden)\n",
    "        decoder_output = decoder_output.squeeze(0)  # (1,B,N) -> (B,N)\n",
    "        context = context.squeeze(0)\n",
    "        decoder_output = self.output(torch.cat([decoder_output, context], 1))\n",
    "        decoder_output = F.log_softmax(decoder_output, dim=1)\n",
    "        return decoder_output, hidden, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, text, summary, teacher_forcing_ratio=0.5):\n",
    "        batch_size = text.size(1)\n",
    "        max_len = summary.size(0)\n",
    "        vocab_size = self.decoder.output_size\n",
    "\n",
    "        encoder_output, hidden = self.encoder(text)\n",
    "        hidden = hidden[:self.decoder.n_layers]\n",
    "        output = Variable(summary.data[0, :]).cuda()  # sos\n",
    "        \n",
    "        outputs = Variable(torch.zeros(max_len, batch_size, vocab_size)).cuda()\n",
    "        for t in range(1, max_len):\n",
    "            output, hidden, attention_weights = self.decoder(\n",
    "                    output, hidden, encoder_output)\n",
    "            outputs[t] = output\n",
    "            is_teacher = random.random() < teacher_forcing_ratio\n",
    "            top_first = output.data.max(1)[1]\n",
    "            output = Variable(summary.data[t] if is_teacher else top_first).cuda()\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(e, model, optimizer, scheduler, train_iter, vocab_size, grad_clip, lang=TEXT):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pad = lang.vocab.stoi['<pad>']\n",
    "    for b, batch in notebook.tqdm(enumerate(train_iter), total=len(train_iter)):\n",
    "        text, len_text = batch.text\n",
    "        summary, len_summary = batch.summary\n",
    "        text, summary = text.cuda(), summary.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(text, summary)\n",
    "        loss = F.nll_loss(\n",
    "            output[1:].view(-1, vocab_size),\n",
    "            summary[1:].contiguous().view(-1),\n",
    "            ignore_index=pad,\n",
    "        )\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.data\n",
    "\n",
    "        if b % 10 == 0 and b != 0:\n",
    "            total_loss = total_loss / 100\n",
    "            print(f'[{b}] [loss: {total_loss}] [loss_exp: {math.exp(total_loss)}]')\n",
    "            total_loss = 0\n",
    "        if b % 50 == 0 and b != 0:\n",
    "            target_summary = text_from_indices(summary.transpose(0, 1)[0])\n",
    "            output_summary = summarize(text_from_indices(text.transpose(0, 1)[0]))[0]\n",
    "            print('Original :', text_from_indices(text.transpose(0, 1)[0]))\n",
    "            print(['-' * 80])\n",
    "            print('Target :', target_summary)\n",
    "            print(['-' * 80])\n",
    "            print('Summary :', output_summary)\n",
    "            print(['=' * 80])\n",
    "            scores = calculate_rouge(hypothesis=output_summary, reference=target_summary)\n",
    "            for key, value in scores[0].items():\n",
    "                print(f'{key.upper()} [precision] : {np.round(value[\"p\"] * 100, 2)}'\n",
    "                      '| [recall] : {np.round(value[\"r\"] * 100, 2)}'\n",
    "                      '| [f-score] : {np.round(value[\"f\"] * 100, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter, vocab_size, lang=TEXT):\n",
    "    with torch.no_grad():\n",
    "        pad = lang.vocab.stoi['<pad>']\n",
    "        total_loss = 0\n",
    "        for b, batch in enumerate(val_iter):\n",
    "            text, len_text = batch.text\n",
    "            summary, len_summary = batch.summary\n",
    "#             text = Variable(text.data, volatile=True)\n",
    "#             summary = Variable(summary.data, volatile=True)\n",
    "            text = Variable(text.data.cuda(), volatile=True)\n",
    "            summary = Variable(summary.data.cuda(), volatile=True)\n",
    "            output = model(text, summary, teacher_forcing_ratio=0.0)\n",
    "            loss = F.nll_loss(\n",
    "                output[1:].view(-1, vocab_size),\n",
    "                summary[1:].contiguous().view(-1),\n",
    "                ignore_index=pad,\n",
    "            )\n",
    "            total_loss += loss.data\n",
    "        return total_loss / len(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge(hypothesis, reference):\n",
    "    hypothesis = hypothesis.split('<sos>')[1].split('<eos>')[0].strip()\n",
    "    reference = reference.split('<sos>')[1].split('<eos>')[0].strip()\n",
    "    scores = rouge.get_scores(hypothesis, reference)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text):\n",
    "    with torch.no_grad():\n",
    "        sequence = indices_from_text(text).unsqueeze(0)\n",
    "        sequence_length = sequence.size(1)\n",
    "        encoder_outputs, encoder_hidden = encoder(sequence.transpose(0, 1))\n",
    "        \n",
    "        decoder_input = Variable(torch.LongTensor([indices_from_text(TEXT.init_token)])).cuda()\n",
    "        hidden = encoder_hidden[:decoder.n_layers]\n",
    "        summary_words = ['<sos>']\n",
    "        max_summary_length = int(sequence_length * 0.25)\n",
    "        decoder_attentions = torch.zeros(max_summary_length, sequence_length)\n",
    "        \n",
    "        for idx in range(max_summary_length):\n",
    "            output, hidden, decoder_attention = decoder(\n",
    "                decoder_input, \n",
    "                hidden, \n",
    "                encoder_outputs,\n",
    "            )\n",
    "            decoder_attentions[idx, :decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "            top_v, top_i = output.data.topk(1)\n",
    "            ni = top_i[0]\n",
    "            if ni == indices_from_text(TEXT.eos_token):\n",
    "                break\n",
    "            else:\n",
    "                summary_words.append(text_from_indices(ni))\n",
    "            \n",
    "            decoder_input = Variable(torch.LongTensor([ni])).cuda()\n",
    "        summary_words.append(TEXT.eos_token)\n",
    "        summary = \" \".join(summary_words).lstrip()\n",
    "        return summary, decoder_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr = 0.01\n",
    "grad_clip = 10.0\n",
    "scheduler_step_size = 50\n",
    "scheduler_gamma = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "embed_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'[!] preparing dataset...')\n",
    "text_size, summary_size = len(TEXT.vocab), len(SUMMARY.vocab)\n",
    "print(f'[TRAIN]: {len(train_iter)} | {len(train_iter.dataset)}\\t [TEST]: {len(test_iter)} | {len(test_iter.dataset)}')\n",
    "print(f'[TEXT_vocab] & [SUMMARY_vocab] (same) {text_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[!] Instantiating models...\")\n",
    "encoder = EncoderRNN(text_size, embed_size, hidden_size,\n",
    "                  n_layers=2, dropout=0.5)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, text_size,\n",
    "                  n_layers=1, dropout=0.5)\n",
    "seq2seq = Seq2Seq(encoder, decoder).cuda()\n",
    "optimizer = optim.Adam(seq2seq.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step_size, gamma=scheduler_gamma)\n",
    "print(seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = None\n",
    "for e in notebook.tqdm(range(1, epochs+1)):\n",
    "    train(e, seq2seq, optimizer, scheduler, train_iter, text_size, grad_clip, TEXT)\n",
    "    val_loss = evaluate(seq2seq, val_iter, text_size, TEXT)\n",
    "    print(f'[Epoch: {e}] val_loss: {val_loss} | val_pp: {math.exp(val_loss)}')\n",
    "\n",
    "    # Save the model if the validation loss is the best we've seen so far.\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        print(\"[!] saving model...\")\n",
    "        if not os.path.isdir(\".save\"):\n",
    "            os.makedirs(\".save\")\n",
    "        torch.save(seq2seq.state_dict(), './.save/seq2seq_%d.pt' % (e))\n",
    "        best_val_loss = val_loss\n",
    "test_loss = evaluate(seq2seq, test_iter, text_size, TEXT)\n",
    "print(f'[TEST] loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob('../working/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'../working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(seq2seq.state_dict(), 'seq2seq_10.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
