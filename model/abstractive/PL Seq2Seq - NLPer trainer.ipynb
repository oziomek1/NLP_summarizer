{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import spacy\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../NLPer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlper.utils.lang_utils import Token\n",
    "from nlper.trainer.data_loader import DataLoader\n",
    "from nlper.utils.lang_utils import VocabConfig\n",
    "\n",
    "from nlper.utils.torch_utils import get_device\n",
    "from nlper.utils.torch_utils import AVAILABLE_GPU\n",
    "\n",
    "from nlper.utils.train_utils import calculate_rouge\n",
    "from nlper.utils.train_utils import draw_attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=f\"%(asctime)s [%(levelname)s] | %(name)s | %(funcName)s: %(message)s\",\n",
    "    level=logging.INFO,\n",
    "    datefmt='%I:%M:%S',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../NLPer/resources/output/trimmed_all_data/val.csv',\n",
       " '../../NLPer/resources/output/trimmed_all_data/test.csv',\n",
       " '../../NLPer/resources/output/trimmed_all_data/train.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('../../NLPer/resources/output/trimmed_all_data/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>niezbyt liczny zgromadzenie być bodaj pierwszy demonstracja protest który odbyć się w Rosja po ogłoszenie w czwartka decyzja o podniesienie wieko emerytalny . wiece organizować m.in. partia emeryt a wziąć w on udział aktywista radykalny front lewica jak i zwolennik jeden z przywódca opozycja antykremlowskiej Aleksiej nawalnego . uczestnik protest przynieść na wiece plakata głosić nie dla podniesienie wieko emerytalny i nie chcieć umrzeć w praca . żądać dymisja premier dmitrija miedwiediewa . pojawić się także hasło putin rosja &lt;num&gt; &lt;num&gt; nawiązywać do wynik czwartkowy mecz między reprezentacja Rosja i Arabia saudyjski . mecz ten zainaugurować odbywać się w Rosja mistrzostwo świat w piłka nożny . ten sam dzień rząd ogłosić plan stopniowy podwyższania od przyszły rok wieko emerytalny . dziennik wiedomosti podać w sobota powoływać się na źródło na kreml że władza Rosja niepokoić się perspektywa protest społeczny . decyzja o podniesienie wieko emerytalny według ekonomista nieunikniony być długo odkładać bowiem być bardzo popularny w społeczeństwo . obecny wieko emerytalny w Rosja to &lt;num&gt; rok dla mężczyzna i &lt;num&gt; dla kobieta . rząd chcieć podnieść ten próg do &lt;num&gt; rok dla mężczyzna i &lt;num&gt; dla kobieta przy co proces ten mieć być rozłożyć na bliski &lt;num&gt; &lt;num&gt; rok . petycja przeciw podniesienie wieko emerytalny skierować do prezydent Władimir Putin premier dmitrija miedwiediewa i władza oba izba parlament Rosja pojawić się w internet na strona change.org . podpisać on do piątek &lt;num&gt; tys. osoba . autor petycja przywoływać statystyka mówić o to iż w &lt;num&gt; region federacja rosyjski średnia prognozować długość życie być niski niż &lt;num&gt; rok . według dane rosyjski ministerstwo zdrowie ogół przeciętny długość życie przekroczyć w Rosja &lt;num&gt; rok . przy co dla kobieta wskaźnik ten wynosić ponad &lt;num&gt; rok a dla mężczyzna &lt;num&gt; rok . z Moskwa anna wróbel papa awl mobr mrr</th>\n",
       "      <td>rosja w Nowosybirsk odbyć się wiece przeciwko ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resovia &lt;num&gt; lokat w środa niby tylko zremisować ale warto zauważyć że wcześnie pelikan u siebie wszystek rywal odprawiać z kwitek . w ekipa z Wolbrom &lt;num&gt; grać kilka groźny zawodnik jak rak dudziński ale bardzo znany być trener . Antonie szymanowski to obrońca słynny drużyna Kazimierz Górski . coach przebój znany być z to że lubić sobie ponarzekać . być nieźle gdyby w sobota mieć ku to rzeczywisty powód . przebój nie być tak mocny jak kilka rok temu jednak mieć parę rutyniarz . bardzo chcieć się zrehabilitować za mecz z rucho mówić hajda . mecz w Brzesko będzie mieć wiele dodatkowy smaczek . wielki to fakt iż Czesława palik coach stal niedawno trenować okocimskiego wprowadzić on do zreformować ii liga i mieć do dyspozycja Ireneusz Gryboś obecnie gracz stal . w skład piwosz grać kilka były stalowiec Ogara Popiel matras szósty ekipa tabela dowodzić Krzysztofa łętocha były zawodnik stal swój czas wymieniać jako kandydat do on trenowania . łętiemu i on piłkarz ostatnio iść szczególnie na wyjazd . wiedzieć że potrafić grać w piłka widziałem jak pokonać w puchar resovię podkreślać palik . trochę mój serce w Brzesko zostać . trenowałem niemal wszystek obecny gracz ten drużyna . ten wiedza się przydać . w obóz biało niebieski panować średni nastrój . kontuzja załapać Wojciechy krauze naciągnięcie mięsień dwugłowy zbić podbicie mieć serges kiema . jeśli dodać do to że ibrahim sunday dopiero odbudowywać forma gryboś wracać po kontuzja a udoudo ciągle pudłować szansa stal nie wyglądać za dobrze . wesoło nie być ale zawsze starać się myśleć pozytywnie i zarażać ten piłkarz . będziemy walczyć o punkt zakończyć trener rzeszowianin . resovia Barany kontuzja stal solecki cieślik federkiewicz krauze kiema . kontuzja .</th>\n",
       "      <td>resovia zagrać z przebój wolbrom Stala w Brzes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>być gnijąca panna młody i być eksplodującysamsung galaxy note &lt;num&gt; samsung wstrzymać produkcja urządzenie i namawiać on posiadacz do dokonywania zwrot . a co w ten sytuacja z pozostały akcesorium . przeważnie wydatek związane z zakup smartfon nie kończyć się jedynie na nabycie słuchawka . który użytkownik potrzebować też dodatkowy akcesorium taki jak wymienny obudowa pokrowiec dodatkowy bateria smyczek zapasowy ładowarka ładowarka samochodowy ładowarka bezprzewodowy zestaw słuchawkowy … . większość z on trzeba kupić na wolny rynek w własny zakres gdyż producent nie dołączać on do zestaw . czytać też samsung zostać pozwać za swój polityka aktualizacja androidawarto przy to nadmienić iż ten typ akcesorium można podzielić jeszcze na dwa podgrupa oficjalny przygotować przez producent telefon specjalnie na on potrzeba oraz oficjalny który zewnętrzny firma po prosty starać się dopasować do możliwość konkretny model urządzenie a czas nawet o zupełnie uniwersalny właściwość . w oblicze wycofywania z sprzedaż samsunga galaxy note &lt;num&gt; na łam portaluthe vergepojawiło się uzasadniony pytanie o to co w taki sytuacja mieć zrobić osoba który zdecydować się na zakup akcesorium do swój smartfon a teraz z wzgląd bezpieczeństwo prawdopodobnie będą musieć on oddać i samsung albo zwrócić on pieniądz albo namówić do zamiana na zupełnie wybuchowy samsunga galaxy edge &lt;num&gt; otóż jak donosić użytkownik reddita amerykański wykop sklep amazon przyjmować zwrot akcesorium do note &lt;num&gt; i to nie tylko w ramy swój standardowy polityka zwrot &lt;num&gt; dzień od moment dokonanie zakup . to się bardzo chwalić ponieważ kwestia zwrot akcesorium w światło przepis prawo szczególnie polski nie być tak jednoznaczny . przy próba skorzystania z rękojmia należałoby bowiem stwierdzić iż sprzedać akcesorium posiadać wada fizyczny w rozumienie kodeksowy a nie potoczny lub prawny co w sytuacja gdy samsung tylko namawiać do zwrot urządzenie nie wydawać się do koniec adekwatny zastosowanie ten przepis . z drugi strona akurat samsung szczególnie w zakres akcesorium ściśle dedykowanych note &lt;num&gt; powinien wykazać inicjatywa w który namawiać sprzedawca do przyjmowania zwrot co w praktyka nie zawsze być możliwy wbrew powszechny opinia zachłanny sprzedawca bardzo często bywać dla ugodowy producent utrapienie . potrafić sobie wyobrazić bowiem scenariusz w który posiadacz niezwracalnych akcesorium dedykowanych note &lt;num&gt; móc domagać się od samsunga odszkodowanie z tytuł ponieść koszt który zaowocować przydatny kawałek skóra czy plastik .</th>\n",
       "      <td>samsung przyjąć zwrot eksplodującego note &lt;num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nasz kluba &lt;num&gt; lokat przystać na prośba limblachu i zgodzić się na zmiana gospodarz spotkanie . limanowianin zajmować &lt;num&gt; miejsce i mieć punkt dużo od akademik . zaskakiwać in plus ale nie zamierzać już przegrywać u siebie . do skład po kontuzja wracać marka osiniak mówić Filipy kosim ii trener azs u. możliwy że za tydzień do gra wrócić inny rekonwalescent piotr ucinka a z koniec rok zwichnąć palec wyleczyć Jakuby musijowski . w drużyna limblachu grać dwa koszykarz znany z boisko nasz regonu rozgrywający piotr kindlik wychowanka Polonia przemyśl oraz skrzydłowy andrzej peciak były zawodnik glimaru gorlice siarka tarnobrzeg i Polonia . mecz o &lt;num&gt;</th>\n",
       "      <td>politechnika rzeszowski zapraszać na sobota ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dotacja być pomysł Witold walawendra radego rozwój Rzeszów . sum na kolano nie rzucać problem klub nie rozwiązać ale pomóc on dociągnąć do koniec rok . być wdzięczny co nie zmieniać fakt że jeśli mieć utrzymać się na poziom ii liga potrzebować wielki wsparcie podkreślać jacek szczepaniak . prezes sekcja piłkarski stal oceniać że dotacja stanowić &lt;num&gt; procent budżet sekcja . aby normalnie funkcjonować musić wydać w runda milion złoty . &lt;num&gt; procent z to to koszt organizacyjny . resovia otrzymać &lt;num&gt; tysiąc . to według prezes Aleksander Bentkowski około &lt;num&gt; procent budżet na sezon . sprawiedliwy podział . sala być w wysoki liga mieć wyjazd na drugi koniec Polska więc zrozumiały że otrzymać więcej . my w niski liga koszt spaść ale oczywiście swój problem mieć . ciągle szukać wsparcie stwierdzać szef resovii . azs u rzeszów koszykówka i liga kobieta otrzymać &lt;num&gt; tysiąc . pieniądz być klub potrzebny jak powietrze zaległość ale sum zaskoczyć in minus bo wstępnie mówić &lt;num&gt; tysiąc . każdy pomoc cieszyć ale uczucie mieć mieszany . wnioskować &lt;num&gt; tysiąc a być mało niż wyjściowy kwota mówić wilhelm woźniak prezes azs u. to my komplikować sprawa . do koniec rok jakoś dobrnąć ale nie wiedzieć co potem . azs potrzebować na nowy sezon około &lt;num&gt; tysiąc . na raz mieć zabezpieczenie na około &lt;num&gt; procent ten kwota dodać woźniak . ekstraklasowi tenisista stołowy politechnika rzeszowski otrzymać zastrzyk w postać &lt;num&gt; tysiąc . tadeusz czułno trener akademik dementować że wnioskować o &lt;num&gt; tysiąc . bzdura . chodzić my o &lt;num&gt; tysiąc . przy okazja wyjaśniać że to nie być tak że prosić o pomoc dla &lt;num&gt; gracz ekstraklasa . mieć zespół w kilka liga szkolić młodzież . to około &lt;num&gt; osoba zapewniać czułno dodawać że &lt;num&gt; tysiąc to jeden szósty zakładać na sezon budżet . wiedzieć że miasto nie móc utrzymywać klub ale akurat my reprezentować sport niszowy i nie stworzyć samofinansować się projekt . odpadać choćby sponsor w postać tłum kibic . tak czy owak dziękować za pomoc . najmniej problem jeśli w ogół mieć developres siatkarka w i liga . ale jak się wieść to się widzie kluba oczekiwać &lt;num&gt; tysiąc dostać &lt;num&gt; nie sądzić że dostać coś koszt koszykówka mówić prezes Rafały mardoń . azs liczyć na więcej ale nie zgłosić się do ekstraklasa i grać na ten sam poziom .</th>\n",
       "      <td>dotacja z rzeszowski ratusz . Stala rzeszów i ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              summary\n",
       "text                                                                                                 \n",
       "niezbyt liczny zgromadzenie być bodaj pierwszy ...  rosja w Nowosybirsk odbyć się wiece przeciwko ...\n",
       "resovia <num> lokat w środa niby tylko zremisow...  resovia zagrać z przebój wolbrom Stala w Brzes...\n",
       "być gnijąca panna młody i być eksplodującysamsu...  samsung przyjąć zwrot eksplodującego note <num...\n",
       "nasz kluba <num> lokat przystać na prośba limbl...  politechnika rzeszowski zapraszać na sobota ja...\n",
       "dotacja być pomysł Witold walawendra radego roz...  dotacja z rzeszowski ratusz . Stala rzeszów i ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../../NLPer/resources/output/trimmed_all_data/val.csv', index_col=0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pl_spacy_model', disable=['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'train_test_val_dir': '../../NLPer/resources/output/trimmed_all_data/',\n",
    "    'model_output_path': '../../NLPer/resources/model_files_notebook/',\n",
    "    'vocab_output_path': '../../NLPer/resources/vocab_files_notebook/',\n",
    "    'model_name': 'seq2seq_with_att_pl_base',\n",
    "    'min_frequency_of_words_in_vocab': 10,\n",
    "    'dataframes_field_names': ['text', 'summary'],\n",
    "    'batch_size': 16,\n",
    "    'hidden_size': 256,\n",
    "    'embed_size': 128,\n",
    "    'epochs': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'grad_clip': 10.0,\n",
    "    'scheduler_step_size': 5000,\n",
    "    'scheduler_gamma': 0.75,\n",
    "    'save_model_after_epoch': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:23:06 [INFO] | LangUtils | set_language_model: Language model using SpaCy `pl_spacy_model`\n",
      "11:23:34 [INFO] | DataLoader | load: Length of vocabulary 68725\n"
     ]
    }
   ],
   "source": [
    "data_iterators, TEXT, SUMMARY = DataLoader(config=config).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_config = VocabConfig()\n",
    "vocab_config.set_vocab_from_field(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, valid_iter, test_iter = data_iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> na złoty oczywiście oddziaływać będą taki wydarzenie jak decyzja główny bank światowy przed wszystko rezerwa federalny mówić Sławomira dębowski główny analityka globtrex.com . natomiast co do polski rzeczywistość to oczywiście znaczenie będą mieść wybór parlamentarny który odbyć się na jesień . oczywiście pis mieć duży przewaga nad platforma obywatelski i wyglądać na to że będziemy mieć na jesień przejęcie władza i to się inwestor obawiać . myślić że poziom <num> na euro złoty czy poziom <num> na dolar do złoty móc być w ciąg ten kilka miesiąc do osiągnięcie . jak mówić z analiza techniczny wynikać że w długi perspektywa dolar móc się znacząco wzmocnić w relacja do euro . można oczekiwać nawet kurs około <num> który być tegoroczny minimum . a to automatycznie będzie sprzyjać <unk> się polski waluta . spadek móc też dotknąć giełda . już wydarzenie po wybór prezydencki pokazać że polski rynka być wrażliwy na ten typ zmiana . w kwestia korelacja pomiędzy polski rynek a rynka zagraniczny w to np. dax być czy rynka amerykański to widać wyraźnie że sytuacja na krajowy rynek głównie polityczny spowodować w ciąg ostatni kilka miesiąc właśnie po wybór prezydencki bardzo duży spadek na polski rynek zwracać uwaga Sławomira dębowski . wydawać się że jeżeli mielibyśmy do czynienie z scenariusz optymistyczny w stan to jeszcze w <num> rok indeks <unk> na szczyt z ten rok a na nasz rynek móc zobaczyć jakiś odbicie . natomiast obawiać się że jeśli przyjść zmiana władza na jesień to przeważyć obawa o to że coś się będzie dziać w różny sektor gospodarka i to móc spowodować spadek . główny sektor który móc oberwać być sektor bankowy . w skala globalny dla inwestor walutowy ważny być dwa częściowo powiązać z sobą kwestia przyszłość chiński gospodarka i chiński giełda oraz termin decyzja fed o podwyżka stopa procentowy . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_config.text_from_indices(batch.text[0].transpose(0, 1)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> Złoto móc osłabić się do główny waluta o <num> grosze . przez wybór parlamentarny na walutowy rynek w Polska inwestor szykować się do wybór parlamentarny . z analiza ekonomista wynikać że obawa przed rząd prawo i sprawiedliwość móc znacząco osłabić polski waluta . jesień móc płacić za dolar niemal <num> złoty a za euro nawet <num> złoty . przysłużyć się to także sytuacja międzynarodowy a analiza techniczny potwierdzać ten poziom . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_config.text_from_indices(batch.summary[0].transpose(0, 1)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, n_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding = nn.Embedding(\n",
    "            input_size, embedding_size, padding_idx=1).to(get_device())\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, n_layers,\n",
    "                          dropout=dropout, bidirectional=True).to(get_device())\n",
    "\n",
    "    def forward(self, sequence, hidden=None):\n",
    "        embedding_output = self.embedding(sequence)  # max_text_len x batch_size x embedding_size\n",
    "        encoder_outputs, hidden = self.gru(embedding_output, hidden)\n",
    "        # hidden: bidirectional x batch_size x hidden_size\n",
    "        # output: max_text_len x batch_size x bidirectional * hidden_size\n",
    "        encoder_outputs = encoder_outputs[:, :, :self.hidden_size] + encoder_outputs[:, :, self.hidden_size:]\n",
    "        # output: max_text_len x batch_size x hidden_size\n",
    "        return encoder_outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention = nn.Linear(hidden_size * 2, hidden_size).to(get_device())\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size)).to(get_device())\n",
    "        stdv = 1. / math.sqrt(self.v.size(0))\n",
    "        self.v.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        h = hidden.transpose(0, 1).repeat(1, encoder_outputs.size(0), 1)\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1)\n",
    "        attn_energies = self.score(h, encoder_outputs)  # batch_size x t x hidden\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)  # batch_size x t\n",
    "\n",
    "    def score(self, hidden, encoder_outputs):\n",
    "        # batch_size x t x 2*hidden -> batch_size x t x hidden\n",
    "        energy = torch.tanh(self.attention(torch.cat([hidden, encoder_outputs], 2)))\n",
    "        energy = energy.transpose(1, 2)  # batch_size x t x 2*hidden -> batch_size x t x hidden\n",
    "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)  # batch_size x 1 x hidden\n",
    "        energy = torch.bmm(v, energy)  # batch_size x 1 x t\n",
    "        return energy.squeeze(1)  # batch_size x t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            output_size, embedding_size, padding_idx=1).to(get_device())\n",
    "        self.dropout = nn.Dropout(dropout, inplace=True).to(get_device())\n",
    "        self.attention = BahdanauAttention(hidden_size).to(get_device())\n",
    "        self.gru = nn.GRU(hidden_size + embedding_size, hidden_size, n_layers, dropout=dropout).to(get_device())\n",
    "        self.classifier = nn.Linear(hidden_size * 2, output_size).to(get_device())\n",
    "\n",
    "    def forward(self, sequence, hidden, encoder_outputs):\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        embedding_output = self.embedding(sequence).unsqueeze(0)  # 1 x batch_size x n\n",
    "        embedding_output = self.dropout(embedding_output)\n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attention_weights = self.attention(hidden, encoder_outputs)\n",
    "        context = attention_weights.bmm(encoder_outputs.transpose(0, 1))  # batch_size x 1 x n\n",
    "        context = context.transpose(0, 1)  # (1,B,N)\n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        decoder_input = torch.cat([embedding_output, context], 2)\n",
    "        decoder_output, hidden = self.gru(decoder_input, hidden)\n",
    "        decoder_output = decoder_output.squeeze(0)  # (1,B,N) -> (B,N)\n",
    "        decoder_output = self.classifier(torch.cat([decoder_output, context.squeeze(0)], 1))\n",
    "        decoder_output = F.log_softmax(decoder_output, dim=1)\n",
    "        return decoder_output, hidden, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, text, summary, teacher_forcing_ratio=0.5):\n",
    "        batch_size = text.size(1)\n",
    "        max_len = summary.size(0)\n",
    "        vocab_size = self.decoder.output_size\n",
    "\n",
    "        encoder_output, hidden = self.encoder(text)\n",
    "        hidden = hidden[:self.decoder.n_layers]\n",
    "        output = summary.data[0, :]  # sos\n",
    "\n",
    "        outputs = torch.FloatTensor(max_len, batch_size, vocab_size).fill_(0).to(get_device())\n",
    "        for t in range(1, max_len):\n",
    "            output, hidden, attention_weights = self.decoder(\n",
    "                output, hidden, encoder_output)\n",
    "            outputs[t] = output\n",
    "            is_teacher = random.random() < teacher_forcing_ratio\n",
    "            top_first = output.data.max(1)[1]\n",
    "            output = summary.data[t] if is_teacher else top_first\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Instantiating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): EncoderRNN(\n",
      "    (embedding): Embedding(68725, 128, padding_idx=1)\n",
      "    (gru): GRU(128, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
      "  )\n",
      "  (decoder): DecoderRNN(\n",
      "    (embedding): Embedding(68725, 128, padding_idx=1)\n",
      "    (dropout): Dropout(p=0.5, inplace=True)\n",
      "    (attention): BahdanauAttention(\n",
      "      (attention): Linear(in_features=512, out_features=256, bias=True)\n",
      "    )\n",
      "    (gru): GRU(384, 256, dropout=0.5)\n",
      "    (classifier): Linear(in_features=512, out_features=68725, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"[!] Instantiating model...\")\n",
    "encoder = EncoderRNN(\n",
    "    input_size=config['text_size'],\n",
    "    embedding_size=config['embed_size'],\n",
    "    hidden_size=config['hidden_size'],\n",
    "    n_layers=2,\n",
    "    dropout=0.5,\n",
    ")\n",
    "decoder = DecoderRNN(\n",
    "    embedding_size=config['embed_size'],\n",
    "    hidden_size=config['hidden_size'],\n",
    "    output_size=config['text_size'],\n",
    "    n_layers=1,\n",
    "    dropout=0.5,\n",
    ")\n",
    "seq2seq = Seq2Seq(encoder, decoder).to(get_device())\n",
    "optimizer = optim.Adam(seq2seq.parameters(), lr=config['learning_rate'])\n",
    "scheduler = optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=config['scheduler_step_size'],\n",
    "    gamma=config['scheduler_gamma'],\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab_config.stoi[Token.Padding.value]).to(get_device())\n",
    "print(seq2seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_path: str, model_epoch) -> None:\n",
    "    torch.save(model.cpu().state_dict(), model_path + f'_{model_epoch}.pt')\n",
    "    torch.save(model.decoder.attention.v.cpu(), model_path + f'_att_param_{model_epoch}.pt')\n",
    "    model.to(get_device())\n",
    "\n",
    "\n",
    "def load_model(model, model_path: str, attention_param_path: str = None) -> None:\n",
    "    if attention_param_path:\n",
    "        model.load_state_dict(torch.load(model_path), strict=False)\n",
    "        model.decoder.attention.v = nn.Parameter(torch.load(attention_param_path))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "\n",
    "def get_text_summary_from_batch(batch):\n",
    "    text = batch.text[0].to(get_device())\n",
    "    summary = batch.summary[0].to(get_device())\n",
    "    return text, summary\n",
    "\n",
    "\n",
    "def show_rouge_and_attention_matrix(epoch, batch_id, text, summary):\n",
    "    original_text = vocab_config.text_from_indices(text.transpose(0, 1)[0])\n",
    "    target_summary = vocab_config.text_from_indices(summary.transpose(0, 1)[0])\n",
    "    output_summary, attention = predict(\n",
    "        vocab_config.text_from_indices(text.transpose(0, 1)[0]))\n",
    "    logging.info(f'Original : {original_text}\\n{\"\".join([\"-\" for i in range(80)])}'\n",
    "                     f'Target : {target_summary}\\n{\"\".join([\"-\" for i in range(80)])}'\n",
    "                     f'Summary : {output_summary}\\n{\"\".join([\"-\" for i in range(80)])}')\n",
    "    scores = calculate_rouge(hypothesis=output_summary, reference=target_summary)\n",
    "    if scores:\n",
    "        for key, value in scores[0].items():\n",
    "            logging.info(\n",
    "                f'{key.upper()} [precision] : {np.round(value[\"p\"] * 100, 2)} '\n",
    "                f'| [recall] : {np.round(value[\"r\"] * 100, 2)} '\n",
    "                f'| [f-score] : {np.round(value[\"f\"] * 100, 2)}',)\n",
    "        draw_attention_matrix(\n",
    "            attention=attention,\n",
    "            original=original_text,\n",
    "            summary=output_summary,\n",
    "            config=config,\n",
    "            epoch=epoch,\n",
    "            batch_id=batch_id,\n",
    "        )\n",
    "    del original_text, target_summary, output_summary, attention, scores\n",
    "\n",
    "\n",
    "def show_loss(batch_id, loss, train_iterator):\n",
    "    print(\n",
    "        f'[{batch_id} / {len(train_iterator)}] [loss: {loss}] '\n",
    "        f'[lr: {optimizer.param_groups[0][\"lr\"]} ]')\n",
    "    if AVAILABLE_GPU:\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, criterion, optimizer, scheduler, train_iter):\n",
    "    grad_clip = config['grad_clip']\n",
    "    text_size = config['text_size']\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_id, batch in tqdm(enumerate(train_iter), total=len(train_iter)):\n",
    "        text, summary = get_text_summary_from_batch(batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(text, summary)\n",
    "        loss = criterion(\n",
    "            output[1:].view(-1, text_size),\n",
    "            summary[1:].contiguous().view(-1),\n",
    "        )\n",
    "        \n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.data\n",
    "\n",
    "        if batch_id % 100 == 0:\n",
    "            show_loss(batch_id, loss.data, train_iter)\n",
    "\n",
    "        if batch_id % 400 == 0:\n",
    "            show_rouge_and_attention_matrix(epoch, batch_id, text, summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, val_iter):\n",
    "    with torch.no_grad():\n",
    "        text_size = config['text_size']\n",
    "        total_loss = 0\n",
    "        for batch_id, batch in enumerate(val_iter):\n",
    "            text, summary = get_text_summary_from_batch(batch)\n",
    "            \n",
    "            output = model(text, summary, teacher_forcing_ratio=0.0)\n",
    "            loss = criterion(\n",
    "                output[1:].view(-1, text_size),\n",
    "                summary[1:].contiguous().view(-1),\n",
    "            )\n",
    "            total_loss += loss.data\n",
    "        return total_loss / len(val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, length_of_original_text=0.25):\n",
    "    with torch.no_grad():\n",
    "        sequence = vocab_config.indices_from_text(text).unsqueeze(0)\n",
    "        sequence_length = sequence.size(1)\n",
    "        encoder_outputs, encoder_hidden = encoder(sequence.transpose(0, 1))\n",
    "        \n",
    "        decoder_input = torch.LongTensor(\n",
    "            [vocab_config.indices_from_text(Token.StartOfSentence.value)]).to(get_device())\n",
    "        hidden = encoder_hidden[:decoder.n_layers]\n",
    "        summary_words = [Token.StartOfSentence.value]\n",
    "        max_summary_length = int(sequence_length * length_of_original_text)\n",
    "        decoder_attentions = torch.zeros(max_summary_length, sequence_length)\n",
    "        \n",
    "        for idx in range(max_summary_length):\n",
    "            output, hidden, decoder_attention = decoder(\n",
    "                decoder_input, \n",
    "                hidden, \n",
    "                encoder_outputs,\n",
    "            )\n",
    "            decoder_attentions[idx, :decoder_attention.size(2)] += \\\n",
    "                decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "            top_v, top_i = output.data.topk(1)\n",
    "            ni = top_i[0]\n",
    "            if ni == vocab_config.indices_from_text(Token.EndOfSentence.value):\n",
    "                break\n",
    "            else:\n",
    "                summary_words.append(vocab_config.text_from_indices(ni))\n",
    "            \n",
    "            decoder_input = torch.LongTensor([ni]).to(get_device())\n",
    "        summary_words.append(Token.EndOfSentence.value)\n",
    "        summary = \" \".join(summary_words).lstrip()\n",
    "        return summary, decoder_attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = None\n",
    "for epoch in tqdm(range(1, config['epochs'] + 1)):\n",
    "    train(epoch, seq2seq, criterion, optimizer, scheduler, train_iter)\n",
    "    valid_loss = seq2seq.evaluate(model, criterion, valid_iter)\n",
    "    \n",
    "    if not best_loss or valid_loss < best_loss:\n",
    "        best_loss = valid_loss\n",
    "        save_model(\n",
    "            model=seq2seq, \n",
    "            model_path=os.path.join(config['model_output_path'], config['model_name']),\n",
    "            model_epoch=epoch,\n",
    "        )\n",
    "        test_loss = seq2seq.evaluate(valid_iterator=test_iterator)\n",
    "        logging.info(f'Test loss : {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
