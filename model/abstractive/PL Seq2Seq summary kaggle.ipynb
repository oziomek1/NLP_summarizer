{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from rouge) (1.14.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from glob import glob\n",
    "from spacy.symbols import LEMMA, ORTH, POS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "from tqdm import notebook, tqdm_notebook\n",
    "\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pl_spacy_model', disable=['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = ['<num>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_case = [{POS: 'NOUN', ORTH: '<num>', LEMMA: '<num>'}]\n",
    "nlp.tokenizer.add_special_case(\"<num>\", special_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_pl(text):\n",
    "    text = re.sub(r\"(\\„|\\”|\\“|\\‟|\\‶|\\‚|\\’|\\‘|\\‛|\\⁏|\\;|\\-|\\—|\\―|\\–|\\⁋|\\‰|\\\\|\\%|\\^|\\&|\\*|\\$|\\#|\\@|\\!)\", '', str(text))\n",
    "    text = re.sub(\"\\.\\.+\", ' ', str(text))\n",
    "    text = re.sub(r\"(\\/)\", ' ', str(text))\n",
    "    text = re.sub(\"[0-9]+\", \" <num> \", str(text)) # hide numbers\n",
    "    return [tok.text for tok in nlp.tokenizer(re.sub(\"\\s+\", ' ', str(text)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(batch_size, special_tokens=None):\n",
    "\n",
    "    TEXT = Field(tokenize=tokenize_pl, include_lengths=True, tokenizer_language='pl',\n",
    "                 init_token='<sos>', eos_token='<eos>')\n",
    "    SUMMARY = Field(tokenize=tokenize_pl, include_lengths=True, tokenizer_language='pl',\n",
    "                    init_token='<sos>', eos_token='<eos>')\n",
    "    train, val, test = TabularDataset.splits(\n",
    "        skip_header=True, \n",
    "        path='../input/pl-articles-split/', format='csv', \n",
    "        fields=[('index', None), ('lead', SUMMARY), ('text', TEXT)],\n",
    "        train='train.csv', validation='val.csv', test='test.csv'\n",
    "    )\n",
    "    TEXT.build_vocab(train, specials=special_tokens, min_freq=10)\n",
    "    SUMMARY.vocab = TEXT.vocab\n",
    "    train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "        (train, val, test), batch_size=batch_size, repeat=False, sort_key=lambda x: len(x.text), sort_within_batch=False\n",
    "    )\n",
    "    return train_iter, val_iter, test_iter, TEXT, SUMMARY, (train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter, TEXT, SUMMARY, _ = load_dataset(batch_size, special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_from_text(text, lang=TEXT):\n",
    "    indices = []\n",
    "    for word in text.strip().split(' '):\n",
    "        indices.append(lang.vocab.stoi[word])\n",
    "    return torch.LongTensor(indices).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_indices(indices, lang=TEXT):\n",
    "    text = \"\"\n",
    "    for element in indices:\n",
    "        if type(element) is torch.Tensor:\n",
    "            text += lang.vocab.itos[element.item()] + \" \"\n",
    "        else:\n",
    "            text += lang.vocab.itos[element] + \" \"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TEXT.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_from_indices(batch.text[0].transpose(0, 1)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_from_indices(batch.lead[0].transpose(0, 1)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, n_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size).cuda()\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, n_layers,\n",
    "                          dropout=dropout, bidirectional=True).cuda()\n",
    "\n",
    "    def forward(self, sequence, hidden=None):\n",
    "        embedding_output = self.embedding(sequence) # max_text_len x batch_size x embedding_size\n",
    "        encoder_outputs, hidden = self.gru(embedding_output, hidden)\n",
    "        # hidden: bidirectional x batch_size x hidden_size\n",
    "        # output: max_text_len x batch_size x bidirectional * hidden_size\n",
    "        encoder_outputs = encoder_outputs[:, :, :self.hidden_size] + encoder_outputs[:, :, self.hidden_size:]\n",
    "        # output: max_text_len x batch_size x hidden_size\n",
    "        return encoder_outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention = nn.Linear(hidden_size * 2, hidden_size).cuda()\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size)).cuda()\n",
    "        stdv = 1. / math.sqrt(self.v.size(0))\n",
    "        self.v.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        timestep = encoder_outputs.size(0)\n",
    "        h = hidden.repeat(timestep, 1, 1).transpose(0, 1)\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1) \n",
    "        attn_energies = self.score(h, encoder_outputs) # batch_size x t x hidden\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1) # batch_size x t\n",
    "\n",
    "    def score(self, hidden, encoder_outputs):\n",
    "        # batch_size x t x 2*hidden -> batch_size x t x hidden\n",
    "        energy = torch.tanh(self.attention(torch.cat([hidden, encoder_outputs], 2)))\n",
    "        energy = energy.transpose(1, 2) # batch_size x t x 2*hidden -> batch_size x t x hidden\n",
    "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1) # batch_size x 1 x hidden\n",
    "        energy = torch.bmm(v, energy) # batch_size x 1 x t\n",
    "        return energy.squeeze(1) # batch_size x t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size).cuda()\n",
    "        self.dropout = nn.Dropout(dropout, inplace=True).cuda()\n",
    "        self.attention = BahdanauAttention(hidden_size).cuda()\n",
    "        self.gru = nn.GRU(hidden_size + embedding_size, hidden_size, n_layers, dropout=dropout).cuda()\n",
    "        self.output = nn.Linear(hidden_size * 2, output_size).cuda()\n",
    "\n",
    "    def forward(self, sequence, hidden, encoder_outputs):\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        embedding_output = self.embedding(sequence).unsqueeze(0)  # 1 x batch_size x n\n",
    "        embedding_output = self.dropout(embedding_output)\n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attention_weights = self.attention(hidden[-1], encoder_outputs)\n",
    "        context = attention_weights.bmm(encoder_outputs.transpose(0, 1)) # batch_size x 1 x n\n",
    "        context = context.transpose(0, 1)  # (1,B,N)\n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        decoder_input = torch.cat([embedding_output, context], 2)\n",
    "        decoder_output, hidden = self.gru(decoder_input, hidden)\n",
    "        decoder_output = decoder_output.squeeze(0)  # (1,B,N) -> (B,N)\n",
    "        decoder_output = self.output(torch.cat([decoder_output, context.squeeze(0)], 1))\n",
    "        decoder_output = F.log_softmax(decoder_output, dim=1)\n",
    "        return decoder_output, hidden, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, text, summary, teacher_forcing_ratio=0.5):\n",
    "        batch_size = text.size(1)\n",
    "        max_len = summary.size(0)\n",
    "        vocab_size = self.decoder.output_size\n",
    "\n",
    "        encoder_output, hidden = self.encoder(text)\n",
    "        hidden = hidden[:self.decoder.n_layers]\n",
    "        output = summary.data[0, :]  # sos\n",
    "        \n",
    "        outputs = torch.cuda.FloatTensor(max_len, batch_size, vocab_size).fill_(0)\n",
    "        for t in range(1, max_len):\n",
    "            output, hidden, attention_weights = self.decoder(\n",
    "                    output, hidden, encoder_output)\n",
    "            outputs[t] = output\n",
    "            is_teacher = random.random() < teacher_forcing_ratio\n",
    "            top_first = output.data.max(1)[1]\n",
    "            output = summary.data[t] if is_teacher else top_first\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(e, model, optimizer, scheduler, train_iter, vocab_size, grad_clip, lang=TEXT):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pad = lang.vocab.stoi['<pad>']\n",
    "    for b, batch in notebook.tqdm(enumerate(train_iter), total=len(train_iter)):\n",
    "        text = batch.text[0].cuda()\n",
    "        summary = batch.lead[0].cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(text, summary)\n",
    "        loss = F.nll_loss(\n",
    "            output[1:].view(-1, vocab_size),\n",
    "            summary[1:].contiguous().view(-1),\n",
    "            ignore_index=pad,\n",
    "        )\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.data\n",
    "        \n",
    "        del output\n",
    "        del loss\n",
    "        \n",
    "        if b % 10 == 0 and b != 0:\n",
    "            total_loss = total_loss / 100\n",
    "            print(f'[{b} / {len(train_iter)}]  [loss: {total_loss}]')\n",
    "            total_loss = 0\n",
    "            torch.cuda.empty_cache()\n",
    "        if b % 400 == 0 and b != 0:\n",
    "            original_text = text_from_indices(text.transpose(0, 1)[0])\n",
    "            target_summary = text_from_indices(summary.transpose(0, 1)[0])\n",
    "            output_summary, attentions = summarize(text_from_indices(text.transpose(0, 1)[0]))\n",
    "            print('Original :', original_text)\n",
    "            print('-' * 80)\n",
    "            print('Target :', target_summary)\n",
    "            print('-' * 80)\n",
    "            print('Summary :', output_summary)\n",
    "            print('=' * 80)\n",
    "            scores = calculate_rouge(hypothesis=output_summary, reference=target_summary)\n",
    "            if scores:\n",
    "                for key, value in scores[0].items():\n",
    "                    print(f'{key.upper()} [precision] : {np.round(value[\"p\"] * 100, 2)} '\n",
    "                          f'| [recall] : {np.round(value[\"r\"] * 100, 2)} '\n",
    "                          f'| [f-score] : {np.round(value[\"f\"] * 100, 2)}')\n",
    "                draw_attention_matrix(attention=attentions, original=original_text, summary=output_summary)\n",
    "                \n",
    "            del original_text, target_summary, output_summary, attentions, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter, vocab_size, lang=TEXT):\n",
    "    with torch.no_grad():\n",
    "        pad = lang.vocab.stoi['<pad>']\n",
    "        total_loss = 0\n",
    "        for b, batch in enumerate(val_iter):\n",
    "            text = batch.text[0].cuda()\n",
    "            summary = batch.lead[0].cuda()\n",
    "            output = model(text, summary, teacher_forcing_ratio=0.0)\n",
    "            loss = F.nll_loss(\n",
    "                output[1:].view(-1, vocab_size),\n",
    "                summary[1:].contiguous().view(-1),\n",
    "                ignore_index=pad,\n",
    "            )\n",
    "            total_loss += loss.data\n",
    "        return total_loss / len(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge(hypothesis, reference):\n",
    "    hypothesis = hypothesis.split('<sos>')[1].split('<eos>')[0].strip()\n",
    "    reference = reference.split('<sos>')[1].split('<eos>')[0].strip()\n",
    "    if len(hypothesis) > 0:\n",
    "        scores = rouge.get_scores(hypothesis, reference)\n",
    "        return scores\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_attention_matrix(attention, original, summary):\n",
    "    labels_original = original.split('<sos>')[1].split('<eos>')[0].strip().split()\n",
    "    labels_summary = summary.split('<sos>')[1].split('<eos>')[0].strip().split()\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(attention.numpy()[:len(labels_summary), 1:len(labels_original)])\n",
    "    plt.xticks([i for i in range(len(labels_original)-1)], labels_original, rotation=75)\n",
    "    plt.yticks([i for i in range(len(labels_summary))], labels_summary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text):\n",
    "    with torch.no_grad():\n",
    "        sequence = indices_from_text(text).unsqueeze(0)\n",
    "        sequence_length = sequence.size(1)\n",
    "        encoder_outputs, encoder_hidden = encoder(sequence.transpose(0, 1))\n",
    "        \n",
    "        decoder_input = torch.cuda.LongTensor([indices_from_text(TEXT.init_token)])\n",
    "        hidden = encoder_hidden[:decoder.n_layers]\n",
    "        summary_words = ['<sos>']\n",
    "        max_summary_length = int(sequence_length * 0.25)\n",
    "        decoder_attentions = torch.zeros(max_summary_length, sequence_length)\n",
    "        \n",
    "        for idx in range(max_summary_length):\n",
    "            output, hidden, decoder_attention = decoder(\n",
    "                decoder_input, \n",
    "                hidden, \n",
    "                encoder_outputs,\n",
    "            )\n",
    "            decoder_attentions[idx, :decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "            top_v, top_i = output.data.topk(1)\n",
    "            ni = top_i[0]\n",
    "            if ni == indices_from_text(TEXT.eos_token):\n",
    "                break\n",
    "            else:\n",
    "                summary_words.append(text_from_indices(ni))\n",
    "            \n",
    "            decoder_input = torch.cuda.LongTensor([ni])\n",
    "        summary_words.append(TEXT.eos_token)\n",
    "        summary = \" \".join(summary_words).lstrip()\n",
    "        return summary, decoder_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr = 0.01\n",
    "grad_clip = 10.0\n",
    "scheduler_step_size = 50\n",
    "scheduler_gamma = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "embed_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'[!] preparing dataset...')\n",
    "text_size, summary_size = len(TEXT.vocab), len(SUMMARY.vocab)\n",
    "print(f'[TRAIN]: {len(train_iter)} | {len(train_iter.dataset)}\\t [TEST]: {len(test_iter)} | {len(test_iter.dataset)}')\n",
    "print(f'[TEXT_vocab] & [SUMMARY_vocab] (same) {text_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[!] Instantiating models...\")\n",
    "encoder = EncoderRNN(text_size, embed_size, hidden_size,\n",
    "                  n_layers=2, dropout=0.5)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, text_size,\n",
    "                  n_layers=1, dropout=0.5)\n",
    "seq2seq = Seq2Seq(encoder, decoder).cuda()\n",
    "optimizer = optim.Adam(seq2seq.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step_size, gamma=scheduler_gamma)\n",
    "print(seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = None\n",
    "for e in notebook.tqdm(range(1, epochs+1)):\n",
    "    train(e, seq2seq, optimizer, scheduler, train_iter, text_size, grad_clip, TEXT)\n",
    "    val_loss = evaluate(seq2seq, val_iter, text_size, TEXT)\n",
    "    print(f'[Epoch: {e}] val_loss: {val_loss} | val_pp: {math.exp(val_loss)}')\n",
    "\n",
    "    # Save the model if the validation loss is the best we've seen so far.\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        print(\"[!] saving model...\")\n",
    "        if not os.path.isdir(\".save\"):\n",
    "            os.makedirs(\".save\")\n",
    "        torch.save(seq2seq.state_dict(), './.save/seq2seq_%d.pt' % (e))\n",
    "        best_val_loss = val_loss\n",
    "test_loss = evaluate(seq2seq, test_iter, text_size, TEXT)\n",
    "print(f'[TEST] loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(seq2seq.state_dict(), 'pl_seq2seq_small.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in seq2seq.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
